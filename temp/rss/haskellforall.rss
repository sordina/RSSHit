<?xml version='1.0' encoding='UTF-8'?><rss xmlns:atom='http://www.w3.org/2005/Atom' xmlns:openSearch='http://a9.com/-/spec/opensearchrss/1.0/' xmlns:blogger='http://schemas.google.com/blogger/2008' xmlns:georss='http://www.georss.org/georss' xmlns:gd='http://schemas.google.com/g/2005' xmlns:thr='http://purl.org/syndication/thread/1.0' version='2.0'><channel><atom:id>tag:blogger.com,1999:blog-1777990983847811806</atom:id><lastBuildDate>Sun, 24 Mar 2013 01:47:33 +0000</lastBuildDate><title>Haskell for all</title><description></description><link>http://www.haskellforall.com/</link><managingEditor>noreply@blogger.com (Gabriel Gonzalez)</managingEditor><generator>Blogger</generator><openSearch:totalResults>36</openSearch:totalResults><openSearch:startIndex>1</openSearch:startIndex><openSearch:itemsPerPage>25</openSearch:itemsPerPage><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5379473811313516945</guid><pubDate>Fri, 22 Mar 2013 06:33:00 +0000</pubDate><atom:updated>2013-03-23T18:47:33.900-07:00</atom:updated><title>pipes-3.2: ListT, Codensity, ArrowChoice, and performance</title><description>&lt;tt&gt;pipes-3.2&lt;/tt&gt; is out and it boasts several cool new features.  The important highlights are: &lt;ul&gt;&lt;li&gt; A correct-by-construction &lt;tt&gt;ListT&lt;/tt&gt; implementation that converts to and from proxies &lt;li&gt; The &lt;tt&gt;CodensityP&lt;/tt&gt; proxy transformer, which improves the time complexity of left-associated binds &lt;li&gt; &lt;tt&gt;ArrowChoice&lt;/tt&gt; operations for selectively applying pipes to subsets of an input stream &lt;li&gt; "Pointful" operators &lt;li&gt; Many performance improvements &lt;/ul&gt;This post is mainly a changelog, so if you are completely new to &lt;tt&gt;pipes&lt;/tt&gt;, then I recommend you begin from &lt;a href="http://hackage.haskell.org/packages/archive/pipes/3.2.0/doc/html/Control-Proxy-Tutorial.html"&gt;the pipes tutorial&lt;/a&gt;, which is probably the longest tutorial on Hackage at this point.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;ListT&lt;/h4&gt;&lt;br /&gt;Many people know that &lt;tt&gt;ListT&lt;/tt&gt; in &lt;tt&gt;transformers&lt;/tt&gt; is broken, thanks to the wonderful &lt;a href="http://www.haskell.org/haskellwiki/ListT_done_right"&gt;ListT done right&lt;/a&gt; article.  Fewer people know that there is a correct-by-construction implementation of &lt;tt&gt;ListT&lt;/tt&gt; up on Hackage in &lt;a href="http://hackage.haskell.org/package/List"&gt;the &lt;tt&gt;List&lt;/tt&gt; package&lt;/a&gt;.  However, there are a couple of problems with the &lt;tt&gt;List&lt;/tt&gt; package: &lt;ul&gt;&lt;li&gt; It's difficult to build custom &lt;tt&gt;ListT&lt;/tt&gt; actions. &lt;li&gt; It's difficult to read out the result of &lt;tt&gt;List&lt;/tt&gt;. &lt;/ul&gt;The &lt;tt&gt;generator&lt;/tt&gt; package tries to solve the first problem, and remarkably resembles a &lt;tt&gt;Producer&lt;/tt&gt; from &lt;tt&gt;pipes&lt;/tt&gt;.  It provides a monad equipped with a &lt;tt&gt;yield&lt;/tt&gt; command and you use &lt;tt&gt;generate&lt;/tt&gt; to compile it to a &lt;tt&gt;ListT&lt;/tt&gt; action.  However, neither &lt;tt&gt;List&lt;/tt&gt; nor &lt;tt&gt;generator&lt;/tt&gt; solve the second problem.&lt;br /&gt;&lt;br /&gt;If you thought to yourself "Oh, no.... Gabriel added a &lt;tt&gt;List&lt;/tt&gt; dependency to &lt;tt&gt;pipes&lt;/tt&gt;", you'd be wrong!  In fact, &lt;tt&gt;pipes&lt;/tt&gt; has had &lt;tt&gt;ListT&lt;/tt&gt; support since version 2.4 and I didn't even realize it until I was working on a perfect backtracking parser for the upcoming &lt;tt&gt;pipes-parse&lt;/tt&gt; library.&lt;br /&gt;&lt;br /&gt;The key lies in the &lt;tt&gt;Interact&lt;/tt&gt; class that I introduced in &lt;tt&gt;pipes-2.4&lt;/tt&gt;, which I've renamed to the &lt;tt&gt;ListT&lt;/tt&gt; class in this release.  People familiar with &lt;tt&gt;pipes&lt;/tt&gt; know that this mysterious class provided two extra operators: &lt;tt&gt;(/&gt;/)&lt;/tt&gt; and &lt;tt&gt;(\&gt;\)&lt;/tt&gt;, and that these operators happened to form two extra categories, with &lt;tt&gt;respond&lt;/tt&gt; and &lt;tt&gt;request&lt;/tt&gt; as their respective identities: &lt;pre&gt;&lt;br /&gt;respond /&gt;/ f = f&lt;br /&gt;&lt;br /&gt;f /&gt;/ respond = f&lt;br /&gt;&lt;br /&gt;(f /&gt;/ g) /&gt;/ h = f /&gt;/ (g /&gt;/ h)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;request \&gt;\ f = f&lt;br /&gt;&lt;br /&gt;f \&gt;\ request = f&lt;br /&gt;&lt;br /&gt;(f \&gt;\ g) \&gt;\ h = f \&gt;\ (g \&gt;\ h)&lt;br /&gt;&lt;/pre&gt;However, at the time I discovered these two additional categories I dismissed them as less interesting than the proxy composition categories, even mentioning in the tutorial that "they are more exotic and you probably never need to use them".  Little did I know how wrong I was!&lt;br /&gt;&lt;br /&gt;I later discovered that these two categories were both &lt;tt&gt;ListT&lt;/tt&gt; Kleisli categories.  The "respond" category (i.e. &lt;tt&gt;respond&lt;/tt&gt; and &lt;tt&gt;(/&gt;/)&lt;/tt&gt;)) is actually a monad over the downstream output of proxies, or in other words: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;respond&lt;/tt&gt; corresponds to &lt;tt&gt;return&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;(/&gt;/)&lt;/tt&gt; corresponds to &lt;tt&gt;(&gt;=&gt;)&lt;/tt&gt;&lt;/ul&gt;I call this monad &lt;tt&gt;RespondT&lt;/tt&gt; and &lt;tt&gt;Control.Proxy.ListT&lt;/tt&gt; exports the following newtype which lets you convert between the &lt;tt&gt;Proxy&lt;/tt&gt; monad and the &lt;tt&gt;RespondT&lt;/tt&gt; monad: &lt;pre&gt;&lt;br /&gt;newtype RespondT p a' a b' m b&lt;br /&gt;    = RespondT { runRespondT :: p a' a b' b m b' }&lt;br /&gt;&lt;br /&gt;instance (Monad m, ListT p) =&gt; Monad (RespondT p a' a b' m) where&lt;br /&gt;    return a = RespondT (respond a)&lt;br /&gt;    m &gt;&gt;= f  = RespondT (&lt;br /&gt;        runRespondT m //&gt; \a -&gt;&lt;br /&gt;        runRespondT (f a))&lt;br /&gt;    -- (//&gt;) is the "pointful" version of (/&gt;/),&lt;br /&gt;    -- just like (&gt;&gt;=) is the "pointful" version of (&gt;=&gt;)&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;RespondT&lt;/tt&gt;, you can bind a proxy's output as if you were binding a list within the list monad: &lt;pre&gt;&lt;br /&gt;import Control.Proxy&lt;br /&gt;&lt;br /&gt;twoNumbers :: (Proxy p) =&gt; () -&gt; Producer p Int IO ()&lt;br /&gt;twoNumbers =&lt;br /&gt;     readLnS&lt;br /&gt; &gt;-&gt; execU (putStrLn "Enter a number: ")&lt;br /&gt; &gt;-&gt; takeB_ 2&lt;br /&gt;&lt;br /&gt;stringsTillQuit :: (Proxy p) =&gt; () -&gt; Producer p String IO ()&lt;br /&gt;stringsTillQuit =&lt;br /&gt;     stdinS&lt;br /&gt; &gt;-&gt; execU (putStrLn "Enter a string: ")&lt;br /&gt; &gt;-&gt; takeWhileD (/= "quit")&lt;br /&gt;&lt;br /&gt;-- 'ProduceT' is a convenient type synonym around 'RespondT'&lt;br /&gt;exampleListT :: (ListT p) =&gt; () -&gt; ProduceT p IO (Int, String)&lt;br /&gt;exampleListT () = do&lt;br /&gt;    n   &lt;- RespondT $ twoNumbers ()&lt;br /&gt;    str &lt;- RespondT $ stringsTillQuit ()&lt;br /&gt;    return (n, str)&lt;br /&gt;&lt;/pre&gt;You can then compile &lt;tt&gt;RespondT&lt;/tt&gt; back to a proxy just by unwrapping the newtype, generating a proxy that produces one output per permutation of bound values: &lt;pre&gt;&lt;br /&gt;exampleProxy :: (List p) =&gt; () -&gt; Producer p (Int, String) IO ()&lt;br /&gt;exampleProxy = runRespondK exampleListT&lt;br /&gt;&lt;/pre&gt;More often, you would just combine these two steps into one: &lt;pre&gt;&lt;br /&gt;exampleProxy :: (List p) =&gt; () -&gt; Producer p (Int, String) IO ()&lt;br /&gt;exampleProxy () = runRespondT $ do&lt;br /&gt;    n   &lt;- RespondT $ twoNumbers ()&lt;br /&gt;    str &lt;- RespondT $ stringsTillQuit ()&lt;br /&gt;    return (n, str)&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runProxy $ exampleProxy &gt;-&gt; printD&lt;br /&gt;Enter a number: &lt;br /&gt;1&amp;lt;Enter&amp;gt;&lt;br /&gt;Enter a string: &lt;br /&gt;Hello&amp;lt;Enter&amp;gt;&lt;br /&gt;(1,"Hello")&lt;br /&gt;Enter a string: &lt;br /&gt;world&amp;lt;Enter&amp;gt;&lt;br /&gt;(1,"world")&lt;br /&gt;Enter a string: &lt;br /&gt;quit&amp;lt;Enter&amp;gt;&lt;br /&gt;Enter a number: &lt;br /&gt;2&amp;lt;Enter&amp;gt;&lt;br /&gt;Enter a string: &lt;br /&gt;Testing&amp;lt;Enter&amp;gt;&lt;br /&gt;(2,"Testing")&lt;br /&gt;Enter a string: &lt;br /&gt;123&amp;lt;Enter&amp;gt;&lt;br /&gt;(2,"123")&lt;br /&gt;Enter a string: &lt;br /&gt;quit&amp;lt;Enter&amp;gt;&lt;br /&gt;&lt;/pre&gt;Notice how reading out the &lt;tt&gt;ListT&lt;/tt&gt; is trivial.  You just use the &lt;tt&gt;pipes&lt;/tt&gt; machinery you know and love to read out the resulting lazy stream of values.&lt;br /&gt;&lt;br /&gt;As you might have guessed, there is a symmetric &lt;tt&gt;ListT&lt;/tt&gt; monad over upstream outputs, too, which I've named &lt;tt&gt;RequestT&lt;/tt&gt;.  &lt;tt&gt;RespondT&lt;/tt&gt; and &lt;tt&gt;RequestT&lt;/tt&gt; are correct by construction, meaning that they always satisfy the monad and monad transformer laws.&lt;br /&gt;&lt;br /&gt;However, &lt;tt&gt;RespondT&lt;/tt&gt; and &lt;tt&gt;RequestT&lt;/tt&gt; are much more powerful than meets the eye.  For example, you need not limit yourself to &lt;tt&gt;Producer&lt;/tt&gt;s when you use &lt;tt&gt;RespondT&lt;/tt&gt;, as the following example demonstrates: &lt;pre&gt;&lt;br /&gt;pipeT :: (ListT p) =&gt; () -&gt; Pipe p Int (Int, Int) IO ()&lt;br /&gt;pipeT () = runRespondT $ do&lt;br /&gt;    x &lt;- RespondT $ takeB_ 2 ()&lt;br /&gt;    y &lt;- RespondT $ takeB_ 3 ()&lt;br /&gt;    return (x, y)&lt;br /&gt;&lt;/pre&gt;You can non-deterministically select outputs from any &lt;tt&gt;Proxy&lt;/tt&gt; type and &lt;tt&gt;RespondT&lt;/tt&gt; just magically does the right thing: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runProxy $ enumFromS 1 &gt;-&gt; pipeT &gt;-&gt; printD&lt;br /&gt;(1,2)&lt;br /&gt;(1,3)&lt;br /&gt;(1,4)&lt;br /&gt;(5,6)&lt;br /&gt;(5,7)&lt;br /&gt;(5,8)&lt;br /&gt;&lt;/pre&gt;Similarly, you need not restrict yourself to unidirectional pipes.  &lt;tt&gt;RespondT&lt;/tt&gt; and &lt;tt&gt;RequestT&lt;/tt&gt; won't bat an eyelash if you try to use them for bidirectional general-purpose proxies.  &lt;tt&gt;pipes&lt;/tt&gt; goes above and beyond a traditional &lt;tt&gt;ListT&lt;/tt&gt; implementation.&lt;br /&gt;&lt;br /&gt;The proxy prelude provides convenience functions for common operations, such as ranges or iterating over lists: &lt;pre&gt;&lt;br /&gt;pairs :: (ListT p) =&gt; () -&gt; Producer p (Int, Int) IO ()&lt;br /&gt;pairs () = runRespondT $ do&lt;br /&gt;    x &lt;- rangeS 1 2&lt;br /&gt;    lift $ putStrLn $ "x = " ++ show x&lt;br /&gt;    y &lt;- eachS [4, 6, 8]&lt;br /&gt;    lift $ putStrLn $ "y = " ++ show y&lt;br /&gt;    return (x, y)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;eachS&lt;/tt&gt; is named after Ruby's &lt;tt&gt;each&lt;/tt&gt; function and &lt;tt&gt;rangeS&lt;/tt&gt; is named after Python's &lt;tt&gt;range&lt;/tt&gt; function.  You can bind each one within &lt;tt&gt;RespondT&lt;/tt&gt; to non-deterministically select from a list or range, respectively. &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runProxy $ pairs &gt;-&gt; printD&lt;br /&gt;x = 1&lt;br /&gt;y = 4&lt;br /&gt;(1,4)&lt;br /&gt;y = 6&lt;br /&gt;(1,6)&lt;br /&gt;y = 8&lt;br /&gt;(1,8)&lt;br /&gt;x = 2&lt;br /&gt;y = 4&lt;br /&gt;(2,4)&lt;br /&gt;y = 6&lt;br /&gt;(2,6)&lt;br /&gt;y = 8&lt;br /&gt;(2,8)&lt;br /&gt;&lt;/pre&gt;It also wouldn't be a "&lt;tt&gt;ListT&lt;/tt&gt; done right" unless it got the examples from that article correct, too: &lt;pre&gt;&lt;br /&gt;myTest :: (ListT p) =&gt; Int -&gt; () -&gt; ProduceT p IO (Int, Int)&lt;br /&gt;myTest n () = do&lt;br /&gt;    let squares = eachS $ takeWhile (&lt;= n) $ map (^2) [0..]&lt;br /&gt;    x &lt;- squares&lt;br /&gt;    y &lt;- squares&lt;br /&gt;    lift $ print (x, y)&lt;br /&gt;    guard $ x + y == n&lt;br /&gt;    lift $ putStrLn "Sum of squares."&lt;br /&gt;    return (x, y)&lt;br /&gt;&lt;/pre&gt;However, that example had a much more difficult time reading out just the first result.  We can do so quite easily just by using the &lt;tt&gt;headD_&lt;/tt&gt; fold, which only drives the &lt;tt&gt;RespondT&lt;/tt&gt; block long enough to retrieve the first result: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; let p = raiseK (runRespondK (myTest 5)) &gt;-&gt; headD_&lt;br /&gt;&gt;&gt;&gt; execWriterT $ runProxy p&lt;br /&gt;(0,0)&lt;br /&gt;(0,1)&lt;br /&gt;(0,4)&lt;br /&gt;(1,0)&lt;br /&gt;(1,1)&lt;br /&gt;(1,4)&lt;br /&gt;Sum of squares.&lt;br /&gt;First {getFirst = Just (1,4)}&lt;br /&gt;&lt;/pre&gt;If you want to learn more, you can read the newly added &lt;a href="http://hackage.haskell.org/packages/archive/pipes/3.2.0/doc/html/Control-Proxy-Tutorial.html#g:11"&gt;&lt;tt&gt;ListT&lt;/tt&gt; section of the tutorial&lt;/a&gt;, which provides even more code examples.&lt;br /&gt;&lt;br /&gt;So now proxies now possess two symmetric ListT implementations you can add to your toolbox, and they improve on the state of the art by reusing the elegant &lt;tt&gt;pipes&lt;/tt&gt; machinery for both building &lt;tt&gt;ListT&lt;/tt&gt; actions and reading out their values.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Codensity Proxy Transformer&lt;/h4&gt;&lt;br /&gt;In addition to &lt;tt&gt;conduit&lt;/tt&gt;, I must also contend with Edward's &lt;tt&gt;machines&lt;/tt&gt; library (currently on &lt;a href="https://github.com/ekmett/machines/"&gt;Github&lt;/a&gt;).  Until recently, &lt;tt&gt;machines&lt;/tt&gt; possessed one notable advantage over &lt;tt&gt;pipes&lt;/tt&gt;: it used a codensity transformation of its internal free monad to avoid a quadratic blowup from a large series of left-associated binds.  Normally these do not arise commonly in practice, but it is still a nice feature to have.&lt;br /&gt;&lt;br /&gt;Now &lt;tt&gt;pipes&lt;/tt&gt; has assimilated this feature, too.  You can improve the time complexity of any pipe just by wrapping the pipe in &lt;tt&gt;runCodensityP&lt;/tt&gt; or &lt;tt&gt;runCodensityK&lt;/tt&gt;, both of which behave like &lt;a href="http://hackage.haskell.org/packages/archive/free/3.4/doc/html/Control-Monad-Free-Church.html#v:improve"&gt;the &lt;tt&gt;improve&lt;/tt&gt; function&lt;/a&gt; from the &lt;tt&gt;free&lt;/tt&gt; package.  These automatically fix any quadratic time complexity of left-associated binds.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;replicateM&lt;/tt&gt; is a great example of a function that generates lots of left-associated binds.  If I try to use it within a pipe, I will get a quadratic blowup: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Proxy&lt;br /&gt;&lt;br /&gt;leftAssociate () = replicateM 10000 (request ())&lt;br /&gt;&lt;br /&gt;main = do&lt;br /&gt;    xs &lt;- runProxy $ enumFromS (1 :: Int) &gt;-&gt; leftAssociate&lt;br /&gt;    print xs&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ time ./main &gt;/dev/null&lt;br /&gt;&lt;br /&gt;real    0m3.773s&lt;br /&gt;user    0m3.716s&lt;br /&gt;sys     0m0.052s&lt;br /&gt;&lt;/pre&gt;... but if you wrap the pipeline in &lt;tt&gt;runCodensityK&lt;/tt&gt;, it switches to linear time complexity: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Codensity&lt;br /&gt;&lt;br /&gt;leftAssociate () = replicateM 10000 (request ())&lt;br /&gt;&lt;br /&gt;main = do&lt;br /&gt;    xs &lt;- runProxy $ runCodensityK $&lt;br /&gt;        enumFromS (1 :: Int) &gt;-&gt; leftAssociate&lt;br /&gt;    print xs&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ time ./main &gt;/dev/null&lt;br /&gt;&lt;br /&gt;real    0m0.031s&lt;br /&gt;user    0m0.024s&lt;br /&gt;sys     0m0.000s&lt;br /&gt;&lt;/pre&gt;Even better, you can wrap just the pathological pipe in &lt;tt&gt;runCodensityK&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;main = do&lt;br /&gt;    xs &lt;- runProxy $&lt;br /&gt;        enumFromS (1 :: Int) &gt;-&gt; runCodensityK leftAssociate&lt;br /&gt;    print xs&lt;br /&gt;&lt;/pre&gt;... which gives a minor performance improvement (more easily detectable for larger numbers of &lt;tt&gt;request&lt;/tt&gt;s): &lt;pre&gt;&lt;br /&gt;time ./main &gt;/dev/null&lt;br /&gt;&lt;br /&gt;real    0m0.027s&lt;br /&gt;user    0m0.024s&lt;br /&gt;sys     0m0.000s&lt;br /&gt;&lt;/pre&gt;My own performance measurements show that while the codensity transformation does improve time complexities for left-associated binds, it yields worse constant factors (about 6-fold slower for entirely pure code, but much less for IO-bound code), which is why I do not enable it on by default.  The main reason the naive free monad in the &lt;tt&gt;ProxyFast&lt;/tt&gt; implementation outperforms the codensity version is that it can use rewrite &lt;tt&gt;RULES&lt;/tt&gt; to rewrite your code into the optimal tuned form, but the codensity-transformed version cannot.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;ArrowChoice&lt;/h4&gt;&lt;br /&gt;Ever since I first released &lt;tt&gt;pipes&lt;/tt&gt;, I've received numerous questions about whether or not &lt;tt&gt;pipes&lt;/tt&gt; can be made an instance of &lt;tt&gt;Arrow&lt;/tt&gt;.  While you can't make &lt;tt&gt;Arrow&lt;/tt&gt; work, you CAN make proxies implement &lt;tt&gt;ArrowChoice&lt;/tt&gt;, although I don't provide an actual instance because there are two such instances (one for downstream and one for upstream) and the requisite newtypes would be very cumbersome.&lt;br /&gt;&lt;br /&gt;You can find these combinators in &lt;a href="http://hackage.haskell.org/packages/archive/pipes/3.2.0/doc/html/Control-Proxy-Prelude-Base.html#g:7"&gt;the &lt;tt&gt;ArrowChoice&lt;/tt&gt; section&lt;/a&gt; of the proxy prelude, which provides &lt;tt&gt;left{D/U}&lt;/tt&gt; and &lt;tt&gt;right{D/U}&lt;/tt&gt;.  Using these combinators, you can selectively apply pipes to a subset of a stream: &lt;pre&gt;&lt;br /&gt;stream&lt;br /&gt;    :: (Monad m, Proxy p)&lt;br /&gt;    =&gt; () -&gt; Producer p (Either Int Char) m ()&lt;br /&gt;stream = fromListS&lt;br /&gt;    [Left 3, Right 'C', Right 'D', Left 4, Right 'E', Left 5]&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; let p = stream &gt;-&gt; leftD (takeB_ 2 &gt;-&gt; mapD show) &gt;-&gt; printD&lt;br /&gt;&gt;&gt;&gt; runProxy p&lt;br /&gt;Left "3"&lt;br /&gt;Right 'C'&lt;br /&gt;Right 'D'&lt;br /&gt;Left "4"&lt;br /&gt;&lt;/pre&gt;This lets you dynamically switch behavior in response to stream values.  For example, one person recently asked me how you would switch content handling in the middle of a pipeline (for example, after negotiating encryption and compression).  One option I proposed is that they could use &lt;tt&gt;Either&lt;/tt&gt; to distinguish between values before and after negotiation and then filter them differently using the &lt;tt&gt;ArrowChoice&lt;/tt&gt; combinators: &lt;pre&gt;&lt;br /&gt;negotiation () = do&lt;br /&gt;     (before &gt;-&gt; mapD Left ) ()&lt;br /&gt;     (after  &gt;-&gt; mapD Right) ()&lt;br /&gt;&lt;br /&gt;main = runProxy $&lt;br /&gt;     source&lt;br /&gt; &gt;-&gt; negotiation&lt;br /&gt; &gt;-&gt; leftD idT &gt;-&gt; rightD (decompress &gt;-&gt; decrypt)&lt;br /&gt; &gt;-&gt; sink&lt;br /&gt;&lt;/pre&gt;However, that's purely a theoretical idea I threw out there.  I haven't actually tried this solution in practice, yet.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Point-ful operators&lt;/h4&gt;&lt;br /&gt;All type classes now use the "point-ful" equivalents of their original point-free composition operators, and the point-free operators are now derived from the point-ful ones.  There are two significant advantages of this: &lt;ul&gt;&lt;li&gt; Types.  Some previous perfectly safe code required the following hack: &lt;tt&gt;((\_ -&gt; p) &gt;-&gt; k) undefined&lt;/tt&gt;.  These point-ful operators now naturally lead to the correct and more general types of their corresponding point-free composition operators. &lt;li&gt; Performance.  I actually used these operators internally to get &lt;tt&gt;pipes&lt;/tt&gt; performance so high.  Exposing them directly in the type class removes a lot of code indirection and improves the performance of the base proxy implementations (typically by about 10-15%) and the proxy transformers because there is less indirection. &lt;/ul&gt;Also, some people have told me that they found these point-ful operators to be more intuitive to work with, although I still personally prefer the point-free operators.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Performance&lt;/h4&gt;&lt;br /&gt;Other performance improvements include better rewrite &lt;tt&gt;RULES&lt;/tt&gt;.  I found several cases where the original rules were not firing, which is why the proxy prelude still depended on the manual worker/wrapper code to ensure that they fired.  I recently found a more general set of rewrite &lt;tt&gt;RULES&lt;/tt&gt; that work even more reliably and the proxy prelude now seems to optimize correctly even when written using the most naive code.  However, I haven't committed the newer naive versions yet, as a precaution.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Stability&lt;/h4&gt;&lt;br /&gt;Many people probably want to know when I still stabilize the &lt;tt&gt;pipes&lt;/tt&gt; package so that it can eventually go in the Haskell platform.  The answer is that I won't stabilize it officially until I complete three upcoming libraries: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;pipes-parse&lt;/tt&gt;, which provides a native parsing extension and a standard set of end-of-input machinery for &lt;tt&gt;pipes&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;pipes-free&lt;/tt&gt;, which will expose the underlying free monad and also provide an &lt;tt&gt;iostreams&lt;/tt&gt;-like interface to &lt;tt&gt;pipes&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;pipes-stm&lt;/tt&gt;, which will be the basis of an FRP system built on top of &lt;tt&gt;pipes&lt;/tt&gt;&lt;/ul&gt;These are the three libraries that I expect to considerably exercise the API of the main library and uncover any significant omissions in its design.  For example, just working on &lt;tt&gt;pipes-parse&lt;/tt&gt; alone gave rise to the &lt;tt&gt;ListT&lt;/tt&gt; machinery and the &lt;tt&gt;ArrowChoice&lt;/tt&gt; combinators.  However, the core API has so far proven to be particularly solid and future-proof, thanks to the enormously useful proxy transformer system.  Proxy transformers let me continue to release new features (like &lt;tt&gt;CodensityP&lt;/tt&gt; and the upcoming &lt;tt&gt;ParseP&lt;/tt&gt;) without impacting any existing code.  The only major backwards-incompatible change in this last release was just renaming the &lt;tt&gt;Interact&lt;/tt&gt; class to &lt;tt&gt;ListT&lt;/tt&gt; for clarity, since I figured this would be my last chance to rename it now that people will probably use it much more heavily now.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Open Design Issues&lt;/h4&gt;&lt;br /&gt;There remains one major performance bottleneck in the fast proxy implementation: &lt;tt&gt;hoist&lt;/tt&gt;.  I can dramatically speed it up by removing an normalization step, but doing so means that you can only safely supply &lt;tt&gt;hoist&lt;/tt&gt; with monad morphisms (such as &lt;tt&gt;lift&lt;/tt&gt;), otherwise you will violate the monad transformer laws.  In theory, you should really only use monad morphisms for &lt;tt&gt;hoist&lt;/tt&gt; anyway, but in practice people violate this all the time and try to do "weird" things like &lt;tt&gt;hoist (runStateT 0)&lt;/tt&gt;, which is very insensible, and I can't easily use the types to forbid that kind of thing.  So I would like feedback on whether people prefer speed or safety for the &lt;tt&gt;ProxyFast&lt;/tt&gt; implementation.  Alternatively, I could release a third base &lt;tt&gt;Proxy&lt;/tt&gt; instance not selected by default that is identical to &lt;tt&gt;ProxyFast&lt;/tt&gt; in all respects except for providing the faster &lt;tt&gt;hoist&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Another question I have is whether or not to merge the proxy prelude into a single module.  I welcome any feedback on that.  Some people comment that the the module hierarchy is a little-bit too fine-grained and that's one opportunity to condense four modules into one.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Upcoming libraries&lt;/h4&gt;&lt;br /&gt;The next library on the docket is &lt;tt&gt;pipes-parse&lt;/tt&gt;, followed shortly by &lt;tt&gt;pipes-bytestring&lt;/tt&gt;.  I know that many people need the &lt;tt&gt;pipes-bytestring&lt;/tt&gt; library to progress further with &lt;tt&gt;pipes&lt;/tt&gt;, but it depends on &lt;tt&gt;pipes-parse&lt;/tt&gt;, which establishes some important higher-level idioms for the &lt;tt&gt;pipes&lt;/tt&gt; ecosystem in general.  My rate of progress has slowed recently mainly because I'm wrapping up my PhD, but I expect that I can finish both within about two months even at my current rate.</description><link>http://www.haskellforall.com/2013/03/pipes-32-listt-codensity-arrowchoice.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>0</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5749877014505709510</guid><pubDate>Sat, 16 Mar 2013 15:09:00 +0000</pubDate><atom:updated>2013-03-17T08:40:17.160-07:00</atom:updated><title>mmorph-1.0.0: Monad morphisms</title><description>Several people have asked me to split off &lt;tt&gt;MFunctor&lt;/tt&gt; from &lt;tt&gt;pipes&lt;/tt&gt; so that they could use it in their own libraries without a &lt;tt&gt;pipes&lt;/tt&gt; dependency, so today I'm releasing &lt;a href="http://hackage.haskell.org/package/mmorph"&gt;the &lt;tt&gt;mmorph&lt;/tt&gt; library&lt;/a&gt;, which is the new official home of &lt;tt&gt;MFunctor&lt;/tt&gt;.  The upcoming &lt;tt&gt;pipes-3.2&lt;/tt&gt; release will depend on &lt;tt&gt;mmorph&lt;/tt&gt; to provide &lt;tt&gt;MFunctor&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The &lt;tt&gt;mmorph&lt;/tt&gt; library specifically targets people who make heavy use of monad transformers.  Many common problems that plague users of monad transformers have very elegant solutions inspired by category theory and &lt;tt&gt;mmorph&lt;/tt&gt; provides a standard home for these kinds of operations.&lt;br /&gt;&lt;br /&gt;This post won't include examples because &lt;tt&gt;mmorph&lt;/tt&gt; already features an &lt;a href="http://hackage.haskell.org/packages/archive/mmorph/1.0.0/doc/html/Control-Monad-Morph.html#g:3"&gt;extended tutorial&lt;/a&gt; at the bottom of its sole module: &lt;tt&gt;Control.Monad.Morph&lt;/tt&gt;.  The tutorial highlights several common use cases where the &lt;tt&gt;mmorph&lt;/tt&gt; library comes in handy and I highly recommend you read it if you want to understand the concrete problems that the &lt;tt&gt;mmorph&lt;/tt&gt; library solves.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Moving on up&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;mmorph&lt;/tt&gt; takes several common Haskell idioms you know and love and lifts them to work on monads instead.  The simplest example is a monad morphism: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE RankNTypes, TypeOperators #-}&lt;br /&gt;&lt;br /&gt;type m :-&gt; n = forall a . m a -&gt; n a&lt;br /&gt;&lt;/pre&gt;A monad morphism is a function between monads and all monad morphisms must satisfy the following two "monad morphism laws": &lt;pre&gt;&lt;br /&gt;morph :: m :-&gt; n&lt;br /&gt;&lt;br /&gt;morph $ do x &lt;- m  =  do x &lt;- morph m&lt;br /&gt;           f x           morph (f x)&lt;br /&gt;&lt;br /&gt;morph (return x) = return x&lt;br /&gt;&lt;/pre&gt;Using the above type synonym for monad morphisms, we can simplify the type signature of &lt;tt&gt;hoist&lt;/tt&gt; from the &lt;tt&gt;MFunctor&lt;/tt&gt; type class: &lt;pre&gt;&lt;br /&gt;class MFunctor t where&lt;br /&gt;    hoist :: (Monad m) =&gt; (m :-&gt; n) -&gt; (t m :-&gt; t n)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;MFunctor&lt;/tt&gt; is the higher-order analog of the &lt;tt&gt;Functor&lt;/tt&gt; class (thus the name), and the resemblance becomes even more striking if you change the type variable names: &lt;pre&gt;&lt;br /&gt;class MFunctor f where&lt;br /&gt;    hoist :: (a :-&gt; b) -&gt; (f a :-&gt; f b)&lt;br /&gt;&lt;/pre&gt;This parallel lets us reuse our intuition for &lt;tt&gt;Functor&lt;/tt&gt;s.  An &lt;tt&gt;MFunctor&lt;/tt&gt; wraps a monad in the same way that a &lt;tt&gt;Functor&lt;/tt&gt; wraps a type, and &lt;tt&gt;MFunctor&lt;/tt&gt;s provide an &lt;tt&gt;fmap&lt;/tt&gt;-like function, &lt;tt&gt;hoist&lt;/tt&gt;, which modifies the wrapped monad.&lt;br /&gt;&lt;br /&gt;If you've ever used monad transformers then you've probably already used &lt;tt&gt;MFunctor&lt;/tt&gt;s.  Just check out the instance list for &lt;tt&gt;MFunctor&lt;/tt&gt; and you'll see many familiar names: &lt;pre&gt;&lt;br /&gt;instance MMorph  IdentityT where ...&lt;br /&gt;instance MMorph  MaybeT    where ...&lt;br /&gt;instance MMorph (StateT s) where ...&lt;br /&gt;&lt;/pre&gt;In fact, &lt;tt&gt;transformers&lt;/tt&gt; has been carrying around type-specialized versions of &lt;tt&gt;hoist&lt;/tt&gt; for years: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;mapIdentityT&lt;/tt&gt; is &lt;tt&gt;hoist&lt;/tt&gt; for &lt;tt&gt;IdentityT&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;mapStateT&lt;/tt&gt; is &lt;tt&gt;hoist&lt;/tt&gt; for &lt;tt&gt;StateT&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;mapMaybeT&lt;/tt&gt; is &lt;tt&gt;hoist&lt;/tt&gt; for &lt;tt&gt;MaybeT&lt;/tt&gt;&lt;/ul&gt;&lt;tt&gt;hoist&lt;/tt&gt; provides a standard interface to these functions so that you can program generically over any monad transformer that implements &lt;tt&gt;MFunctor&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;I heard you like monads&lt;/h4&gt;&lt;br /&gt;We can define a higher-order functor that wraps monads, so why not also define a higher-order monad that wraps ... monads?&lt;br /&gt;&lt;br /&gt;It turns out that actually works! &lt;pre&gt;&lt;br /&gt;class MMonad t where&lt;br /&gt;    embed :: (Monad n) =&gt; (m :-&gt; t n) -&gt; (t m :-&gt; t n)&lt;br /&gt;&lt;/pre&gt;Again, judicious renaming of type variables reveals the parallel to the &lt;tt&gt;Monad&lt;/tt&gt; class: &lt;pre&gt;&lt;br /&gt;class MMonad m where&lt;br /&gt;    embed :: (Monad b) =&gt; (a :-&gt; m b) -&gt; (m a :-&gt; m b)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;embed&lt;/tt&gt; is just the higher-order cousin of &lt;tt&gt;(=&lt;&lt;)&lt;/tt&gt;!  Many monad transformers have sensible definitions for &lt;tt&gt;embed&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;instance               MMonad IdentityT   where ...&lt;br /&gt;instance               MMonad MaybeT      where ...&lt;br /&gt;instance (Monoid w) =&gt; MMonad (WriterT w) where ...&lt;br /&gt;&lt;/pre&gt;But wait!  Where is &lt;tt&gt;return&lt;/tt&gt;?  Well, what type would we expect the higher-order &lt;tt&gt;return&lt;/tt&gt; to have? &lt;pre&gt;&lt;br /&gt;??? :: m :-&gt; t m&lt;br /&gt;&lt;/pre&gt;Well, if we expand out the definition of &lt;tt&gt;(:-&gt;)&lt;/tt&gt;, we get: &lt;pre&gt;&lt;br /&gt;??? :: m a -&gt; t m a&lt;br /&gt;&lt;/pre&gt;Why, that is just the signature for &lt;tt&gt;lift&lt;/tt&gt;!&lt;br /&gt;&lt;br /&gt;But it's not enough for it to just have the right shape of type.  If it's really part of a higher-order monad, then &lt;tt&gt;lift&lt;/tt&gt; and &lt;tt&gt;embed&lt;/tt&gt; must obey the monad laws: &lt;pre&gt;&lt;br /&gt;-- m &gt;&gt;= return = m&lt;br /&gt;embed lift m = m&lt;br /&gt;&lt;br /&gt;-- return x &gt;&gt;= f = f x&lt;br /&gt;embed f (lift x) = f x&lt;br /&gt;&lt;br /&gt;-- (m &gt;&gt;= f) &gt;&gt;= g = m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)&lt;br /&gt;embed g (embed f m) = embed (\x -&gt; embed g (f x)) m&lt;br /&gt;&lt;/pre&gt;... and all the &lt;tt&gt;MMonad&lt;/tt&gt; instances do satisfy these laws!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Functor design pattern&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;mmorph&lt;/tt&gt; library represents a concrete example of the &lt;a href="http://www.haskellforall.com/2012/09/the-functor-design-pattern.html"&gt;functor design pattern&lt;/a&gt; in two separate ways.&lt;br /&gt;&lt;br /&gt;First, the monad morphisms themselves define functors that transform Kleisli categories, and the monad morphism laws are actually functor laws: &lt;pre&gt;&lt;br /&gt;morph :: forall a . m a -&gt; n a&lt;br /&gt;&lt;br /&gt;(morph .) (f &gt;=&gt; g) = (morph .) f &gt;=&gt; (morph .) g&lt;br /&gt;&lt;br /&gt;(morph .) return = return&lt;br /&gt;&lt;/pre&gt;... so you can think of a monad morphism as just a principled way to transform one monad into another monad for compatibility purposes.&lt;br /&gt;&lt;br /&gt;Second, the &lt;tt&gt;hoist&lt;/tt&gt; function from &lt;tt&gt;MFunctor&lt;/tt&gt; defines a functor that transforms monad morphisms: &lt;pre&gt;&lt;br /&gt;hoist (f . g) = hoist f . hoist g&lt;br /&gt;&lt;br /&gt;hoist id = id&lt;br /&gt;&lt;/pre&gt;... so you can think of &lt;tt&gt;hoist&lt;/tt&gt; as just a principled way to transform one monad morphism into another monad morphism for compatibility purposes.&lt;br /&gt;&lt;br /&gt;The &lt;tt&gt;mmorph&lt;/tt&gt; library is a concrete example of how functors naturally arise as compatibility layers whenever we encounter impedance mismatch between our tools.  In this case, we have an impedance mismatch between our monad transformers and we use functors to bridge between them so they can seamlessly work together.</description><link>http://www.haskellforall.com/2013/03/mmorph-100-monad-morphisms.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>6</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-3458556845715291786</guid><pubDate>Thu, 14 Feb 2013 16:40:00 +0000</pubDate><atom:updated>2013-03-14T11:34:29.447-07:00</atom:updated><title>Comonads are objects</title><description>Haskell programmers popularized the use of monads to structure imperative computations, complete with syntactic sugar in the form of &lt;tt&gt;do&lt;/tt&gt; notation.  However, category theorists predict that there is also a completely symmetric concept called a "comonad", which tickles our fancy.  After all, if monads are so intriguing, then perhaps comonads are equally intriguing, and who doesn't like twice the intrigue?&lt;br /&gt;&lt;br /&gt;However, there's nothing intriguing about comonads.  In fact, comonads are so pervasive in modern programming that they need no introduction.  I hope to show that you very likely already employ a comonadic programming style, although you probably prefer to call it "object-oriented programming".&lt;br /&gt;&lt;br /&gt;In this post I will build the metaphor of comonads as objects and also introduce syntactic sugar for comonads that strongly motivates this object-oriented interpretation.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Builder Pattern&lt;/h4&gt;&lt;br /&gt;Let's try to reimplement the objected-oriented builder design pattern in Haskell.  For example, let's say that we have a &lt;tt&gt;Config&lt;/tt&gt; value we want to build that just stores a list of program &lt;tt&gt;Option&lt;/tt&gt;s: &lt;pre&gt;&lt;br /&gt;type Option = String&lt;br /&gt;&lt;br /&gt;data Config = MakeConfig [Option] deriving (Show)&lt;br /&gt;&lt;/pre&gt;We want to encapsulate the &lt;tt&gt;Config&lt;/tt&gt; and prevent the user from disassembling it, so we don't export the &lt;tt&gt;MakeConfig&lt;/tt&gt; constructor to prevent the user from pattern matching on the constructor.  Instead, we export a function in place of the constructor so that the user can still create values of type &lt;tt&gt;Config&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;configBuilder :: [Option] -&gt; Config&lt;br /&gt;configBuilder options = MakeConfig options&lt;br /&gt;&lt;br /&gt;-- or: configBuilder = MakeConfig&lt;br /&gt;&lt;/pre&gt;We could also preset certain options ahead of time for the user: &lt;pre&gt;&lt;br /&gt;defaultConfig :: [Option] -&gt; Config&lt;br /&gt;defaultConfig options = MakeConfig (["-Wall"] ++ options)&lt;br /&gt;&lt;/pre&gt;These functions both have the same type: they take a list of &lt;tt&gt;Option&lt;/tt&gt;s and return a &lt;tt&gt;Config&lt;/tt&gt; so let's call any function that has this type a "builder": &lt;pre&gt;&lt;br /&gt;someBuilder :: [Option] -&gt; Config&lt;br /&gt;&lt;/pre&gt;These builders work fine if the user can supply all the options up front, because then we can set the options in one shot: &lt;pre&gt;&lt;br /&gt;profile :: ([Option] -&gt; Config) -&gt; Config&lt;br /&gt;profile builder = builder ["-prof", "-auto-all"]&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; profile defaultConfig&lt;br /&gt;MakeConfig ["-Wall","-prof","-auto-all"]&lt;br /&gt;&lt;/pre&gt;However, our &lt;tt&gt;profile&lt;/tt&gt; option setter uses up our builder and we cannot supply any further options.  For example, I might have another set of options to supply: &lt;pre&gt;&lt;br /&gt;goFaster :: ([Option] -&gt; Config) -&gt; Config&lt;br /&gt;goFaster builder = builder ["-O2"]&lt;br /&gt;&lt;/pre&gt;... but I wouldn't be able to use both &lt;tt&gt;profile&lt;/tt&gt; and &lt;tt&gt;goFaster&lt;/tt&gt; on the same builder.&lt;br /&gt;&lt;br /&gt;In object oriented programming you don't have this problem, because you usually structure your builder to append options instead of setting them so that you can feed in additional options later.  Then you extract the final configuration when you are done: &lt;pre&gt;&lt;br /&gt;builder = new DefaultConfig();  // Begin from default config file&lt;br /&gt;builder.profile();              // Add profiling&lt;br /&gt;builder.goFaster();             // Add optimization&lt;br /&gt;config = builder.extract();     // Extract final config file&lt;br /&gt;&lt;/pre&gt;However, Haskell has no implicit state, so we cannot mutate the original builder like the objected oriented version does.  Even if we could, it's not clear where we would store additional options since our builder is a function, not a record with fields.&lt;br /&gt;&lt;br /&gt;Instead, we must cheat and modify our original functions to return a new builder that "precompiles in" the given options: &lt;pre&gt;&lt;br /&gt;profile'  :: ([Option] -&gt; Config) -&gt; ([Option] -&gt; Config)&lt;br /&gt;profile' builder =&lt;br /&gt;    \options -&gt; builder (["-prof", "-auto-all"] ++ options)&lt;br /&gt;&lt;br /&gt;goFaster' :: ([Option] -&gt; Config) -&gt; ([Option] -&gt; Config)&lt;br /&gt;goFaster' builder =&lt;br /&gt;    \options -&gt; builder (["-O2"] ++ options)&lt;br /&gt;&lt;/pre&gt;We transformed our option setters into option appenders that leave our builder open just like the object-oriented version.  Additionally, we need some sort of &lt;tt&gt;extract&lt;/tt&gt; function that completes the process and returns the final configuration.  That's easy since we can flush the builder by supplying it with an empty option list: &lt;pre&gt;&lt;br /&gt;extract :: ([Option] -&gt; Config) -&gt; Config&lt;br /&gt;extract builder = builder []&lt;br /&gt;&lt;/pre&gt;Finally, we would like to emulate the post-fix function application of objected oriented programming, so we define the following infix operator that simulates calling a method on an object: &lt;pre&gt;&lt;br /&gt;-- (&amp;) is another popular name for this operator&lt;br /&gt;(#) :: a -&gt; (a -&gt; b) -&gt; b&lt;br /&gt;x # f = f x&lt;br /&gt;&lt;br /&gt;infixl 0 #&lt;br /&gt;&lt;/pre&gt;Using our option appenders and &lt;tt&gt;extract&lt;/tt&gt;, we can make a mockery of objected oriented style: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; let builder1 = defaultConfig # profile'&lt;br /&gt;&gt;&gt;&gt; let builder2 = builder1 # goFaster'&lt;br /&gt;&gt;&gt;&gt; builder2 # extract&lt;br /&gt;MakeConfig ["-Wall","-prof","-auto-all","-O2"]&lt;br /&gt;&lt;/pre&gt;However, going back and upgrading all possible option setters into option appenders is a painstaking and laborious process, especially if we already defined a lot of them.  Haskell is a functional language, though, so could we just write a function to automate this upgrade process?&lt;br /&gt;&lt;br /&gt;In other words, we already wrote some option setter that closes the builder when done: &lt;pre&gt;&lt;br /&gt;setter :: ([Option] -&gt; Config) -&gt; Config&lt;br /&gt;&lt;/pre&gt;... but we want to &lt;tt&gt;extend&lt;/tt&gt; that setter to behave like an appender that keeps the builder open: &lt;pre&gt;&lt;br /&gt;extend setter :: ([Option] -&gt; Config) -&gt; ([Option] -&gt; Config)&lt;br /&gt;&lt;/pre&gt;This means that our &lt;tt&gt;extend&lt;/tt&gt; function must have the following overall type: &lt;pre&gt;&lt;br /&gt;extend :: (([Option] -&gt; Config) -&gt;              Config )&lt;br /&gt;       -&gt;  ([Option] -&gt; Config) -&gt; ([Option] -&gt; Config)&lt;br /&gt;&lt;/pre&gt;You might expect that this isn't possible.  After all, option setters seem to irreversibly use up the builder.  However, we can actually cheat by intercepting the &lt;tt&gt;setter&lt;/tt&gt; before applying it to the &lt;tt&gt;builder&lt;/tt&gt; to reserve space for future options: &lt;pre&gt;&lt;br /&gt;extend setter builder =&lt;br /&gt;    \opts2 -&gt; setter (\opts1 -&gt; builder (opts1 ++ opts2))&lt;br /&gt;&lt;/pre&gt;For example, if &lt;tt&gt;setter&lt;/tt&gt; were our &lt;tt&gt;goFaster&lt;/tt&gt; function, then &lt;tt&gt;extend&lt;/tt&gt; would transform it into &lt;tt&gt;goFaster'&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;extend goFaster builder&lt;br /&gt;= \opts2 -&gt; goFaster (\opts1 -&gt; builder (opts1 ++ opts2))&lt;br /&gt;= \opts2 -&gt; builder (["-O2"] ++ opts2)&lt;br /&gt;= goFaster' builder&lt;br /&gt;&lt;br /&gt;-- or: extend goFaster = goFaster'&lt;br /&gt;&lt;/pre&gt;Neat!&lt;br /&gt;&lt;br /&gt;However, all we've proven is that &lt;tt&gt;extend&lt;/tt&gt; works for our &lt;tt&gt;goFaster&lt;/tt&gt; function.  How could we prove that it always works in every possible case?  We might try to write some tests, perhaps by defining some example option setters, upgrading them to appenders, and simulating a few build processes, but these tests would only prove that &lt;tt&gt;extend&lt;/tt&gt; works in those few cases that we tested.  Could we instead prove that &lt;tt&gt;extend&lt;/tt&gt; does the right thing in every conceivable scenario?  Is that even possible?&lt;br /&gt;&lt;br /&gt;Fortunately, Haskell's enforced purity unlocks a more powerful and more general alternative to testing: equational reasoning.  We simply define the expected behavior of our &lt;tt&gt;extend&lt;/tt&gt; function in terms of equations and prove that &lt;tt&gt;extend&lt;/tt&gt; satisfies those equations.  But what might that expected behavior be?&lt;br /&gt;&lt;br /&gt;Well, we expect that if we &lt;tt&gt;extend&lt;/tt&gt; a &lt;tt&gt;setter&lt;/tt&gt; to become an appender, apply it to a &lt;tt&gt;builder&lt;/tt&gt;, and then immediately &lt;tt&gt;extract&lt;/tt&gt; the result, it should behave as if we had directly used the &lt;tt&gt;setter&lt;/tt&gt;.  The equation for that would be: &lt;pre&gt;&lt;br /&gt;extract (extend setter builder) = setter builder&lt;br /&gt;&lt;/pre&gt;In other words, there's no point in &lt;tt&gt;extend&lt;/tt&gt;ing a &lt;tt&gt;setter&lt;/tt&gt; if we plan to &lt;tt&gt;extract&lt;/tt&gt; the result immediately afterwards.&lt;br /&gt;&lt;br /&gt;We can prove our equation because: &lt;pre&gt;&lt;br /&gt;extract (extend setter builder)&lt;br /&gt;&lt;br /&gt;-- Use definition of extend&lt;br /&gt;= extract (\opts2 -&gt; setter (\opts1 -&gt; builder (opts1 ++ opts2)))&lt;br /&gt;&lt;br /&gt;-- Use definition of extract&lt;br /&gt;= (\opts2 -&gt; setter (\opts1 -&gt; builder (opts1 ++ opts2))) []&lt;br /&gt;&lt;br /&gt;-- Apply the function&lt;br /&gt;= setter (\opts1 -&gt; builder (opts1 ++ []))&lt;br /&gt;&lt;br /&gt;-- (opts1 ++ []) = opts1&lt;br /&gt;= setter (\opts1 -&gt; builder opts1)&lt;br /&gt;&lt;br /&gt;-- (\opts1 -&gt; builder opts1) = builder&lt;br /&gt;= setter builder&lt;br /&gt;&lt;/pre&gt;Perfect!&lt;br /&gt;&lt;br /&gt;We might also expect that if we &lt;tt&gt;extend&lt;/tt&gt; the empty option setter (i.e. &lt;tt&gt;extract&lt;/tt&gt;), the resulting appender should not change the builder since &lt;tt&gt;extract&lt;/tt&gt; doesn't supply any options:&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise&lt;/b&gt;: Prove that:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;extend extract builder = builder&lt;br /&gt;&lt;/pre&gt;There's one last property that's really subtle, but important.  If we choose not to &lt;tt&gt;extend&lt;/tt&gt; the second of two setters, we can always go back and &lt;tt&gt;extend&lt;/tt&gt; the second setter later as long as we haven't applied them to the &lt;tt&gt;builder&lt;/tt&gt; yet:&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Challenge exercise:&lt;/b&gt; Prove that: &lt;pre&gt;&lt;br /&gt;s1, s2 :: ([Option] -&gt; Config) -&gt; Config  -- setters&lt;br /&gt;b , b' ::  [Option] -&gt; Config             -- builders&lt;br /&gt;&lt;br /&gt;extend (\b' -&gt; s2 (extend s1 b')) b&lt;br /&gt;= extend s2 (extend s1 b)&lt;br /&gt;&lt;/pre&gt;Interestingly, these three equations suffice to completely describe what it means to convert an option setter into an appender.  We can formulate any other property in terms of those three properties.  This means that we no longer need to test our function at all because we've proven it correct in all possible circumstances.&lt;br /&gt;&lt;br /&gt;For example, we might suppose that if we choose not to &lt;tt&gt;extend&lt;/tt&gt; the &lt;b&gt;third&lt;/b&gt; of three setters, we can always go back and &lt;tt&gt;extend&lt;/tt&gt; the third setter later on as long as we haven't applied them to the builder yet: &lt;pre&gt;&lt;br /&gt;extend (\b' -&gt; s3 (extend s2 (extend s1 b')) b&lt;br /&gt;= extend s3 (extend s2 (extend s1 b))&lt;br /&gt;&lt;/pre&gt;We can derive that property from the proof of the two-setter case: &lt;pre&gt;&lt;br /&gt;extend (\b' -&gt; s3 (extend s2 (extend s1 b')) b&lt;br /&gt;&lt;br /&gt;-- Apply proof in reverse to the two inner stages&lt;br /&gt;= extend (\b' -&gt; s3 (extend (\b'' -&gt; s2 (extend s1 b'')) b') b&lt;br /&gt;&lt;br /&gt;-- Apply proof to the two outer stages&lt;br /&gt;= extend s3 (extend (\b'' -&gt; s2 (extend s1 b'')) b)&lt;br /&gt;&lt;br /&gt;-- Apply proof to the two inner stages&lt;br /&gt;= extend s3 (extend s2 (extend s1 b))&lt;br /&gt;&lt;/pre&gt;In fact, the proof for the two-setter case generalizes to any number of stages.  In other words, if we choose not to &lt;tt&gt;extend&lt;/tt&gt; the last setter in an arbitrarily long chain, we can always go back and &lt;tt&gt;extend&lt;/tt&gt; the last setter later if we haven't applied them to the builder yet.&lt;br /&gt;&lt;br /&gt;You might be surprised to learn that we've inadvertently defined our first comonad in our pursuit of simulating object oriented programming, but it might not be clear what exactly a comonad is or why those three equations are the only equations we need to prove.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Iterator Pattern&lt;/h4&gt;&lt;br /&gt;Now let's imagine that we're writing a new terminal shell, complete with command line history.  We could model history as an infinite iterator that stores events in reverse chronological order: &lt;pre&gt;&lt;br /&gt;data Iterator a = a :&lt; (Iterator a)&lt;br /&gt;&lt;br /&gt;infixr 5 :&lt;&lt;br /&gt;&lt;/pre&gt;The history would start off empty, which we model as an infinite stream of empty commands: &lt;pre&gt;&lt;br /&gt;initialHistory :: Iterator String&lt;br /&gt;initialHistory = "" :&lt; initialHistory&lt;br /&gt;&lt;/pre&gt;... however as the user types in more commands, we expect the history to grow: &lt;pre&gt;&lt;br /&gt;exampleHistory :: Iterator String&lt;br /&gt;exampleHistory =&lt;br /&gt;       "^D"&lt;br /&gt;    :&lt; "^C"&lt;br /&gt;    :&lt; "eat flaming death"&lt;br /&gt;    :&lt; "hello?"&lt;br /&gt;    :&lt; "bye"&lt;br /&gt;    :&lt; "exit"&lt;br /&gt;    :&lt; "quit"&lt;br /&gt;    :&lt; "?"&lt;br /&gt;    :&lt; "help"&lt;br /&gt;    :&lt; "ed"&lt;br /&gt;    :&lt; initialHistory&lt;br /&gt;&lt;/pre&gt;We want a structured way to browse history, so we decide to use the object-oriented iterator pattern.  We first must define a function which &lt;tt&gt;extract&lt;/tt&gt;s the command below the current cursor: &lt;pre&gt;&lt;br /&gt;extract :: Iterator a -&gt; a&lt;br /&gt;extract (cmd :&lt; _) = cmd&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; extract exampleHistory&lt;br /&gt;"^D"&lt;br /&gt;&lt;/pre&gt;Now we need a command to get the &lt;tt&gt;next&lt;/tt&gt; element in the iterator (which is the previous user command, since we're storing commands in reverse chronological order): &lt;pre&gt;&lt;br /&gt;next :: Iterator a -&gt; a&lt;br /&gt;next (_ :&lt; (cmd :&lt; _)) = cmd&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; next exampleHistory&lt;br /&gt;"^C"&lt;br /&gt;&lt;/pre&gt;But what if we want to advance another step?  We can't just write: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; next (next exampleHistory)  -- Type error!&lt;br /&gt;&lt;/pre&gt;Our &lt;tt&gt;next&lt;/tt&gt; command uses up our &lt;tt&gt;Iterator&lt;/tt&gt;, so we cannot proceed to the next step.&lt;br /&gt;&lt;br /&gt;Fortunately, we are not stupid.  We can define a command which shifts the iterator by one step without returning a value: &lt;pre&gt;&lt;br /&gt;next' :: Iterator a -&gt; Iterator a&lt;br /&gt;next' (_ :&lt; iterator) = iterator&lt;br /&gt;&lt;/pre&gt;Now we can get the value two spaces after the cursor by combining a shift and a retrieval: &lt;pre&gt;&lt;br /&gt;next2 :: Iterator a -&gt; a&lt;br /&gt;next2 iterator = next (next' iterator)&lt;br /&gt;&lt;/pre&gt;... which should also be equivalent to shifting twice and extracting the value below the cursor: &lt;pre&gt;&lt;br /&gt;next2 iterator = extract (next' (next' iterator))&lt;br /&gt;&lt;/pre&gt;The latter form starts to resemble an object-oriented approach.  Let's humor ourselves and pretend we are object-oriented programmers for a moment: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; let history1 = exampleHistory # next'&lt;br /&gt;&gt;&gt;&gt; let history2 = history1 # next'&lt;br /&gt;&gt;&gt;&gt; history2 # extract&lt;br /&gt;"eat flaming death"&lt;br /&gt;&lt;/pre&gt;Hmmm.  This would greatly resemble object-oriented style if we didn't have to pass around intermediate states manually...&lt;br /&gt;&lt;br /&gt;What if we define a new retrieval that looks ahead three values? &lt;pre&gt;&lt;br /&gt;next3 :: Iterator a -&gt; a&lt;br /&gt;next3 iterator = next (next' (next' iterator)))&lt;br /&gt;&lt;/pre&gt;Then we'd have to duplicate our function and make a minor change to convert it into a shift: &lt;pre&gt;&lt;br /&gt;next3' :: Iterator a -&gt; Iterator a&lt;br /&gt;next3' iterator = next' (next' (next' iterator)))&lt;br /&gt;&lt;/pre&gt;Duplication with minor changes is a code smell.  I would like these two functions to remain consistent such that &lt;tt&gt;next3'&lt;/tt&gt; always shifts to the value that &lt;tt&gt;next3&lt;/tt&gt; points to, but when I duplicate the code I must manually enforce that consistency between them.  The "Don't Repeat Yourself" principle says you should not duplicate code precisely to avoid this problem.&lt;br /&gt;&lt;br /&gt;Moreover, even the initial duplication could introduce mistakes, such as accidentally deleting one step while modifying the code: &lt;pre&gt;&lt;br /&gt;next3' :: Iterator a -&gt; Iterator a&lt;br /&gt;next3' iterator = next' (next' iterator))&lt;br /&gt;-- Oops!  I deleted the next and my boss&lt;br /&gt;-- distracted me in the middle of the process&lt;br /&gt;-- so I forgot to replace it with next'&lt;br /&gt;&lt;/pre&gt;We'd prefer to automate the conversion process both to avoid introducing errors and to enforce consistency between the two functions.  In other words, I need a function that takes some sort of &lt;tt&gt;retrieval&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;retrieval :: Iterator a -&gt; a&lt;br /&gt;&lt;/pre&gt;... and &lt;tt&gt;extend&lt;/tt&gt;s the retrieval to become the equivalent shift: &lt;pre&gt;&lt;br /&gt;extend retrieval :: Iterator a -&gt; Iterator a&lt;br /&gt;&lt;/pre&gt;... which means that our &lt;tt&gt;extend&lt;/tt&gt; function has type: &lt;pre&gt;&lt;br /&gt;extend :: (Iterator a -&gt;          a)&lt;br /&gt;       -&gt;  Iterator a -&gt; Iterator a&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise:&lt;/b&gt; Write the &lt;tt&gt;extend&lt;/tt&gt; function.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Solution:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;extend f (a :&lt; as) = (f (a :&lt; as)) :&lt; (extend f as)&lt;br /&gt;&lt;br /&gt;-- or using Haskell "as-patterns"&lt;br /&gt;&lt;br /&gt;extend f iter@(_ :&lt; as) = (f iter) :&lt; (extend f as)&lt;br /&gt;&lt;/pre&gt;It's not as straightforward to prove that &lt;tt&gt;extend next&lt;/tt&gt; is equivalent to &lt;tt&gt;next'&lt;/tt&gt;.  We must settle for proving that they produce the same stream of values: &lt;pre&gt;&lt;br /&gt;extend next (_ :&lt; as0@(a1 :&lt; _))&lt;br /&gt;&lt;br /&gt;= next (_ :&lt; as0@(a1 :&lt; _)) :&lt; extend next as1&lt;br /&gt;&lt;br /&gt;= a1 :&lt; (extend next as0)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;-- Now do the same for next'&lt;br /&gt;next' (_ :&lt; as0@(a1 :&lt; _))&lt;br /&gt;&lt;br /&gt;= as0&lt;br /&gt;&lt;br /&gt;= a1 :&lt; (next' as0)&lt;br /&gt;&lt;br /&gt;-- Both functions are of the form:&lt;br /&gt;f (_ :&lt; as0@(a1 :&lt; _) = a1 :&lt; f as0&lt;br /&gt;-- where f is (extend next) or (next')&lt;br /&gt;&lt;br /&gt;-- Therefore we tentatively conclude they are the same stream&lt;br /&gt;extend next iterator = next' iterator&lt;br /&gt;&lt;br /&gt;-- or just:&lt;br /&gt;extend next = next'&lt;br /&gt;&lt;/pre&gt;Boy, that's a lot of effort to prove that &lt;tt&gt;extend&lt;/tt&gt; upgrades one retrieval correctly.  I'd prefer to pick my proofs wisely so that I can prove that &lt;tt&gt;extend&lt;/tt&gt; upgrades &lt;b&gt;all&lt;/b&gt; retrievals correctly.  But what proofs suffice to nail down what it means to convert a retrieval into a shift?&lt;br /&gt;&lt;br /&gt;Well, I expect that if I upgrade a &lt;tt&gt;retrieval&lt;/tt&gt; into a shift, apply the shift, then &lt;tt&gt;extract&lt;/tt&gt; the value under the cursor, I should get the same value as if I had just used the retrieval directly:&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise:&lt;/b&gt; Prove that: &lt;pre&gt;&lt;br /&gt;extract (extend retrieval iterator) = retrieval iterator&lt;br /&gt;&lt;/pre&gt;This proof is simple and requires no fancy tricks.&lt;br /&gt;&lt;br /&gt;Since &lt;tt&gt;extract&lt;/tt&gt; points to the current location, I expect the equivalent shift to not move the iterator at all: &lt;pre&gt;&lt;br /&gt;extend extract iterator = iterator&lt;br /&gt;&lt;/pre&gt;I'll do this one: &lt;pre&gt;&lt;br /&gt;extend extract (a :&lt; as)&lt;br /&gt;&lt;br /&gt;= (extract (a :&lt; as)) :&lt; (extend extract as)&lt;br /&gt;&lt;br /&gt;= a :&lt; (extend extract as)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;-- Haskell's 'id' function produces the same stream:&lt;br /&gt;id a = a&lt;br /&gt;&lt;br /&gt;id (a :&lt; as)&lt;br /&gt;&lt;br /&gt;= a :&lt; (id as)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;-- Both functions are of the form:&lt;br /&gt;f (a :&lt; as) = a :&lt; (f as)&lt;br /&gt;-- where f is (extend extract) or (id)&lt;br /&gt;&lt;br /&gt;-- Therefore we tentatively conclude they are the same stream:&lt;br /&gt;extend extract iterator = id iterator = iterator&lt;br /&gt;&lt;br /&gt;-- or just:&lt;br /&gt;extend extract = id&lt;br /&gt;&lt;/pre&gt;Again, there's one last non-trivial property.  If I choose not to &lt;tt&gt;extend&lt;/tt&gt; the second of two retrievals, I can still &lt;tt&gt;extend&lt;/tt&gt; the second retrieval later if I haven't applied both of them to an iterator yet:&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Challenge Exercise:&lt;/b&gt; Prove that: &lt;pre&gt;&lt;br /&gt;r1, r2 :: Iterator a -&gt; a  -- retrievals&lt;br /&gt;i , i' :: Iterator a       -- iterators&lt;br /&gt;&lt;br /&gt;extend (\i' -&gt; r2 (extend r1 i')) i&lt;br /&gt;= extend r2 (extend r1 i)&lt;br /&gt;&lt;/pre&gt;Notice how we arrived at the exact same three equations, despite solving two completely unrelated problems.  Something very deep seems to lie just beneath the surface.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Command Pattern&lt;/h4&gt;&lt;br /&gt;Now imagine that we are trying to build a small DSL for manipulating a thermostat.  The thermostat keeps an internal floating point temperature in Kelvin, which it presents to the user as a string representation in Celsius.  The thermostat comes with a simple API: &lt;ul&gt;&lt;li&gt; Increment the temperature by one degree &lt;li&gt; Decrement the temperature by one degree &lt;/ul&gt;This is the classic text-book example of objected-oriented design where we have some object that maintains state and methods on that object.  Unfortunately, we're gluttons for punishment and choose to implement this solution in Haskell, one of the most decidedly anti-object-oriented languages in existence.&lt;br /&gt;&lt;br /&gt;We choose to model our thermostat as a pair of values: &lt;ul&gt;&lt;li&gt; The internal representation of temperature, in Kelvin &lt;li&gt; A function that reads out the temperature into various representations &lt;/ul&gt;The Haskell type for that would be: &lt;pre&gt;&lt;br /&gt;-- Use a newtype so we don't accidentally mix differerent&lt;br /&gt;-- representations of temperature&lt;br /&gt;newtype Kelvin = Kelvin { getKelvin :: Double }&lt;br /&gt;&lt;br /&gt;-- The thermostat type:&lt;br /&gt;(Kelvin, Kelvin -&gt; a)&lt;br /&gt;-- 'a' is the readout type, which may vary&lt;br /&gt;&lt;/pre&gt;We can define an initial state for our thermostat that begins with a readout that converts the internal temperature in &lt;tt&gt;Kelvin&lt;/tt&gt; to &lt;tt&gt;Celsius&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;newtype Celsius = Celsius { getCelsius :: Double }&lt;br /&gt;    deriving (Show)&lt;br /&gt;&lt;br /&gt;kelvinToCelsius :: Kelvin -&gt; Celsius&lt;br /&gt;kelvinToCelsius (Kelvin t) = Celsius (t - 273.15)&lt;br /&gt;&lt;br /&gt;initialThermostat :: (Kelvin, Kelvin -&gt; Celsius)&lt;br /&gt;initialThermostat = (298.15, kelvinToCelsius)&lt;br /&gt;&lt;/pre&gt;We can always query the readout at any time using a function called &lt;tt&gt;extract&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;extract :: (Kelvin, Kelvin -&gt; a) -&gt; a&lt;br /&gt;extract (t, f) = f t&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; extract initialThermostat&lt;br /&gt;25.0&lt;br /&gt;&lt;/pre&gt;Our client is not the sharpest crayon in the box, so we have to also provide an API for previewing changes in temperature before we make them: &lt;pre&gt;&lt;br /&gt;up :: (Kelvin, Kelvin -&gt; a) -&gt; a&lt;br /&gt;up (t, f) = f (t + 1)&lt;br /&gt;&lt;br /&gt;down :: (Kelvin, Kelvin -&gt; a) -&gt; a&lt;br /&gt;down (t, f) = f (t - 1)&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; up initialThermostat&lt;br /&gt;Celsius { getCelsius :: 26.0 }&lt;br /&gt;&gt;&gt;&gt; down initialThermostat&lt;br /&gt;Celsius { getCelsius :: 24.0 }&lt;br /&gt;&lt;/pre&gt;Similarly we can define a function to convert the current temperature into a user-friendly string: &lt;pre&gt;&lt;br /&gt;toString :: (Kelvin, Kelvin -&gt; Celsius) -&gt; String&lt;br /&gt;toString (t, f) = show (getCelsius (f t)) ++ " Celsius"&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; toString initialThermostat&lt;br /&gt;25.0 Celsius&lt;br /&gt;&lt;/pre&gt;But if what if I want to convert the previews into user-friendly strings?  This won't type-check: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; toString (up initialThermostat)  -- Type error&lt;br /&gt;&lt;/pre&gt;Instead, we must define adjustment functions that modify the internal temperature of the thermostat: &lt;pre&gt;&lt;br /&gt;up' :: (Kelvin, Kelvin -&gt; a) -&gt; (Kelvin, Kelvin -&gt; a)&lt;br /&gt;up' (t, f) = (t + 1, f)&lt;br /&gt;&lt;br /&gt;down' :: (Kelvin, Kelvin -&gt; a) -&gt; (Kelvin, Kelvin -&gt; a)&lt;br /&gt;down' (t, f) = (t - 1, f)&lt;br /&gt;&lt;/pre&gt;Now we can simulate an object-oriented API for interacting with the thermostat: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; thermostat1 = initialThermostat # up'&lt;br /&gt;&gt;&gt;&gt; thermostat2 = thermostat1 # up'&lt;br /&gt;&gt;&gt;&gt; toString thermostat2&lt;br /&gt;27.0 Celsius&lt;br /&gt;&lt;/pre&gt;However, there's a potential source of bugs in this approach.  When a user selects a given preview, nothing requires us to apply an adjustment that matches the preview.  We can only enforce this by being sufficiently diligent programmers.  Wouldn't it be nice, though, if we could eliminate an entire class of bugs by automatically converting the preview into the correct corresponding adjustment?&lt;br /&gt;&lt;br /&gt;In other words, we have a preview function: &lt;pre&gt;&lt;br /&gt;preview :: (Kelvin, Kelvin -&gt; a) -&gt; b&lt;br /&gt;&lt;/pre&gt;... and we want to &lt;tt&gt;extend&lt;/tt&gt; it to behave like the corresponding adjustment function: &lt;pre&gt;&lt;br /&gt;extend preview :: (Kelvin, Kelvin -&gt; a) -&gt; (Kelvin, Kelvin -&gt; b)&lt;br /&gt;&lt;/pre&gt;... which means that &lt;tt&gt;extend&lt;/tt&gt; has type: &lt;pre&gt;&lt;br /&gt;extend :: ((Kelvin, Kelvin -&gt; a) -&gt;                    b)&lt;br /&gt;       -&gt;  (Kelvin, Kelvin -&gt; a) -&gt; (Kelvin, Kelvin -&gt; b)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise:&lt;/b&gt; Write the &lt;tt&gt;extend&lt;/tt&gt; function.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Solution:&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;extend preview (t, f) = (t, \t' -&gt; preview (t', f))&lt;br /&gt;&lt;/pre&gt;If we apply &lt;tt&gt;extend&lt;/tt&gt; to &lt;tt&gt;up&lt;/tt&gt;, it should give us &lt;tt&gt;up'&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;extend up (t, f)&lt;br /&gt;&lt;br /&gt;-- Apply definition of 'extend'&lt;br /&gt;= (t, \t' -&gt; up (t', f))&lt;br /&gt;&lt;br /&gt;-- Apply definition of 'up'&lt;br /&gt;= (t, \t' -&gt; f (t' + 1))&lt;br /&gt;&lt;/pre&gt;Wait, what's this?  This doesn't match the definition of &lt;tt&gt;up'&lt;/tt&gt; at all: &lt;pre&gt;&lt;br /&gt;up' (t, f) = (t + 1, f)&lt;br /&gt;&lt;/pre&gt;Which one is the "right" version?  Well, we can decide which implementation is the correct one by specifying the desired behavior in the form of equations, and then seeing which implementation satisfies the equations.&lt;br /&gt;&lt;br /&gt;We first expect that if you &lt;tt&gt;extract&lt;/tt&gt; the result of an adjustment, it should match the corresponding &lt;tt&gt;preview&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise:&lt;/b&gt; Prove that: &lt;pre&gt;&lt;br /&gt;extract (extend preview thermostat) = preview thermostat&lt;br /&gt;&lt;/pre&gt;Both &lt;tt&gt;extend up&lt;/tt&gt; and &lt;tt&gt;up'&lt;/tt&gt; satisfy this criterion, so we can't yet say which one is correct.&lt;br /&gt;&lt;br /&gt;We also expect that if you &lt;tt&gt;extend&lt;/tt&gt; a preview of the current state (i.e. &lt;tt&gt;extract&lt;/tt&gt;) to become an adjustment, then this adjustment should do nothing.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Exercise:&lt;/b&gt; Prove that: &lt;pre&gt;&lt;br /&gt;extend extract thermostat = thermostat&lt;br /&gt;&lt;/pre&gt;This criterion doesn't apply to any previews other than &lt;tt&gt;extract&lt;/tt&gt;, so we can't use it to select between &lt;tt&gt;extend up&lt;/tt&gt; and &lt;tt&gt;up'&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;This leaves us with our final equation: If you combine an adjustment and preview, you can &lt;tt&gt;extend&lt;/tt&gt; the pair of them into an adjustment, which should be identical to &lt;tt&gt;extend&lt;/tt&gt;ing the preview alone.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Challenge Exercise&lt;/b&gt;: Prove that: &lt;pre&gt;&lt;br /&gt;p1, p2 :: (Kelvin, Kelvin -&gt; a) -&gt; b&lt;br /&gt;t , t' :: (Kelvin, Kelvin -&gt; a)&lt;br /&gt;&lt;br /&gt;extend (\t' -&gt; p2 (extend p1 t')) t&lt;br /&gt;= extend p2 (extend p1 t')&lt;br /&gt;&lt;/pre&gt;This proves to be the acid test that eliminates our original implementation of &lt;tt&gt;up'&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Challenge Exercise:&lt;/b&gt; Prove that our original implementation of &lt;tt&gt;up'&lt;/tt&gt; does not play nice with &lt;tt&gt;extend&lt;/tt&gt;.  In other words, find a counter-example that proves the following equation &lt;b&gt;false&lt;/b&gt;: &lt;pre&gt;&lt;br /&gt;extend (\t' -&gt; p (up' t')) t = extend p (up' t)&lt;br /&gt;&lt;/pre&gt;&lt;b&gt;Challenge Exercise:&lt;/b&gt; What bug does the above counter-example predict may happen when you mix &lt;tt&gt;extend&lt;/tt&gt; with &lt;tt&gt;up'&lt;/tt&gt;?&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Comonads&lt;/h4&gt;&lt;br /&gt;At this point, we've tackled three separate object-oriented problems and in all three of them we define an &lt;tt&gt;extract&lt;/tt&gt; and &lt;tt&gt;extend&lt;/tt&gt; function that seem very similar across all three cases.  We already know that these two functions always seem to obey the same set of equations, despite having very different types in each case.&lt;br /&gt;&lt;br /&gt;However, we can squint a little bit and realize that the types are not as different as they initially seem.  Define: &lt;pre&gt;&lt;br /&gt;type Builder a = [Option] -&gt; a&lt;br /&gt;&lt;br /&gt;-- Keep 'Iterator' as is&lt;br /&gt;&lt;br /&gt;type Thermostat a = (Kelvin, Kelvin -&gt; a)&lt;br /&gt;&lt;/pre&gt;Using these type synonyms, we can rewrite the type signature for all three &lt;tt&gt;extract&lt;/tt&gt; functions: &lt;pre&gt;&lt;br /&gt;extract :: Builder a -&gt; a&lt;br /&gt;&lt;br /&gt;extract :: Iterator a -&gt; a&lt;br /&gt;&lt;br /&gt;extract :: Thermostat a -&gt; a&lt;br /&gt;&lt;/pre&gt;Also, it turns out that the type signatures for our &lt;tt&gt;extend&lt;/tt&gt; functions were too specialized.  We could actually generalize them to the following more polymorphic types with no change to the code: &lt;pre&gt;&lt;br /&gt;extend :: (Builder a -&gt; b) -&gt; Builder a -&gt; Builder b&lt;br /&gt;&lt;br /&gt;extend :: (Iterator a -&gt; b) -&gt; Iterator a -&gt; Iterator b&lt;br /&gt;&lt;br /&gt;extend :: (Thermostat a -&gt; b) -&gt; Thermostat a -&gt; Thermostat b&lt;br /&gt;&lt;/pre&gt;In each case, we defined some type constructor &lt;tt&gt;w&lt;/tt&gt; and two functions: &lt;pre&gt;&lt;br /&gt;extract :: w a -&gt; a&lt;br /&gt;&lt;br /&gt;extend :: (w a -&gt; b) -&gt; w a -&gt; w b&lt;br /&gt;&lt;/pre&gt;The combination of &lt;tt&gt;w&lt;/tt&gt;, &lt;tt&gt;extract&lt;/tt&gt;, and &lt;tt&gt;extend&lt;/tt&gt; is a comonad.  The equations we've been proving are known as the "comonad laws".&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Comonad laws&lt;/h4&gt;&lt;br /&gt;Why do we always seem to come across the same set of equations each time?  Well, we can get a clue if we define a derived operator in terms of &lt;tt&gt;extend&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;(f =&gt;= g) w = g (extend f w)&lt;br /&gt;&lt;/pre&gt;This operator has the nice property that &lt;tt&gt;extract&lt;/tt&gt; is both its left and right identity: &lt;pre&gt;&lt;br /&gt;extract =&gt;= f = f&lt;br /&gt;&lt;br /&gt;f =&gt;= extract = f&lt;br /&gt;&lt;/pre&gt;Also, this operator is associative: &lt;pre&gt;&lt;br /&gt;(f =&gt;= g) =&gt;= h = f =&gt;= (g =&gt;= h)&lt;br /&gt;&lt;/pre&gt;In other words, comonads form a category, specifically a "CoKleisli" category, where &lt;tt&gt;(=&gt;=)&lt;/tt&gt; is the associative composition operator for the category and &lt;tt&gt;extract&lt;/tt&gt; is the identity of this composition.  The comonad laws are nothing more than the category laws in disguise.&lt;br /&gt;&lt;br /&gt;If you take the last three equations and substitute in the definition of &lt;tt&gt;(=&gt;=)&lt;/tt&gt;, you will derive the same three comonad laws we have repeatedly proven.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Object-oriented programming&lt;/h4&gt;&lt;br /&gt;Every time we try to implement object-oriented programming in Haskell we gravitate, inexorably, to modeling objects as comonads.  This suggests that object-oriented programming and comonadic programming are one and the same.  Haskell programmers have struggled with comonads because we so militantly rejected object-oriented programming.&lt;br /&gt;&lt;br /&gt;This means we should approach object oriented programming with humility instead of disdain and borrow object-oriented insight to devise a suitable syntactic sugar for programming with comonads.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Syntactic sugar for comonads&lt;/h4&gt;&lt;br /&gt;The object-oriented intuition for comonads suggests the syntactic sugar for comonads, which I call &lt;tt&gt;method&lt;/tt&gt; notation.&lt;br /&gt;&lt;br /&gt;Given the following &lt;tt&gt;method&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;method&lt;br /&gt;    wa&gt; expr1&lt;br /&gt;    wb&gt; expr2&lt;br /&gt;    wc&gt; expr3&lt;br /&gt;&lt;/pre&gt;... this desugars to: &lt;pre&gt;&lt;br /&gt;   \wa -&gt;&lt;br /&gt;let wb =      extend (\this -&gt; expr1) wa&lt;br /&gt;    wc =      extend (\this -&gt; expr2) wb&lt;br /&gt; in extract $ extend (\this -&gt; expr3) wc&lt;br /&gt;&lt;/pre&gt;We can simplify the last line because of the comonad laws: &lt;pre&gt;&lt;br /&gt;   \wa -&gt;&lt;br /&gt;let wb =      extend (\this -&gt; expr1) wa&lt;br /&gt;    wc =      extend (\this -&gt; expr2) wb&lt;br /&gt; in                  (\this -&gt; expr3) wc&lt;br /&gt;&lt;/pre&gt;In other words, &lt;tt&gt;method&lt;/tt&gt; notation &lt;tt&gt;extend&lt;/tt&gt;s every function except the last one.  This is also equivalent to &lt;tt&gt;extend&lt;/tt&gt;ing all of them and &lt;tt&gt;extract&lt;/tt&gt;ing the result.&lt;br /&gt;&lt;br /&gt;You can also leave out the bound variables on the left, which simply does not bring them into scope: &lt;pre&gt;&lt;br /&gt;method&lt;br /&gt;    expr1&lt;br /&gt;    expr2&lt;br /&gt;    expr3&lt;br /&gt;=&lt;br /&gt;   \_wa -&gt;&lt;br /&gt;let _wb =      extend (\this -&gt; expr1) _wa&lt;br /&gt;    _wc =      extend (\this -&gt; expr2) _wb&lt;br /&gt;in  extract  $ extend (\this -&gt; expr3) _wc&lt;br /&gt;&lt;/pre&gt;Using the latter form, the configuration file example becomes: &lt;pre&gt;&lt;br /&gt;config :: Config&lt;br /&gt;config = defaultConfig # method&lt;br /&gt;    this # profile   -- no apostrophes, these are setters&lt;br /&gt;    this # goFaster&lt;br /&gt;&lt;/pre&gt;This desugars to: &lt;pre&gt;&lt;br /&gt;config = defaultConfig # \_b0 -&gt;&lt;br /&gt;    let _b1 =     extend (\this -&gt; this # profile ) _b0&lt;br /&gt;    in  extract $ extend (\this -&gt; this # goFaster) _b1&lt;br /&gt;&lt;br /&gt;-- equivalent to:&lt;br /&gt;config = defaultConfig # \_b0 -&gt;&lt;br /&gt;    let _b1 = extend profile _b0&lt;br /&gt;     in goFaster _b1&lt;br /&gt;&lt;br /&gt;-- which reduces to:&lt;br /&gt;config = goFaster (extend profile defaultConfig)&lt;br /&gt;&lt;/pre&gt;Notice how it looks like we are declaring an anonymous &lt;tt&gt;method&lt;/tt&gt; and immediately invoking it on the &lt;tt&gt;defaultConfig&lt;/tt&gt; object.  Also, we only use setters and yet the &lt;tt&gt;method&lt;/tt&gt; does "the right thing" and does not &lt;tt&gt;extend&lt;/tt&gt; the last setter, as if we were returning the last line directly.&lt;br /&gt;&lt;br /&gt;The iterator example works equally well: &lt;pre&gt;&lt;br /&gt;next3 :: Iterator a -&gt; a&lt;br /&gt;next3 = method&lt;br /&gt;    this # next  -- Move one step forward&lt;br /&gt;    this # next  -- Move another step forward&lt;br /&gt;    this # next  -- Return the next value&lt;br /&gt;&lt;br /&gt;-- desugars to:&lt;br /&gt;next3 =&lt;br /&gt;      \_i0 -&gt;&lt;br /&gt;    let i1 =      extend (\this -&gt; this # next) _i0&lt;br /&gt;        i2 =      extend (\this -&gt; this # next)  i1&lt;br /&gt;        extract $ extend (\this -&gt; this # next)  i2&lt;br /&gt;&lt;br /&gt;-- which reduces to:&lt;br /&gt;next3 = \i -&gt; next (extend next (extend next i))&lt;br /&gt;&lt;/pre&gt;Here we are declaring &lt;tt&gt;next3&lt;/tt&gt; as if it were part of a class definition.  &lt;tt&gt;method&lt;/tt&gt; notation implicitly makes it a function of the corresponding object and brings &lt;tt&gt;this&lt;/tt&gt; into scope, which always implicitly refers to the current state of the object.&lt;br /&gt;&lt;br /&gt;If we want to refer to previous states, we just bring the intermediate steps into scope using the "prompt" notation: &lt;pre&gt;&lt;br /&gt;next123 :: Iterator a -&gt; [a]&lt;br /&gt;next123 = method&lt;br /&gt;        this # next&lt;br /&gt;    i1&gt; this # next&lt;br /&gt;    i2&gt; this # next&lt;br /&gt;    i3&gt; [i1 # extract, i2 # extract, i3 # extract]&lt;br /&gt;&lt;br /&gt;-- desugars to:&lt;br /&gt;next123 =&lt;br /&gt;      \_i0 -&gt;&lt;br /&gt;    let i1 =      extend (\this -&gt; this # next) _i0&lt;br /&gt;        i2 =      extend (\this -&gt; this # next)  i1&lt;br /&gt;        i3 =      extend (\this -&gt; this # next)  i2&lt;br /&gt;     in extract $ extend (\this -&gt;&lt;br /&gt;            [i1 # extract, i2 # extract, i3 # extract]) i3&lt;br /&gt;&lt;br /&gt;-- which reduces to:&lt;br /&gt;next123 = \_i0 -&gt;&lt;br /&gt;    [ next _i0&lt;br /&gt;    , next (extend next _i0)&lt;br /&gt;    , next (extend next (extend next i0))&lt;br /&gt;    ]&lt;br /&gt;&lt;/pre&gt;The above &lt;tt&gt;method&lt;/tt&gt; returns the next three elements of the iterator, using the intermediate steps in the traversal.  If we want to call it, we use it just like an object-oriented method: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; exampleHistory # next123&lt;br /&gt;["^C","eat flaming death","hello?"]&lt;br /&gt;&lt;/pre&gt;More over, &lt;tt&gt;method&lt;/tt&gt;s automatically do "the right thing" if you use them within other &lt;tt&gt;method&lt;/tt&gt;s: &lt;pre&gt;&lt;br /&gt;next123456 :: Iterator a -&gt; [a]&lt;br /&gt;next123456 = method&lt;br /&gt;          this # next123&lt;br /&gt;    w123&gt; this # next123&lt;br /&gt;    w456&gt; (w123 # extract) ++ (w456 # extract)&lt;br /&gt;&lt;br /&gt;-- desugars to:&lt;br /&gt;next123456 =&lt;br /&gt;       \_w0 -&gt;&lt;br /&gt;    let w123 =    extend (\this -&gt; this # next123) _w0&lt;br /&gt;        w456 =    extend (\this -&gt; this # next123) w123&lt;br /&gt;     in extract # extend (\this -&gt;&lt;br /&gt;            (w123 # extract) ++ (w456 # extract)) w456&lt;br /&gt;&lt;br /&gt;-- which reduces to:&lt;br /&gt;next123456 = \_w0 -&gt;&lt;br /&gt;    next123 _w0 ++ next123 (extend next123 _w0)&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; exampleHistory # next123456&lt;br /&gt;["^C","eat flaming death","hello?","bye","exit","quit"]&lt;br /&gt;&lt;/pre&gt;We don't have to carefully keep track of whether or not we should use them as accessors or "mutators".  &lt;tt&gt;method&lt;/tt&gt; notation automatically gets that correct for us.&lt;br /&gt;&lt;br /&gt;Notice the duality with &lt;tt&gt;do&lt;/tt&gt; notation and monads.  With monads, unwrapped variables are scarce since we can irreversibly convert them to wrapped values, so &lt;tt&gt;do&lt;/tt&gt; notation keeps them in scope as long as possible.  With comonads, wrapped variables are scarce since we can irreversibly convert them to unwrapped values, so &lt;tt&gt;method&lt;/tt&gt; notation keeps them in scope for as long as possible.&lt;br /&gt;&lt;br /&gt;Our thermostat example looks just like the classic object-oriented example using &lt;tt&gt;method&lt;/tt&gt; notation, except we don't need to say &lt;tt&gt;return&lt;/tt&gt; at the end as &lt;tt&gt;method&lt;/tt&gt; notation always implicitly returns the value of the last line: &lt;pre&gt;&lt;br /&gt;up2 :: Thermostat Celsius -&gt; String&lt;br /&gt;up2 = method&lt;br /&gt;    this # up&lt;br /&gt;    this # up&lt;br /&gt;    this # toString&lt;br /&gt;&lt;br /&gt;-- desugars to:&lt;br /&gt;up2 =  \_th0 -&gt;&lt;br /&gt;    let _th1 =    extend (\this -&gt; this # up      ) _th0&lt;br /&gt;        _th2 =    extend (\this -&gt; this # up      ) _th1&lt;br /&gt;     in extract $ extend (\this -&gt; this # toString) _th2&lt;br /&gt;&lt;br /&gt;-- which reduces to:&lt;br /&gt;up2 = \_th0 -&gt; toString (extend up (extend up _th0))&lt;br /&gt;&lt;/pre&gt;You can even return the object itself, just by returning &lt;tt&gt;this&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;up2' :: Thermostat Celsius -&gt; Thermostat Celsius&lt;br /&gt;up2' = method&lt;br /&gt;    this # up&lt;br /&gt;    this # up&lt;br /&gt;    this&lt;br /&gt;&lt;br /&gt;up2 :: Thermostat Celsius -&gt; String&lt;br /&gt;up2 th = toString (th # up2')&lt;br /&gt;&lt;/pre&gt;If we inline the definition of &lt;tt&gt;up2'&lt;/tt&gt; back into &lt;tt&gt;up2&lt;/tt&gt;, we get: &lt;pre&gt;&lt;br /&gt;up2 w = toString (w # method&lt;br /&gt;    this # up&lt;br /&gt;    this # up&lt;br /&gt;    this)&lt;br /&gt;&lt;/pre&gt;Any function we apply to an invoked &lt;tt&gt;method&lt;/tt&gt; can be converted to a post-fix application: &lt;pre&gt;&lt;br /&gt;toString (w # method&lt;br /&gt;    this # up&lt;br /&gt;    this # up&lt;br /&gt;    this)&lt;br /&gt;= (w # method&lt;br /&gt;    this  # up&lt;br /&gt;    this  # up&lt;br /&gt;    this) # toString&lt;br /&gt;&lt;/pre&gt;Observe how suggestive the notation is.  When we use post-fix syntax, we can just remove the parentheses and it is still correct: &lt;pre&gt;&lt;br /&gt;(w # method&lt;br /&gt;    this  # up&lt;br /&gt;    this  # up&lt;br /&gt;    this) # toString&lt;br /&gt;= w # method&lt;br /&gt;    this  # up&lt;br /&gt;    this  # up&lt;br /&gt;    this  # toString&lt;br /&gt;&lt;/pre&gt;The post-fix application style plays incredibly nicely with &lt;tt&gt;method&lt;/tt&gt; syntax, even though I never designed it for that purpose.  This suggests that the object-oriented tendency towards post-fix function application style falls out naturally from the comonadic style and is not just a quirk of object-oriented tradition.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Comonad laws&lt;/h4&gt;&lt;br /&gt;The acid test of syntactic sugar is that the notation promotes an intuition for the comonad laws.  Let's write the comonad laws using &lt;tt&gt;method&lt;/tt&gt; notation: &lt;pre&gt;&lt;br /&gt;extract (extend f w) = f w&lt;br /&gt;&lt;br /&gt;w # method          = w # method&lt;br /&gt;    this # f              this # f&lt;br /&gt;    this # extract&lt;br /&gt;&lt;/pre&gt;This law says that there's no need to "re-&lt;tt&gt;extract&lt;/tt&gt;" the current context at the end.  &lt;tt&gt;method&lt;/tt&gt; notation already does that for you. &lt;pre&gt;&lt;br /&gt;f (extend extract w) = f w&lt;br /&gt;&lt;br /&gt;w # method          = w # method&lt;br /&gt;    this # extract        this # f&lt;br /&gt;    this # f&lt;br /&gt;&lt;/pre&gt;All &lt;tt&gt;extract&lt;/tt&gt; commands are no-ops within a &lt;tt&gt;method&lt;/tt&gt; block since they point to our current location.&lt;br /&gt;&lt;br /&gt;This leaves us with the final comonad law: &lt;pre&gt;&lt;br /&gt;  h (extend (\w' -&gt; g (extend f w')) w)&lt;br /&gt;= h (extend g (extend f w))&lt;br /&gt;&lt;/pre&gt;I'll do the intermediate translation steps for this law since they are illuminating.  All we have to remember is that: &lt;pre&gt;&lt;br /&gt;extend f w&lt;br /&gt;&lt;br /&gt;= w # method&lt;br /&gt;    this # f&lt;br /&gt;    this&lt;br /&gt;&lt;/pre&gt;Using that, we can mechanically derive both sides of the equation: &lt;pre&gt;&lt;br /&gt;-- Left-hand side:&lt;br /&gt;h (extend (\w' -&gt; g (extend f w')) w)&lt;br /&gt;= h (w # method&lt;br /&gt;    this # \w' -&gt; g (extend f w')&lt;br /&gt;    this )&lt;br /&gt;= w # method&lt;br /&gt;    this # \w' -&gt; g (extend f w')&lt;br /&gt;    this # h&lt;br /&gt;= w # method&lt;br /&gt;    g (extend f this)&lt;br /&gt;    this # h&lt;br /&gt;= w # method&lt;br /&gt;    g (this # method&lt;br /&gt;        this # f&lt;br /&gt;        this )&lt;br /&gt;    this # h&lt;br /&gt;= w # method&lt;br /&gt;    this # method&lt;br /&gt;        this # f&lt;br /&gt;        this # g&lt;br /&gt;    this # h&lt;br /&gt;&lt;br /&gt;-- Right-hand side&lt;br /&gt;h (extend g (extend f w))&lt;br /&gt;= h (extend f w # method&lt;br /&gt;    this # g&lt;br /&gt;    this )&lt;br /&gt;= extend f w # method&lt;br /&gt;    this # g&lt;br /&gt;    this # h&lt;br /&gt;= (w # method&lt;br /&gt;    this   # f&lt;br /&gt;    this ) # method&lt;br /&gt;        this # g&lt;br /&gt;        this # h&lt;br /&gt;= w # method&lt;br /&gt;    this # f&lt;br /&gt;    this # method&lt;br /&gt;        this # g&lt;br /&gt;        this # h&lt;br /&gt;&lt;/pre&gt;Placing them side by side gives: &lt;pre&gt;&lt;br /&gt;w # method         = w # method&lt;br /&gt;    this # method        this # f&lt;br /&gt;        this # f         this # method&lt;br /&gt;        this # g             this # g&lt;br /&gt;    this # h                 this # h&lt;br /&gt;&lt;/pre&gt;... and like &lt;tt&gt;do&lt;/tt&gt; notation, we can flatten both forms to a single normal form: &lt;pre&gt;&lt;br /&gt;= w # method&lt;br /&gt;    this # f&lt;br /&gt;    this # g&lt;br /&gt;    this # h&lt;br /&gt;&lt;/pre&gt;The notation suggests quite naturally that if you call a &lt;tt&gt;method&lt;/tt&gt; on &lt;tt&gt;this&lt;/tt&gt;, it's equivalent to inlining the &lt;tt&gt;method&lt;/tt&gt; directly.  Conversely, you can arbitrarily factor out any group of steps into their own &lt;tt&gt;method&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Comonad transformers&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;do&lt;/tt&gt; notation has the nice property that it promotes the correct intuition for the monad transformer laws, where the &lt;tt&gt;lift&lt;/tt&gt; distributes over the &lt;tt&gt;do&lt;/tt&gt; block: &lt;pre&gt;&lt;br /&gt;lift $ do x &lt;- m  = do x &lt;- lift m&lt;br /&gt;          f x          lift (f x)&lt;br /&gt;&lt;br /&gt;lift (return x) = return x&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;method&lt;/tt&gt; notation also promotes the correct intuition for comonad transformers where &lt;tt&gt;lower&lt;/tt&gt; similarly distributes over &lt;tt&gt;method&lt;/tt&gt; blocks: &lt;pre&gt;&lt;br /&gt;w # lower # method = w # method&lt;br /&gt;    this # f           this # lower # f&lt;br /&gt;    this # g           this # lower # g&lt;br /&gt;&lt;br /&gt;w # lower # extract = w # extract&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;Object-oriented programming is the long-lost comonadic programming that Haskell programmers have been searching for.  Comonads are "object-oriented programming done right".&lt;br /&gt;&lt;br /&gt;Monads and &lt;tt&gt;do&lt;/tt&gt; notation transformed the face of Haskell by turning it into the finest imperative programming language.  I believe that comonads and &lt;tt&gt;method&lt;/tt&gt; notation may similarly transform Haskell into the finest object-oriented language as well.</description><link>http://www.haskellforall.com/2013/02/you-could-have-invented-comonads.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>20</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-8269676736848909488</guid><pubDate>Mon, 21 Jan 2013 20:42:00 +0000</pubDate><atom:updated>2013-02-04T15:32:00.451-08:00</atom:updated><title>Introduction to Haskell IO</title><description>I fell in love with Haskell neither because of types nor functional programming.  Rather, I admired Haskell's beautiful approach to I/O and I hope that after reading this you will, too.  I'm writing this &lt;tt&gt;IO&lt;/tt&gt; tutorial to underscore Haskell's simplicity and consistency.&lt;br /&gt;&lt;br /&gt;If you want to follow along, download the &lt;a href="http://www.haskell.org/platform/"&gt;Haskell Platform&lt;/a&gt;, which provides a Haskell compiler (&lt;tt&gt;ghc&lt;/tt&gt;) and Haskell interpreter (&lt;tt&gt;ghci&lt;/tt&gt;).&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Hello, world!&lt;/h4&gt;&lt;br /&gt;Let's begin from the simplest possible Haskell program: &lt;pre&gt;&lt;br /&gt;main = putStrLn "Hello, world"&lt;br /&gt;&lt;/pre&gt;If you save the above program to &lt;tt&gt;example.hs&lt;/tt&gt;, you can compile and run it using: &lt;pre&gt;&lt;br /&gt;$ ghc -O2 example.hs  # '-O2' is a good habit to learn&lt;br /&gt;[1 of 1] Compiling Main             ( example.hs, example.o )&lt;br /&gt;Linking example ...&lt;br /&gt;$ ./example&lt;br /&gt;Hello, world!&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Types - Part 1&lt;/h4&gt;&lt;br /&gt;All Haskell values have types, but we usually don't need to supply any type signatures because the compiler can mechanically deduce the types for us.&lt;br /&gt;&lt;br /&gt;This means we can ask the &lt;tt&gt;ghci&lt;/tt&gt; Haskell interpreter to infer the types of arbitrary Haskell expressions.  Let's fire up &lt;tt&gt;ghci&lt;/tt&gt; so we can ask for the types of the values we used: &lt;pre&gt;&lt;br /&gt;$ ghci&lt;br /&gt;GHCi, version 7.4.1: http://www.haskell.org/ghc/  :? for help&lt;br /&gt;Loading package ghc-prim ... linking ... done.&lt;br /&gt;Loading package integer-gmp ... linking ... done.&lt;br /&gt;Loading package base ... linking ... done.&lt;br /&gt;Prelude&gt; &lt;br /&gt;&lt;/pre&gt;Let's start off with something simple.  What is the type of &lt;tt&gt;"Hello, world!"&lt;/tt&gt;? &lt;pre&gt;&lt;br /&gt;Prelude&gt; :type "Hello, world!"&lt;br /&gt;"Hello, world!" :: [Char]&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;ghci&lt;/tt&gt; says that &lt;tt&gt;"Hello, world!"&lt;/tt&gt;'s type is &lt;tt&gt;[Char]&lt;/tt&gt;, which means "a list of characters".  &lt;tt&gt;Char&lt;/tt&gt; is the type of a single character and the brackets around &lt;tt&gt;Char&lt;/tt&gt; mean "list of".&lt;br /&gt;&lt;br /&gt;Wait, shouldn't it be a &lt;tt&gt;String&lt;/tt&gt;?  Actually, &lt;tt&gt;String&lt;/tt&gt; is just a type synonym for &lt;tt&gt;[Char]&lt;/tt&gt;, and we can verify that using &lt;tt&gt;ghci&lt;/tt&gt;'s &lt;tt&gt;:info&lt;/tt&gt; command: &lt;pre&gt;&lt;br /&gt;Prelude&gt; :info String&lt;br /&gt;type String = [Char]    -- Defined in `GHC.Base'&lt;br /&gt;&lt;/pre&gt;That means that we can use &lt;tt&gt;String&lt;/tt&gt; or &lt;tt&gt;[Char]&lt;/tt&gt; interchangeably in types.  They are equal.&lt;br /&gt;&lt;br /&gt;Now let's study the type of &lt;tt&gt;putStrLn&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;Prelude&gt; :t putStrLn  -- You can use ":t" instead of ":type"&lt;br /&gt;putStrLn :: String -&gt; IO ()&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;putStrLn&lt;/tt&gt; is a function that takes a single argument of type &lt;tt&gt;String&lt;/tt&gt; and produces a value of type &lt;tt&gt;IO ()&lt;/tt&gt;.  The &lt;tt&gt;IO ()&lt;/tt&gt; signifies an executable action that returns a value of type &lt;tt&gt;()&lt;/tt&gt;.  In this case, the action just print the given &lt;tt&gt;String&lt;/tt&gt;, and &lt;tt&gt;putStrLn&lt;/tt&gt; is just a mnemonic for "&lt;tt&gt;put&lt;/tt&gt; &lt;tt&gt;Str&lt;/tt&gt;ing with new&lt;tt&gt;L&lt;/tt&gt;i&lt;tt&gt;n&lt;/tt&gt;e.&lt;br /&gt;&lt;br /&gt;All &lt;tt&gt;IO&lt;/tt&gt; actions must return a value, so Haskell programmers return &lt;tt&gt;()&lt;/tt&gt; when they have nothing useful to return.  This exactly mirrors how imperative programmers mark a function &lt;tt&gt;void&lt;/tt&gt; when they don't return anything useful.  For example, if we were to translate &lt;tt&gt;putStrLn&lt;/tt&gt;'s type to other languages, it would look like: &lt;pre&gt;&lt;br /&gt;// C&lt;br /&gt;void putStrLn(char *str)&lt;br /&gt;&lt;br /&gt;// Java&lt;br /&gt;public static void putStrLn(String str)&lt;br /&gt;&lt;/pre&gt;We can ask &lt;tt&gt;ghci&lt;/tt&gt; about the types of expressions, too: &lt;pre&gt;&lt;br /&gt;Prelude&gt; :t putStrLn "Hello, world!"&lt;br /&gt;putStrLn "Hello, world!" :: IO ()&lt;br /&gt;&lt;/pre&gt;This tells us what we already knew: when we supply &lt;tt&gt;putStrLn&lt;/tt&gt; with a &lt;tt&gt;String&lt;/tt&gt; argument we get an executable &lt;tt&gt;IO&lt;/tt&gt; action which will print the supplied &lt;tt&gt;String&lt;/tt&gt;.  All of this so far is very straight-forward and we haven't deviated yet from traditional programming languages.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Equality&lt;/h4&gt;&lt;br /&gt;Now let's compare our original program side-by-side with equivalent &lt;tt&gt;main&lt;/tt&gt; functions in imperative languages: &lt;pre&gt;&lt;br /&gt;-- Haskell&lt;br /&gt;main = putStrLn "Hello, world!"&lt;br /&gt;&lt;br /&gt;// C (non-standards-conformant, to simplify the comparison)&lt;br /&gt;void main() {&lt;br /&gt;    printf("Hello, world!");&lt;br /&gt;}&lt;br /&gt;&lt;br /&gt;// Java&lt;br /&gt;public static void main(String[] args) {&lt;br /&gt;    System.out.println("Hello, world!");&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;One difference should stand out: the Haskell version does not use traditional block syntax for defining the &lt;tt&gt;main&lt;/tt&gt; function.  Instead it uses the equals sign, which may seems quite curious to imperative eyes.&lt;br /&gt;&lt;br /&gt;It turns out that Haskell takes equality very seriously.  When you write: &lt;pre&gt;&lt;br /&gt;x = 5&lt;br /&gt;&lt;/pre&gt;... you simply declare &lt;tt&gt;x&lt;/tt&gt; to be synonymous with &lt;tt&gt;5&lt;/tt&gt;.  You cannot change the value of &lt;tt&gt;x&lt;/tt&gt; any more than you can change the value of the number &lt;tt&gt;5&lt;/tt&gt;.  &lt;tt&gt;x&lt;/tt&gt; and &lt;tt&gt;5&lt;/tt&gt; become completely interchangeable since they both refer to the same thing.  They are equal.&lt;br /&gt;&lt;br /&gt;So when we write: &lt;pre&gt;&lt;br /&gt;main = putStrLn "Hello, world!"&lt;br /&gt;&lt;/pre&gt;... all that says is that &lt;tt&gt;main&lt;/tt&gt; is nothing more than a synonym for &lt;tt&gt;putStrLn "Hello, world!"&lt;/tt&gt;.  Therefore, they must have the same type and we can prove this by loading our program into &lt;tt&gt;ghci&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;$ ghci example.hs&lt;br /&gt;GHCi, version 7.4.1: http://www.haskell.org/ghc/  :? for help&lt;br /&gt;Loading package ghc-prim ... linking ... done.&lt;br /&gt;Loading package integer-gmp ... linking ... done.&lt;br /&gt;Loading package base ... linking ... done.&lt;br /&gt;Ok, modules loaded: Main.&lt;br /&gt;Prelude Main&gt; :t putStrLn "Hello, world!"&lt;br /&gt;putStrLn "Hello, world!" :: IO ()&lt;br /&gt;Prelude Main&gt; :t main&lt;br /&gt;main :: IO ()&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Types - Part 2&lt;/h4&gt;&lt;br /&gt;Haskell has one and only one rule for what constitutes a valid &lt;tt&gt;main&lt;/tt&gt;: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;main&lt;/tt&gt; must have type &lt;tt&gt;IO a&lt;/tt&gt; (where &lt;tt&gt;a&lt;/tt&gt; may be any return value) &lt;/ul&gt;That's it!&lt;br /&gt;&lt;br /&gt;Anything of type &lt;tt&gt;IO a&lt;/tt&gt; is executable, and that rule ensures that &lt;tt&gt;main&lt;/tt&gt; is executable.  If I define &lt;tt&gt;main&lt;/tt&gt; to be something non-executable, I get a type error:&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;main = 'A'&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ ghc -O2 example.hs&lt;br /&gt;[1 of 1] Compiling Main             ( example.hs, example.o )&lt;br /&gt;&lt;br /&gt;example.hs:1:1:&lt;br /&gt;    Couldn't match expected type `IO t0' with actual type `Char'&lt;br /&gt;    In the expression: main&lt;br /&gt;    When checking the type of the function `main'&lt;br /&gt;&lt;/pre&gt;The compiler tells us that a &lt;tt&gt;Char&lt;/tt&gt; is not executable, which makes sense!  Notice that we rejected the above &lt;tt&gt;main&lt;/tt&gt; not on the basis of syntax or grammar, but solely on the basis of its type.  The type alone communicates whether or not something is executable.  If something has type is &lt;tt&gt;IO a&lt;/tt&gt;, then it is executable.  If something does not have type &lt;tt&gt;IO a&lt;/tt&gt;, then it is not executable.&lt;br /&gt;&lt;br /&gt;Wait... How does &lt;tt&gt;main&lt;/tt&gt; do more than one thing, then?  &lt;tt&gt;putStrLn "Hello, world"&lt;/tt&gt; has type &lt;tt&gt;IO ()&lt;/tt&gt;, so does that mean that it uses up all of &lt;tt&gt;main&lt;/tt&gt;'s "executable juice"?  Not at all!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;do&lt;/tt&gt; notation&lt;/h4&gt;&lt;br /&gt;Haskell lets you combine multiple &lt;tt&gt;IO&lt;/tt&gt; actions into a single &lt;tt&gt;IO&lt;/tt&gt; action using &lt;tt&gt;do&lt;/tt&gt; notation.  I'll introduce the following two functions to demonstrate this: &lt;pre&gt;&lt;br /&gt;getLine  :: IO String        -- I read one line from stdin&lt;br /&gt;putStrLn :: String -&gt; IO ()  -- We've met&lt;br /&gt;&lt;/pre&gt;We can feed the &lt;tt&gt;String&lt;/tt&gt; return value of &lt;tt&gt;getLine&lt;/tt&gt; into &lt;tt&gt;putStrLn&lt;/tt&gt; using &lt;tt&gt;do&lt;/tt&gt; notation: &lt;pre&gt;&lt;br /&gt;main = do str &lt;- getLine&lt;br /&gt;          putStrLn str&lt;br /&gt;&lt;/pre&gt;Haskell also supports semicolons and braces for those who don't like significant whitespace: &lt;pre&gt;&lt;br /&gt;main = do {&lt;br /&gt;    str &lt;- getLine;&lt;br /&gt;    putStrLn str;&lt;br /&gt;}&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;do&lt;/tt&gt; notation combines these two &lt;tt&gt;IO&lt;/tt&gt; actions into a single &lt;tt&gt;IO&lt;/tt&gt; action.  This combined action prompts the user for one line of input and then echoes it back.  Let's try it! &lt;pre&gt;&lt;br /&gt;$ ./example&lt;br /&gt;Test&amp;lt;Enter&amp;gt;&lt;br /&gt;Test&lt;br /&gt;&lt;/pre&gt;We can also sequence two &lt;tt&gt;IO&lt;/tt&gt; actions like this: &lt;pre&gt;&lt;br /&gt;main = do putStrLn "Hello,"&lt;br /&gt;          putStrLn "world!"&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;./example&lt;br /&gt;Hello,&lt;br /&gt;world!&lt;br /&gt;&lt;/pre&gt;We can combine as many actions as we please: &lt;pre&gt;&lt;br /&gt;main = do putStrLn "Enter a string:"&lt;br /&gt;          str &lt;- getLine&lt;br /&gt;          putStrLn str&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ ./example&lt;br /&gt;Enter a string:&lt;br /&gt;Apple&amp;lt;Enter&amp;gt;&lt;br /&gt;Apple&lt;br /&gt;&lt;/pre&gt;Our &lt;tt&gt;do&lt;/tt&gt; block only lets us combine &lt;tt&gt;IO&lt;/tt&gt; commands, though.  If we attempt to insert a non-&lt;tt&gt;IO&lt;/tt&gt; statement, we get a type error: &lt;pre&gt;&lt;br /&gt;main = do putStrLn "Enter a string:"&lt;br /&gt;          str &lt;- getLine&lt;br /&gt;          "Hello"&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;example.hs:3:11:&lt;br /&gt;    Couldn't match expected type `IO b0' with actual type `[Char]'&lt;br /&gt;    In a stmt of a 'do' block: "Hello"&lt;br /&gt;    In the expression:&lt;br /&gt;      do { putStrLn "Enter a string:";&lt;br /&gt;           str &lt;- getLine;&lt;br /&gt;           "Hello" }&lt;br /&gt;    In an equation for `main':&lt;br /&gt;        main&lt;br /&gt;          = do { putStrLn "Enter a string:";&lt;br /&gt;                 str &lt;- getLine;&lt;br /&gt;                 "Hello" }&lt;br /&gt;&lt;/pre&gt;The first line says it all.  The &lt;tt&gt;do&lt;/tt&gt; block expected another executable command on the last line, but we gave it a &lt;tt&gt;String&lt;/tt&gt;, which isn't executable.  That's a pretty reasonable type error if you ask me.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Types - Part 3&lt;/h4&gt;&lt;br /&gt;Haskell has one and only one rule for deciding if a &lt;tt&gt;do&lt;/tt&gt; block is valid: &lt;pre&gt;&lt;br /&gt;-- Given:&lt;br /&gt;m :: IO a&lt;br /&gt;f :: a -&gt; IO b&lt;br /&gt;&lt;br /&gt;-- Then the following 'do' block is valid&lt;br /&gt;block :: IO b  -- This must match the return value of 'f'&lt;br /&gt;block = do a &lt;- m&lt;br /&gt;           f a&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;do&lt;/tt&gt; blocks are first class expressions in Haskell.  Like all expressions, we can ask for &lt;tt&gt;ghci&lt;/tt&gt; for their type:  &lt;pre&gt;&lt;br /&gt;Prelude&gt; :t do { str &lt;- getLine; putStrLn str; }&lt;br /&gt;do { str &lt;- getLine; putStrLn str; } :: IO ()&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;putStrLn str&lt;/tt&gt; was the last action and it's type is &lt;tt&gt;IO ()&lt;/tt&gt;, so according to the rule the whole block has the same type: &lt;tt&gt;IO ()&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Now, why on earth should a &lt;tt&gt;do&lt;/tt&gt; block have a return value at all?  That would only make sense if we could use a &lt;tt&gt;do&lt;/tt&gt; block within another &lt;tt&gt;do&lt;/tt&gt; block.  Does that work? &lt;pre&gt;&lt;br /&gt;main = do str &lt;- do putStrLn "Enter a string:"&lt;br /&gt;                    getLine&lt;br /&gt;          putStrLn str&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ ./example&lt;br /&gt;Enter a string:&lt;br /&gt;Apple&amp;lt;Enter&amp;gt;&lt;br /&gt;Apple&lt;br /&gt;&lt;/pre&gt;Huh.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;do&lt;/tt&gt; blocks use the same return value as their last command because they actually return the last command's value if you bind them within a larger &lt;tt&gt;do&lt;/tt&gt; block.  In the above example, the inner &lt;tt&gt;do&lt;/tt&gt; block forwards the &lt;tt&gt;String&lt;/tt&gt; returned by &lt;tt&gt;getLine&lt;/tt&gt; to the outer &lt;tt&gt;do&lt;/tt&gt; block, and that &lt;tt&gt;String&lt;/tt&gt; is bound to the &lt;tt&gt;str&lt;/tt&gt; variable.&lt;br /&gt;&lt;br /&gt;This approach maintains consistency in the face of refactorings.  Let's define a synonym for the inner &lt;tt&gt;do&lt;/tt&gt; block so we can refer to it by name: &lt;pre&gt;&lt;br /&gt;main = do str &lt;- prompt&lt;br /&gt;          putStrLn str&lt;br /&gt;&lt;br /&gt;prompt :: IO String&lt;br /&gt;prompt = do putStrLn "Enter a string:"&lt;br /&gt;            getLine&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;prompt&lt;/tt&gt;'s type signature is entirely for our own benefit.  Remember that the compiler can deduce the type mechanically.  Haskell programmers still like to include these type signatures to organize their thoughts or to clearly communicate their code's intention to other programmers.  &lt;tt&gt;prompt&lt;/tt&gt;'s type signature tells other programmers "This is an executable action that retrieves a &lt;tt&gt;String&lt;/tt&gt;".&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Impurity&lt;/h4&gt;&lt;br /&gt;Notice how we don't use the equals sign when we store the result of &lt;tt&gt;IO&lt;/tt&gt; actions.  Instead we use the &lt;tt&gt;&lt;-&lt;/tt&gt; symbol: &lt;pre&gt;&lt;br /&gt;main = do str &lt;- prompt&lt;br /&gt;          ...&lt;br /&gt;&lt;/pre&gt;That's because &lt;tt&gt;str&lt;/tt&gt; is not truly equal to &lt;tt&gt;prompt&lt;/tt&gt;.  In fact, they don't even have the same type.  &lt;tt&gt;str&lt;/tt&gt; has type &lt;tt&gt;String&lt;/tt&gt; and &lt;tt&gt;prompt&lt;/tt&gt; has type &lt;tt&gt;IO String&lt;/tt&gt;.  When we mark something as &lt;tt&gt;IO a&lt;/tt&gt;, we communicate that its result may change each time we bind its result within a &lt;tt&gt;do&lt;/tt&gt; block.&lt;br /&gt;&lt;br /&gt;That is obvious in the case of &lt;tt&gt;prompt&lt;/tt&gt; since the user may enter a different string each time: &lt;pre&gt;&lt;br /&gt;main = do str1 &lt;- prompt&lt;br /&gt;          putStrLn str1&lt;br /&gt;          str2 &lt;- prompt&lt;br /&gt;          putStrLn str2&lt;br /&gt;&lt;br /&gt;prompt :: IO String&lt;br /&gt;prompt = do putStrLn "Enter a string:"&lt;br /&gt;            getLine&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;Enter a string:&lt;br /&gt;String 1&lt;br /&gt;String 1&lt;br /&gt;Enter a string:&lt;br /&gt;String 2&lt;br /&gt;String 2&lt;br /&gt;&lt;/pre&gt;However, notice that we still use the equal sign when defining &lt;tt&gt;prompt&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;prompt :: IO String&lt;br /&gt;prompt = do putStrLn "Enter a string:"&lt;br /&gt;            getLine&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;prompt&lt;/tt&gt; is truly equal to that executable action, which seems strange.  How does that reconcile with what I just said?&lt;br /&gt;&lt;br /&gt;It turns out that Haskell distinguishes between an executable program and the program's return value, a distinction that almost no other language makes.  A value of type &lt;tt&gt;IO a&lt;/tt&gt; is an executable program that retrieves an &lt;tt&gt;a&lt;/tt&gt;, possibly with side effects, but the program itself is not the same as its return value.  So if &lt;tt&gt;getLine&lt;/tt&gt; has type &lt;tt&gt;IO String&lt;/tt&gt;, that means that &lt;tt&gt;getLine&lt;/tt&gt; is an executable program that knows how to retrieve a &lt;tt&gt;String&lt;/tt&gt;.  It does not mean that &lt;tt&gt;getLine&lt;/tt&gt; is a &lt;tt&gt;String&lt;/tt&gt;&lt;br /&gt;&lt;br /&gt;When I say &lt;tt&gt;prompt&lt;/tt&gt; equals the given &lt;tt&gt;do&lt;/tt&gt; block, I mean that they are equal in the sense that they are the same program.  Since they are equal I can freely substitute one for the other.  For example, I can go back and substitute the &lt;tt&gt;do&lt;/tt&gt; block in place of &lt;tt&gt;prompt&lt;/tt&gt; and trust that this substitution does not change anything: &lt;pre&gt;&lt;br /&gt;main = do str1 &lt;- do putStrLn "Enter a string:"&lt;br /&gt;                     getLine&lt;br /&gt;          putStrLn str1&lt;br /&gt;          str2 &lt;- do putStrLn "Enter a string:"&lt;br /&gt;                     getLine&lt;br /&gt;          putStrLn str2&lt;br /&gt;&lt;/pre&gt;This means that &lt;tt&gt;do&lt;/tt&gt; notation does not actually do any computation.  All it does is combine program descriptions into larger program descriptions.  The compiler then translates the &lt;tt&gt;main&lt;/tt&gt; program description into an executable.&lt;br /&gt;&lt;br /&gt;This might seem like a trivial distinction at first until you realize that this allows you to separate your program into two parts: &lt;ul&gt;&lt;li&gt; The part you reason about at compile-time (i.e. non-&lt;tt&gt;IO&lt;/tt&gt; code) &lt;li&gt; The part you reason about at run-time (i.e. &lt;tt&gt;IO&lt;/tt&gt; code) &lt;/ul&gt;The more you factor your program into non-&lt;tt&gt;IO&lt;/tt&gt; code, the more of your program that you can prove is correct at compile time, which means that no run-time circumstances will ever break it.&lt;br /&gt;&lt;br /&gt;With traditional programming languages, all code only exists at run-time (i.e. it is all &lt;tt&gt;IO&lt;/tt&gt; code by default), so you can never be entirely sure that it is truly correct.  No matter how many tests you write, all you can prove to yourself is that a certain run-time snapshot of your program happens to be in a correct state.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Associativity&lt;/h4&gt;&lt;br /&gt;Haskell guarantees the following property of all &lt;tt&gt;IO&lt;/tt&gt; programs: &lt;pre&gt;&lt;br /&gt;-- Given:&lt;br /&gt;m :: IO a&lt;br /&gt;f :: a -&gt; IO b&lt;br /&gt;g :: b -&gt; IO c&lt;br /&gt;&lt;br /&gt;  do b &lt;- do a &lt;- m&lt;br /&gt;             f a&lt;br /&gt;     g b&lt;br /&gt;&lt;br /&gt;= do a &lt;- m&lt;br /&gt;     b &lt;- f a&lt;br /&gt;     g b&lt;br /&gt;&lt;br /&gt;= do a &lt;- m&lt;br /&gt;     do b &lt;- f a&lt;br /&gt;        g b&lt;br /&gt;&lt;/pre&gt;In other words, the program's behavior does not change no matter how you group &lt;tt&gt;IO&lt;/tt&gt; actions.  They will still always execute in the same order and preserve the same flow of information.&lt;br /&gt;&lt;br /&gt;This guarantees that we can always safely refactor arbitrary code blocks without worrying that we will get weird behavior as a result of creating or removing blocks.  Using the above example, I could choose to factor out the first two actions: &lt;pre&gt;&lt;br /&gt;block12 = do a &lt;- m&lt;br /&gt;             f a&lt;br /&gt;&lt;br /&gt;block123 = do b &lt;- block12&lt;br /&gt;              g b&lt;br /&gt;&lt;/pre&gt;... or I can factor out the last two actions: &lt;pre&gt;&lt;br /&gt;block23 a = do b &lt;- f a&lt;br /&gt;               g b&lt;br /&gt;&lt;br /&gt;block123 = do a &lt;- m&lt;br /&gt;              block23 a&lt;br /&gt;&lt;/pre&gt;I can similarly trust that "unfactoring" things is safe and won't cause weird behavior.  In other words, I can inline the two refactored blocks safely and trust that it produces the same program: &lt;pre&gt;&lt;br /&gt;block123 = do a &lt;- m&lt;br /&gt;              b &lt;- f a&lt;br /&gt;              g b&lt;br /&gt;&lt;/pre&gt;Notice that all these programs are all truly equal, which is why we use the equal sign when we say they are the same.  This is an example of how we reason about correctness at compile time.  We can't reason about the specific values of &lt;tt&gt;a&lt;/tt&gt;, &lt;tt&gt;b&lt;/tt&gt;, and &lt;tt&gt;c&lt;/tt&gt; because they do not exist until run-time, but the program descriptions themselves exist at compile time, so we can statically reason about their correctness and prove that certain transformations are correct.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Identity&lt;/h4&gt;&lt;br /&gt;What if we want to create a "trivial" program that just returns a value without any side effects?  That's what the &lt;tt&gt;return&lt;/tt&gt; function does: &lt;pre&gt;&lt;br /&gt;return :: a -&gt; IO a&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;return&lt;/tt&gt; takes a value and then defines a trivial program that has no side effects and just returns the given value.&lt;br /&gt;&lt;br /&gt;Note that it does not behave like the traditional &lt;tt&gt;return&lt;/tt&gt; command in imperative languages.  It does not escape from the surrounding block because Haskell &lt;tt&gt;do&lt;/tt&gt; notation has no concept of a "surrounding block".  If it did, all the transformations I gave in the last section would not be correct.  More generally, &lt;tt&gt;return&lt;/tt&gt; does not affect control flow in any way.  All it does is create an "empty" program that yields a value.  That's it.&lt;br /&gt;&lt;br /&gt;We call it &lt;tt&gt;return&lt;/tt&gt; because we commonly use it as the last statement in a &lt;tt&gt;do&lt;/tt&gt; block to combine the results of several previous &lt;tt&gt;IO&lt;/tt&gt; actions: &lt;pre&gt;&lt;br /&gt;twoStrings :: IO (String, String)&lt;br /&gt;twoStrings = do str1 &lt;- getLine&lt;br /&gt;                str2 &lt;- getLine&lt;br /&gt;                return (str1, str2)&lt;br /&gt;&lt;/pre&gt;Other than that, it bears no resemblance to traditional &lt;tt&gt;return&lt;/tt&gt;s.&lt;br /&gt;&lt;br /&gt;What equalities might we expect &lt;tt&gt;return&lt;/tt&gt; to satisfy?  Well, we expect that: &lt;pre&gt;&lt;br /&gt;do x &lt;- m&lt;br /&gt;   return x&lt;br /&gt;&lt;br /&gt;= do m&lt;br /&gt;&lt;/pre&gt;In other words, there is no need to "re-&lt;tt&gt;return&lt;/tt&gt;" the last action's value, because &lt;tt&gt;do&lt;/tt&gt; notation already does that.&lt;br /&gt;&lt;br /&gt;We also expect that: &lt;pre&gt;&lt;br /&gt;do y &lt;- return x&lt;br /&gt;   f y&lt;br /&gt;&lt;br /&gt;= do f x&lt;br /&gt;&lt;/pre&gt;This just formalizes what I already said: &lt;tt&gt;return&lt;/tt&gt; is an empty program that just binds the same value that you gave it.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Ordering&lt;/h4&gt;&lt;br /&gt;Now let's define two programs that retrieve input from the outside world: &lt;pre&gt;&lt;br /&gt;getLine :: IO String  -- Provided by the Prelude&lt;br /&gt;&lt;br /&gt;getInt :: IO Int&lt;br /&gt;getInt = do str &lt;- getLine&lt;br /&gt;            return (read str)&lt;br /&gt;&lt;/pre&gt;... and then a function designed to use both of those values: &lt;pre&gt;&lt;br /&gt;f :: String -&gt; Int -&gt; IO ()&lt;br /&gt;f str n = do&lt;br /&gt;    if (n &gt; 0)&lt;br /&gt;        then putStrLn "n is positive"&lt;br /&gt;        else putStrLn "n is not positive"&lt;br /&gt;    putStrLn str&lt;br /&gt;&lt;/pre&gt;New Haskell programmers will commonly make the following mistake: &lt;pre&gt;&lt;br /&gt;main = f getLine getInt&lt;br /&gt;&lt;/pre&gt;... which the compiler will promptly correct: &lt;pre&gt;&lt;br /&gt;example.hs:12:10:&lt;br /&gt;    Couldn't match expected type `String' with actual type `IO String'&lt;br /&gt;    In the first argument of `f', namely `getLine'&lt;br /&gt;    In the expression: f getLine getInt&lt;br /&gt;    In an equation for `main': main = f getLine getInt&lt;br /&gt;&lt;/pre&gt;Imperative programmers make this mistake because imperative languages let them write: &lt;pre&gt;&lt;br /&gt;f(getLine(), getInt())&lt;br /&gt;&lt;/pre&gt;... and the imperative compiler doesn't mind that you passed an impure function as an argument because imperative languages don't distinguish between the side effects and their result.&lt;br /&gt;&lt;br /&gt;The imperative approach may seem acceptable until you ask yourself the question: "Which function will prompt the user first: &lt;tt&gt;getLine()&lt;/tt&gt; or &lt;tt&gt;getInt()&lt;/tt&gt;?  Typically an imperative language will evaluate the arguments in order, first evaluating &lt;tt&gt;getLine&lt;/tt&gt; followed by &lt;tt&gt;getInt&lt;/tt&gt;.  However, this evaluation order is entirely arbitrary and requires extending the language definition.&lt;br /&gt;&lt;br /&gt;In fact, most imperative programmers would probably consider the above imperative example "bad form".  We'd rather make the ordering more explicit by writing: &lt;pre&gt;&lt;br /&gt;str = getLine(); // First prompt the user for a string&lt;br /&gt;n   = getInt();  // Now prompt the user for an int&lt;br /&gt;f(str, n);       // Now use both values&lt;br /&gt;&lt;/pre&gt;Haskell differs from imperative languages by forcing you to explicitly specify the order of all computations with side effects, so that there is never any ambiguity.  Haskell forces us to write: &lt;pre&gt;&lt;br /&gt;main = do str &lt;- getLine&lt;br /&gt;          n   &lt;- getInt&lt;br /&gt;          f str n&lt;br /&gt;&lt;/pre&gt;In other words, Haskell requires imperative best practices by forcing the programmer to order all side effects and not rely on any implicit ordering by the language.  This improves the readability of Haskell code because you can always reason about the order of side effects: a &lt;tt&gt;do&lt;/tt&gt; block guarantees that side effects always order from top to bottom.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Miscellany&lt;/h4&gt;&lt;br /&gt;Haskell prides itself on being an orthogonal language.  Almost all concepts are just syntactic sugar on just a few core concepts.  This section just describes a few last syntactic niceties that Haskell provides that build entirely on top of the previous concepts.&lt;br /&gt;&lt;br /&gt;First off, when we sequence two commands: &lt;pre&gt;&lt;br /&gt;do command1&lt;br /&gt;   command2&lt;br /&gt;&lt;/pre&gt;... that is just equivalent to discarding the result of the first action: &lt;pre&gt;&lt;br /&gt;do _ &lt;- command1&lt;br /&gt;   command2&lt;br /&gt;&lt;/pre&gt;Also, a &lt;tt&gt;do&lt;/tt&gt; block with one command is just equal to that command: &lt;pre&gt;&lt;br /&gt;main = do putStrLn "Hello, world!"&lt;br /&gt;&lt;br /&gt;-- is equivalent to:&lt;br /&gt;&lt;br /&gt;main = putStrLn "Hello, world!"&lt;br /&gt;&lt;/pre&gt;Finally, you can define pure computations within a &lt;tt&gt;do&lt;/tt&gt; block using &lt;tt&gt;let&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;do let x = y&lt;br /&gt;   f x&lt;br /&gt;&lt;br /&gt;= do f y&lt;br /&gt;&lt;/pre&gt;For example: &lt;pre&gt;&lt;br /&gt;main = do&lt;br /&gt;    str &lt;- getLine&lt;br /&gt;    let response = "You entered: " ++ str&lt;br /&gt;    putStrLn response&lt;br /&gt;&lt;br /&gt;{- equivalent to:&lt;br /&gt;main = do&lt;br /&gt;    str &lt;- getLine&lt;br /&gt;    putStrLn ("You entered: " ++ str)&lt;br /&gt;-}&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ ./example&lt;br /&gt;Orange&amp;lt;Enter&amp;gt;&lt;br /&gt;You entered: Orange&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;Actually, all of that is just the tip of the iceberg because &lt;tt&gt;do&lt;/tt&gt; notation is also just syntactic sugar!  If you want to learn more about that, then I recommend you read &lt;a href="http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html"&gt;You Could Have Invented Monads&lt;/a&gt;, which explains how &lt;tt&gt;do&lt;/tt&gt; notation itself is built on top of an even more primitive core concept.  The more you learn Haskell, the more you realize how it is just a bunch of syntactic sugar on a very small core of orthogonal concepts.</description><link>http://www.haskellforall.com/2013/01/introduction-to-haskell-io.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>16</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-3473494703624315947</guid><pubDate>Tue, 15 Jan 2013 04:01:00 +0000</pubDate><atom:updated>2013-01-15T08:39:58.913-08:00</atom:updated><title>pipes-safe-1.0 - Resource management and exception handling for pipes</title><description>I promised in &lt;tt&gt;pipes-3.0&lt;/tt&gt; that I would release a resource management library for &lt;tt&gt;pipes&lt;/tt&gt; and now I'm delivering on that promise.  &lt;tt&gt;pipes-safe&lt;/tt&gt; extends &lt;tt&gt;pipes&lt;/tt&gt; with resource management and exception handling.  Here are the big highlights that I want to emphasize: &lt;ul&gt;&lt;li&gt; You can now lazily manage resources and conserve handles &lt;li&gt; The library also adds exception handling, meaning that you can catch and resume from any exception within a pipeline &lt;li&gt; &lt;tt&gt;pipes-safe&lt;/tt&gt; interoperates cleanly with existing unmanaged &lt;tt&gt;pipes&lt;/tt&gt; code. &lt;li&gt; The central code is reasonably simple and many people should be able to read the source and reason about its safety &lt;/ul&gt;As always, check out &lt;a href="http://hackage.haskell.org/packages/archive/pipes-safe/1.0.0/doc/html/Control-Proxy-Safe-Tutorial.html"&gt;the tutorial&lt;/a&gt; if you want to learn the &lt;a href="http://hackage.haskell.org/package/pipes-safe"&gt;library&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Lazy Initializatiom&lt;/h4&gt;&lt;br /&gt;Now you can package up allocation information with streaming resources, which simplifies their presentation.  You don't have to say "run these allocation routines before the session to expose this resource, now stream from that resource, and then run these close routines afterwards".&lt;br /&gt;&lt;br /&gt;This means that you can now just concatenate multiple resources and trust that they only open in response to demand and only one resource is open at any given time.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Prompt Finalization&lt;/h4&gt;&lt;br /&gt;There was one issue with finalization, which is that in order to guarantee safety I cannot always guarantee prompt finalization when composition terminates.  I can only safely run dropped finalizers at the end of the &lt;tt&gt;Session&lt;/tt&gt;.  However, the library lets you trade safety for prompt finalization when you can prove that the prompter finalization safe.&lt;br /&gt;&lt;br /&gt;In practice, this will not be an issue for most users since the dominant use case is a session that is just one linear chain like this: &lt;pre&gt;&lt;br /&gt;session = p1 &gt;-&gt; p2 &gt;-&gt; ... &gt;-&gt; pn&lt;br /&gt;&lt;/pre&gt;In that case, the end of composition coincides with the end of the &lt;tt&gt;Session&lt;/tt&gt;, so there is no delay in finalization.  You only need concern yourself with it if you try to do fancier things, and the documentation explains how to safely use the prompt finalization primitives in those cases.&lt;br /&gt;&lt;br /&gt;In the documentation for the prompt finalization primitives I outline the "pathological" case that foils all attempts to safely finalize things promptly.  I'll repeat it here since it is very illuminating: &lt;pre&gt;&lt;br /&gt;p1 &gt;-&gt; ((p2 &gt;-&gt; p3) &gt;=&gt; p4)&lt;br /&gt;&lt;/pre&gt;When &lt;tt&gt;p3&lt;/tt&gt; finalizes, we might naively expect that it finalizes &lt;tt&gt;p2&lt;/tt&gt; promptly, but not &lt;tt&gt;p1&lt;/tt&gt;.  After all, if we finalized &lt;tt&gt;p1&lt;/tt&gt;, we might accidentally access the finalized resource if &lt;tt&gt;p4&lt;/tt&gt; were to &lt;tt&gt;request&lt;/tt&gt; more input.&lt;br /&gt;&lt;br /&gt;However, this intuition leads to a contradiction when we carefully select &lt;tt&gt;p2&lt;/tt&gt; to be &lt;tt&gt;idT&lt;/tt&gt; and &lt;tt&gt;p4&lt;/tt&gt; to be &lt;tt&gt;return&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;  p1 &gt;-&gt; ((idT &gt;-&gt; p3) &gt;=&gt; return)&lt;br /&gt;= p1 &gt;-&gt; p3&lt;br /&gt;&lt;/pre&gt;In this scenario, if we don't finalize &lt;tt&gt;p1&lt;/tt&gt; when &lt;tt&gt;p3&lt;/tt&gt; terminates, then we are not being prompt!  You don't even necessarily have to use &lt;tt&gt;idT&lt;/tt&gt;.  Setting &lt;tt&gt;p4&lt;/tt&gt; to &lt;tt&gt;return&lt;/tt&gt; suffices to trigger the problem, thanks to associativity: &lt;pre&gt;&lt;br /&gt;  p1 &gt;-&gt; ((p2 &gt;-&gt; p3) &gt;=&gt; return)&lt;br /&gt;= p1 &gt;-&gt; (p2 &gt;-&gt; p3)&lt;br /&gt;= (p1 &gt;-&gt; p2) &gt;-&gt; p3&lt;br /&gt;= p12 &gt;-&gt; p3&lt;br /&gt;&lt;/pre&gt;Associativity guarantees that we can combine the two upstream pipes and treat them like a black box.  Again, if &lt;tt&gt;p3&lt;/tt&gt; terminates, we would have to finalize &lt;tt&gt;p12&lt;/tt&gt; which contains &lt;tt&gt;p1&lt;/tt&gt;.  This contradicts our assumption that we could not finalize &lt;tt&gt;p1&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The old Frames implementation used indexed monads to avoid this problem because the result of composition had to end in a closed state.  Therefore, when &lt;tt&gt;(p2 &gt;-&gt; p3)&lt;/tt&gt; would terminate, it would end in the closed state and would consequently forbid &lt;tt&gt;p4&lt;/tt&gt; from &lt;tt&gt;request&lt;/tt&gt;ing more input, thus guaranteeing that you could safely finalize &lt;tt&gt;p1&lt;/tt&gt; promptly.&lt;br /&gt;&lt;br /&gt;This example demonstrates something that I had difficulty articulating up until recently: There is no meaningful way to distinguish between pipes that are "directly" composed (like &lt;tt&gt;p2&lt;/tt&gt; and &lt;tt&gt;p3&lt;/tt&gt;) and "indirectly" composed (like &lt;tt&gt;p1&lt;/tt&gt; and &lt;tt&gt;p3&lt;/tt&gt;).  This foils any attempt to finalize things both promptly and safely.&lt;br /&gt;&lt;br /&gt;Note that the second example applies to &lt;tt&gt;conduit&lt;/tt&gt;, too, and I suspect that &lt;tt&gt;conduit&lt;/tt&gt; has the same latent problem and cannot guarantee both prompt finalization and associativity.  When I have more time I will dig back in to &lt;tt&gt;conduit&lt;/tt&gt;'s source and see if my intuition is correct.&lt;br /&gt;&lt;br /&gt;Update and clarification: &lt;tt&gt;pipe-safe&lt;/tt&gt; DOES promptly finalize if any bracketed block terminates normally or receives an exception.  The finalizer is only delayed if another pipe composed with it terminates before the bracketed block completes.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Native exception handling&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;pipes-safe&lt;/tt&gt; improves on &lt;tt&gt;conduit&lt;/tt&gt; in one important way: You can catch and resume from exceptions in &lt;tt&gt;pipes&lt;/tt&gt; code so that you can continue streaming where you left off.  &lt;tt&gt;pipes-safe&lt;/tt&gt; builds on the &lt;tt&gt;EitherP&lt;/tt&gt; proxy transformer to integrate exception handling natively within proxies.&lt;br /&gt;&lt;br /&gt;In fact, &lt;tt&gt;EitherP&lt;/tt&gt; gave me the strongest motivation to complete this library.  I felt that it would be a really big shame to be the only streaming library with an elegant error-handling framework but then not use it to handle exceptions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Backwards Compatibility&lt;/h4&gt;&lt;br /&gt;Another way that &lt;tt&gt;pipes-safe&lt;/tt&gt; improves on &lt;tt&gt;conduit&lt;/tt&gt; is that the resource management system does not require any integration with the core &lt;tt&gt;Proxy&lt;/tt&gt; type or with the standard libraries.  It is a well-behaved member of the &lt;tt&gt;pipes&lt;/tt&gt; ecosystem that requires no buy-in from other &lt;tt&gt;pipes&lt;/tt&gt; libraries in order to interoperate with them.&lt;br /&gt;&lt;br /&gt;I provide the &lt;tt&gt;try&lt;/tt&gt; function, which upgrades "unmanaged" proxies to "managed" proxies.  &lt;tt&gt;try&lt;/tt&gt; is a "proxy morphism", meaning that the corresponding functor preserves all five of these categories: &lt;ul&gt;&lt;li&gt; The Kleisli category &lt;li&gt; The pull-based proxy composition category &lt;li&gt; The push-based proxy composition category &lt;li&gt; The "request" category &lt;li&gt; The "respond" category &lt;/ul&gt;This solution is a perfect example of practical category theory, specifically the &lt;a href="http://www.haskellforall.com/2012/09/the-functor-design-pattern.html"&gt;functor design pattern&lt;/a&gt;.  I don't have to require a rewrite of every existing proxy to take into account resource management.  I instead just define a functor that automatically promotes unmanaged proxies to managed ones as if they had been written from the ground up with resource management in mind.&lt;br /&gt;&lt;br /&gt;Code that doesn't need resource management just proceeds as before, blissfully unaware that there is such a thing as a &lt;tt&gt;pipes-safe&lt;/tt&gt; library or exceptions or resource management.  If it ever needs to be used in a safe context, &lt;tt&gt;try&lt;/tt&gt; automatically promotes it to behave correctly, avoiding unnecessary code duplication.&lt;br /&gt;&lt;br /&gt;My big objective when designing this library was that &lt;tt&gt;pipes-safe&lt;/tt&gt; would require zero buy-in from the community and from the standard libraries.  Fortunately, that's precisely the problem that functors solve by providing well-behaved compatibility layers.  In this case, the &lt;tt&gt;try&lt;/tt&gt; function provides that compatibility layer.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Simple Implementation&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;pipes-safe&lt;/tt&gt; is very simple and has a clear implementation.  In fact, I encourage you to read the source yourself if you want to reason about the safety of the library.  The only non-trivial function is the internal &lt;tt&gt;registerK&lt;/tt&gt; function, which serves a similar purpose to the &lt;tt&gt;resourcet&lt;/tt&gt; library.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;registerK&lt;/tt&gt; saves pending finalizers from other proxies so they don't get lost if composition drops them.  Unlike &lt;tt&gt;resourcet&lt;/tt&gt; it uses an elegant zipper-like behavior to keep track of finalizers rather than a &lt;tt&gt;Map&lt;/tt&gt; that requires globally unique IDs.  This also means that it has perfect time complexity, being just O(1) for all finalization operations.  In fact, you could actually implement it using just &lt;tt&gt;StateT&lt;/tt&gt; in the base monad if it were not for exceptions.  However, I had to use &lt;tt&gt;IORef&lt;/tt&gt;s in order to ensure that the finalizer state survived exceptions so it is similar to &lt;tt&gt;resourcet&lt;/tt&gt; in that regard.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;pipes-safe&lt;/tt&gt; does not use &lt;tt&gt;monad-control&lt;/tt&gt; and it doesn't use any ad-hoc or unprincipled type classes.  Instead it just reuses the &lt;tt&gt;Proxy&lt;/tt&gt; class and the &lt;tt&gt;EitherP&lt;/tt&gt; proxy transformer to do everything so that you don't have to learn any new concepts to understand how it works.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;With &lt;tt&gt;pipes-safe&lt;/tt&gt; complete, my next major targets are: &lt;ul&gt;&lt;li&gt; Native parsing for proxies with optional backtracking &lt;li&gt; Bytestring support &lt;/ul&gt;I actually already have the bytestring library up on GitHub, but I haven't released it yet.  The reason is that I've been doing a lot of work recently on distinguishing between &lt;tt&gt;pipes&lt;/tt&gt; as a bytestring (or builder) transport layer and as an ordinary session layer.  The former is quite challenging to implement correctly, but it will be ultimately rewarding because it will allow people to control the properties of the stream without affecting the payload, and also allow people to stream irregular payloads instead of just list-like things.&lt;br /&gt;&lt;br /&gt;I will elaborate more on this in a later post, but the point is that the direction of that work affects what proxies I include in the &lt;tt&gt;bytestring&lt;/tt&gt; library and what proxies will go in a separate transport layer library and that's why I haven't published it yet.</description><link>http://www.haskellforall.com/2013/01/pipes-safe-10-resource-management-and.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>0</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-3887548369332504731</guid><pubDate>Sun, 30 Dec 2012 14:50:00 +0000</pubDate><atom:updated>2013-01-29T17:50:46.291-08:00</atom:updated><title>The Continuation Monad</title><description>The continuation monad is one of the least appreciated monads and in this post I hope to motivate when to use it.  This post will first motivate continuations in general and then motivate them in their specific capacity as monads.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Continuations&lt;/h4&gt;&lt;br /&gt;A Haskell continuation has the following type: &lt;pre&gt;&lt;br /&gt;newtype Cont r a = Cont { runCont :: (a -&gt; r) -&gt; r }&lt;br /&gt;&lt;/pre&gt;A continuation takes a function of type &lt;tt&gt;(a -&gt; r)&lt;/tt&gt; and generates an &lt;tt&gt;r&lt;/tt&gt;, where &lt;tt&gt;r&lt;/tt&gt; can sometimes be a fixed value like &lt;tt&gt;Int&lt;/tt&gt; or &lt;tt&gt;IO ()&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;For example, I might write a long-running process that spawns an action every time the user enters a line of input: &lt;pre&gt;&lt;br /&gt;onInput :: (String -&gt; IO ()) -&gt; IO ()&lt;br /&gt;        -- i.e. Cont (IO ()) String&lt;br /&gt;onInput f = forever $ do&lt;br /&gt;    str &lt;- getLine&lt;br /&gt;    f str&lt;br /&gt;&lt;/pre&gt;You will recognize this idiom if you've ever used frameworks with callbacks.  We supply the framework with a function (i.e. a continuation) and the framework uses that function to do its job.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;"Complete me Later"&lt;/h4&gt;&lt;br /&gt;You generally use continuations when you are programming something, but you want somebody else to complete it.  Common reasons include: &lt;ul&gt;&lt;li&gt; You are programming a framework with callbacks that users supply &lt;li&gt; You are defining a custom map engine for game players to program &lt;li&gt; You are lazy &lt;/ul&gt;I'll use the following hypothetical code segment as an example: &lt;pre&gt;&lt;br /&gt;unitAttack :: Target -&gt; IO ()&lt;br /&gt;unitAttack target = do&lt;br /&gt;    swingAxeBack 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then ??? target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;Let's imagine you have to package up and compile this code for somebody else (say, a fellow colleague) to use later, but it won't compile yet because you still have the unspecified &lt;tt&gt;???&lt;/tt&gt; function.  What do you do?&lt;br /&gt;&lt;br /&gt;Like all good programming, the best solution is the laziest one.  We punt and take the incomplete behavior as a parameter so that whoever finishes the function later on can complete the function by passing the specified behavior in: &lt;pre&gt;&lt;br /&gt;unitAttack :: Target -&gt; (Target -&gt; IO ()) -&gt; IO ()&lt;br /&gt;unitAttack target todo = do&lt;br /&gt;    swingAxeBack 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then todo target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;Problem solved!  Notice how the right hand side of the type signature resembles the shape of our &lt;tt&gt;Cont&lt;/tt&gt; type.  If we just add a newtype, we can wrap it in &lt;tt&gt;Cont&lt;/tt&gt; ourselves: &lt;pre&gt;&lt;br /&gt;unitAttack :: Target -&gt; Cont (IO ()) Target&lt;br /&gt;unitAttack target = Cont $ \todo -&gt; do&lt;br /&gt;    swingAxeBack 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then todo target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;... or, even better, we can use &lt;tt&gt;ContT&lt;/tt&gt; instead.  The benefit of &lt;tt&gt;ContT&lt;/tt&gt; is that it is also a monad transformer, which comes in handy.  &lt;tt&gt;ContT&lt;/tt&gt; has the exact same &lt;tt&gt;Monad&lt;/tt&gt; instance as &lt;tt&gt;Cont&lt;/tt&gt;, so they are otherwise interchangeable:&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;newtype ContT r m a = ContT { runContT :: (a -&gt; m r) -&gt; m r }&lt;br /&gt;&lt;br /&gt;unitAttack :: Target -&gt; ContT () IO Target&lt;br /&gt;unitAttack target = ContT $ \todo -&gt; do&lt;br /&gt;    swingAxeBack 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then todo target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;This is great because now somebody else can "continue" where we left off (thus the name: continuations).  They would just define the missing function: &lt;pre&gt;&lt;br /&gt;damageTarget :: Target -&gt; IO ()&lt;br /&gt;&lt;/pre&gt;... and then supply it to our continuation to complete it: &lt;pre&gt;&lt;br /&gt;runContT (unitAttack target) damageTarget :: IO ()&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Variable Arguments&lt;/h4&gt;&lt;br /&gt;Our strategy works well if we have exactly one hole in our function, but what if we have two holes in our function, each of which takes a different argument? &lt;pre&gt;&lt;br /&gt;unitAttack :: Target -&gt; IO ()&lt;br /&gt;unitAttack target = do&lt;br /&gt;    ???_1 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then ???_2 target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;Well, we might try to accept two continuations: &lt;pre&gt;&lt;br /&gt;unitAttack&lt;br /&gt; :: Target -&gt; (Int -&gt; IO ()) -&gt; (Target -&gt; IO ()) -&gt; IO ()&lt;br /&gt;unitAttack target todo1 todo2 = do&lt;br /&gt;    todo1 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then todo2 target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;... but that no longer cleanly fits into our &lt;tt&gt;Cont&lt;/tt&gt; type, which expects exactly one continuation.&lt;br /&gt;&lt;br /&gt;Fortunately, there is a clean and general solution.  Just define a data type that wraps both possible arguments in a sum type, and just define a single continuation that accepts this sum type: &lt;pre&gt;&lt;br /&gt;data Hole = Swing Int | Attack Target&lt;br /&gt;&lt;br /&gt;unitAttack :: Target -&gt; ContT () IO Hole&lt;br /&gt;unitAttack target = ContT $ \k -&gt; do&lt;br /&gt;    k (Swing 60)&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then k (Attack target)&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;Each constructor acts as a place-holder that signals to the continuation which hole it is currently filling.  Then somebody else can continue where we left off and just write: &lt;pre&gt;&lt;br /&gt;damage    :: Target -&gt; IO ()&lt;br /&gt;swingBack :: Int -&gt; IO ()&lt;br /&gt;&lt;br /&gt;continue :: Hole -&gt; IO ()&lt;br /&gt;continue (Swing  n) = swingBack n&lt;br /&gt;continue (Attack t) = damage t&lt;br /&gt;&lt;br /&gt;runCont (unitAttack target) continue :: IO ()&lt;br /&gt;&lt;/pre&gt;This trick generalizes to &lt;tt&gt;n&lt;/tt&gt; holes with variable arguments per hole.  Just define a type with &lt;tt&gt;n&lt;/tt&gt; constructors, one for each hole, where each constructor stores whatever arguments that particular continuation will need: &lt;pre&gt;&lt;br /&gt;data Hole = Hole1 Arg1 Arg2 | Hole2 | Hole3 Arg3 | Hole4&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Algebraic Data Types&lt;/h4&gt;&lt;br /&gt;I want to digress for a moment to talk about algebraic data types.  If you are not interested, skip to the next section.&lt;br /&gt;&lt;br /&gt;It turns out we can elegantly derive the above trick for multiple holes.  Type algebra says that if we squint then we can translate the following type constructors to algebraic operators and derive equivalent types from simple algebraic manipulations: &lt;pre&gt;&lt;br /&gt;Either a b  &lt;=&gt;  a + b&lt;br /&gt;(a, b)      &lt;=&gt;  a * b&lt;br /&gt;a -&gt; b      &lt;=&gt;  b ^ a&lt;br /&gt;&lt;/pre&gt;That means that if we have a function with two continuations: &lt;pre&gt;&lt;br /&gt;(a1 -&gt; r) -&gt; ((a2 -&gt; r) -&gt; r)&lt;br /&gt;&lt;/pre&gt;... we just translate it to the equivalent algebraic expression: &lt;pre&gt;&lt;br /&gt;(r ^ (r ^ a2)) ^ (r ^ a1)&lt;br /&gt;&lt;/pre&gt;... and then we can derive equivalent representations just by using the rules of algebra: &lt;pre&gt;&lt;br /&gt;  (r ^ (r ^ a2)) ^ (r ^ a1)&lt;br /&gt;= r ^ ((r ^ a2) * (r ^ a1))&lt;br /&gt;= r ^ (r ^ (a2 + a1))&lt;br /&gt;&lt;/pre&gt;... then if we translate that back to the equivalent type, we get: &lt;pre&gt;&lt;br /&gt;(Either a2 a1 -&gt; r) -&gt; r&lt;br /&gt;&lt;/pre&gt;... which is exactly the trick described in the previous section.&lt;br /&gt;&lt;br /&gt;Similarly, if we have more than one argument to a continuation: &lt;pre&gt;&lt;br /&gt;(a -&gt; b -&gt; r) -&gt; r&lt;br /&gt;&lt;/pre&gt;... we can find an equivalent single-argument form using type algebra: &lt;pre&gt;&lt;br /&gt;  r ^ ((r ^ a) ^ b)&lt;br /&gt;= r ^ (r ^ (a * b))&lt;br /&gt;&lt;/pre&gt;... which transforms back to: &lt;pre&gt;&lt;br /&gt;((a, b) -&gt; r) -&gt; r&lt;br /&gt;&lt;/pre&gt;So type algebra tells us the obvious: uncurry the continuation if it needs a single argument.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Continuation Monad&lt;/h4&gt;&lt;br /&gt;So far that explains what continuations are useful for, but it does not explain what the continuation &lt;tt&gt;Monad&lt;/tt&gt; is useful for.&lt;br /&gt;&lt;br /&gt;I firmly believe that the way to a &lt;tt&gt;Monad&lt;/tt&gt;s heart is through its Kleisli arrows, and if you want to study a &lt;tt&gt;Monad&lt;/tt&gt;s "purpose" or "motivation" you study what its Kleisli arrows do.&lt;br /&gt;&lt;br /&gt;So rather than study the &lt;tt&gt;Monad&lt;/tt&gt; instance for &lt;tt&gt;Cont&lt;/tt&gt;, let's instead just study the shape of the &lt;tt&gt;Cont&lt;/tt&gt; Kleisli arrow and infer what it does from its type alone: &lt;pre&gt;&lt;br /&gt;  a -&gt; Cont r b&lt;br /&gt;~ a -&gt; (b -&gt; r) -&gt; r    -- Expand the definition of Cont&lt;br /&gt;~ (b -&gt; r) -&gt; (a -&gt; r)  -- Flip the arguments&lt;br /&gt;&lt;/pre&gt;In other words, we take a function that handles &lt;tt&gt;b&lt;/tt&gt;s and transform it into a function that handles &lt;tt&gt;a&lt;/tt&gt;s.&lt;br /&gt;&lt;br /&gt;This suggests a basic starting intuition for the continuation monad: we transform handlers.&lt;br /&gt;&lt;br /&gt;Let's build on that intuition by revisiting our previous example: &lt;pre&gt;&lt;br /&gt;unitAttack :: Target -&gt; ContT () IO Target&lt;br /&gt;unitAttack target = ContT $ \todo -&gt; do&lt;br /&gt;    swingBack 60&lt;br /&gt;    valid &lt;- isTargetValid target&lt;br /&gt;    if valid&lt;br /&gt;    then todo target&lt;br /&gt;    else sayUhOh&lt;br /&gt;&lt;/pre&gt;We need to supply a completion function of type: &lt;pre&gt;&lt;br /&gt;handler :: Target -&gt; IO ()&lt;br /&gt;&lt;/pre&gt;We &lt;i&gt;could&lt;/i&gt; complete this function ... or we could half-ass it and leave our work incomplete: &lt;pre&gt;&lt;br /&gt;halfAssedCompletion :: Target -&gt; IO ()&lt;br /&gt;halfAssedCompletion target = do&lt;br /&gt;    registerUnitBeingAttacked&lt;br /&gt;    playDamageSound&lt;br /&gt;    ??? 40  -- So close...&lt;br /&gt;&lt;/pre&gt;This means we essentially created a new continuation with a slightly smaller hole: &lt;pre&gt;&lt;br /&gt;halfAssedCompletion :: Target -&gt; ContT () IO Int&lt;br /&gt;halfAssedCompletion target = ContT $ \todo -&gt; do&lt;br /&gt;    registerUnitBeingAttacked&lt;br /&gt;    playDamageSound&lt;br /&gt;    todo 40&lt;br /&gt;&lt;/pre&gt;This is a Kleisli arrow!  That means we can compose it with our previous Kleisli arrow: &lt;pre&gt;&lt;br /&gt;unitAttack &gt;=&gt; halfAssedCompletion :: Target -&gt; ContT () IO Int&lt;br /&gt;&lt;/pre&gt;This composition substitutes in &lt;tt&gt;halfAssedCompletion&lt;/tt&gt; for each hole we left in the &lt;tt&gt;unitAttack&lt;/tt&gt; function.  However, &lt;tt&gt;halfAssedCompletion&lt;/tt&gt; left smaller &lt;tt&gt;Int&lt;/tt&gt; holes of its own that somebody else now has to finish up.&lt;br /&gt;&lt;br /&gt;Notice how now we originally needed a handler of type: &lt;pre&gt;&lt;br /&gt;handler :: Target -&gt; IO ()&lt;br /&gt;&lt;/pre&gt;... but now we only need a smaller handler of type: &lt;pre&gt;&lt;br /&gt;newHandler :: Int -&gt; IO ()&lt;br /&gt;&lt;/pre&gt;... in other words, &lt;tt&gt;halfAssedCompletion&lt;/tt&gt; acts as an intermediary that transforms handlers of type &lt;tt&gt;(Int -&gt; IO ())&lt;/tt&gt; into handlers of type &lt;tt&gt;(Target -&gt; IO ())&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The &lt;tt&gt;Cont&lt;/tt&gt; monad is all about chaining these kinds of partial completions together until all the holes are finally filled.  You could use this abstraction to complete a project in stages and seamlessly hand off work from person to person whenever circumstances require a change in maintainer before completing the project.  Alternative, you can use this to condense the callback API of a framework into a single point of entry.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Kleisli Category&lt;/h4&gt;&lt;br /&gt;Earlier I said that the key to a monad is its Kleisli arrows.  The reason why is that Kleisli arrows are morphisms in the Kleisli category, where &lt;tt&gt;(&gt;=&gt;)&lt;/tt&gt; is Kleisli arrow composition: &lt;pre&gt;&lt;br /&gt;(&gt;=&gt;) :: (Monad m) =&gt; (a -&gt; m b) -&gt; (b -&gt; m c) -&gt; (a -&gt; m c)&lt;br /&gt;(f &gt;=&gt; g) x = f x &gt;&gt;= g&lt;br /&gt;&lt;/pre&gt;.. and &lt;tt&gt;return&lt;/tt&gt; is the identity: &lt;pre&gt;&lt;br /&gt;return :: (Monad m) =&gt; a -&gt; m a&lt;br /&gt;&lt;/pre&gt;Like all categories, the Kleisli category must obey the category laws: &lt;pre&gt;&lt;br /&gt;return &gt;=&gt; f = f                   -- Left identity&lt;br /&gt;&lt;br /&gt;f &gt;=&gt; return = f                   -- Right identity&lt;br /&gt;&lt;br /&gt;(f &gt;=&gt; g) &gt;=&gt; h = f &gt;=&gt; (g &gt;=&gt; h)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Things that obey these laws have nice properties.  For example, it guarantees that you can reason about each Kleisli arrow in a composition chain in isolation.  Each Kleisli arrow's behavior is completely determined by its input (i.e. domain) and output (i.e. codomain).  So let's think about how that modularity translates to the &lt;tt&gt;Cont&lt;/tt&gt; Kleisli category.&lt;br /&gt;&lt;br /&gt;When you switch maintainers, you don't have to give the next maintainer a bunch of holes sprawled out over a large code base like this: &lt;pre&gt;&lt;br /&gt;largeProgram = do&lt;br /&gt;    ...&lt;br /&gt;    x &lt;- ???_1 y&lt;br /&gt;    ...&lt;br /&gt;    ???_2 horseTheyRodeInOn&lt;br /&gt;    ...&lt;br /&gt;    spawn ???_29 foo&lt;br /&gt;&lt;/pre&gt;Instead you can unify all the holes using a single callback that accepts a single type (the "codomain") unifying all the holes you left: &lt;pre&gt;&lt;br /&gt;largeProgram :: () -&gt; ContT () IO Hole&lt;br /&gt;largeProgram () = ContT $ \k -&gt; do&lt;br /&gt;    ...&lt;br /&gt;    x &lt;- k (Hole1 y)&lt;br /&gt;    ...&lt;br /&gt;    k Hole2&lt;br /&gt;    ...&lt;br /&gt;    k (Hole29 spawn foo)&lt;br /&gt;&lt;/pre&gt;This give the next person a single point of entry to continue from, because now they only have to write a Kleisli arrow that handles a single &lt;tt&gt;Hole&lt;/tt&gt; input which encompasses all the previous holes: &lt;pre&gt;&lt;br /&gt;nextContribution :: Hole -&gt; ContT () IO NextHole&lt;br /&gt;nextContribution currHole = ConT $ \nextHole -&gt; case currHole of&lt;br /&gt;    Hole1 y -&gt; ... -- Fill first hole&lt;br /&gt;    Hole2   -&gt; ... -- Fill second hole&lt;br /&gt;    ...&lt;br /&gt;    Hole29 spawn foo -&gt; ... -- File 29th hole&lt;br /&gt;&lt;/pre&gt;Then you just use Kleisli composition to connect your code contribution: &lt;pre&gt;&lt;br /&gt;largeProgram &gt;=&gt; nextContribution&lt;br /&gt;&lt;/pre&gt;This cleanly modularizes the first person's contribution so that you can hermetically seal it off from subsequent contributions.  By repeating this process, each subsequent contribution to the code base becomes its own modular and composable Kleisli arrow, cleanly separated from other contributions: &lt;pre&gt;&lt;br /&gt;alice'sWork :: a -&gt; ContT r m b &lt;br /&gt;bob'sWork   :: b -&gt; ContT r m c&lt;br /&gt;carlo'sWork :: c -&gt; ContT r m d &lt;br /&gt;&lt;br /&gt;engine = alice'sWork &gt;=&gt; bob'sWork &gt;=&gt; carlo'sWork&lt;br /&gt; :: a -&gt; ContT r m d&lt;br /&gt;&lt;br /&gt;customMap :: d -&gt; ContT r m e&lt;br /&gt;&lt;br /&gt;completeGame = engine &gt;=&gt; customMap&lt;br /&gt; :: a -&gt; ContT r m e&lt;br /&gt;&lt;/pre&gt;This is why frameworks and game custom map makers all use continuations to delimit the interface between the company's code and the user's code.  The continuation monad is all about establishing air-tight code boundaries, both internally within a project, and externally for user facing APIs.  This lets you isolate responsibilities if you can separate each code contribution into its own Kleisli arrow.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Callback Hell&lt;/h4&gt;&lt;br /&gt;Frameworks are the canonical example of separating responsibilities, where the framework writer provides some code, but the user is expected to fill in the gap with callbacks of their own.  This often results in callback hell in frameworks that take this principle to the extreme, like Node.js.&lt;br /&gt;&lt;br /&gt;But it doesn't have to be that way.  The continuation monad teaches us that we can always condense a sprawling API filled with callbacks into a single callback that takes a single argument.  Even better, we get monadic syntactic sugar for composing multiple layers of callbacks.&lt;br /&gt;&lt;br /&gt;I'll use the &lt;tt&gt;GLUT&lt;/tt&gt; package as an example, which requires several callbacks like: &lt;pre&gt;&lt;br /&gt;type ReshapeCallback = Size -&gt; IO ()&lt;br /&gt;&lt;br /&gt;type VisibilityCallback = Visibility -&gt; IO ()&lt;br /&gt;&lt;br /&gt;type WindowStateCallback = WindowState -&gt; IO ()&lt;br /&gt;&lt;br /&gt;type CloseCallback = IO ()&lt;br /&gt;&lt;br /&gt;-- there are more, but I'll stop here&lt;br /&gt;&lt;/pre&gt;Instead, we can wrap GLUT's multiple callbacks into a uniform &lt;tt&gt;ContT&lt;/tt&gt; API: &lt;pre&gt;&lt;br /&gt;glut :: () -&gt; ContT () IO Hole&lt;br /&gt;&lt;br /&gt;data Hole&lt;br /&gt;   = Reshape Size&lt;br /&gt;   | Visible Visibility&lt;br /&gt;   | Window WindowState&lt;br /&gt;   | Close&lt;br /&gt;   ...&lt;br /&gt;&lt;/pre&gt;Now the end user has a single entry point to the GLUT monad, so they can now complete the framework in a single function: &lt;pre&gt;&lt;br /&gt;userCallbacks :: Hole -&gt; ContT () IO a&lt;br /&gt;userCallbacks hole = ContT $ \_ -&gt; case hole of&lt;br /&gt;    Reshape size -&gt; ... -- Handle reshapes&lt;br /&gt;    Visibility v -&gt; ... -- Handle visibility switches&lt;br /&gt;    Window ws    -&gt; ... -- Handle changes to window state&lt;br /&gt;    Close        -&gt; ... -- Handle window closing&lt;br /&gt;    ...&lt;br /&gt;&lt;/pre&gt;Moreover, they can now just compose their code with the glut framework: &lt;pre&gt;&lt;br /&gt;glut &gt;=&gt; userCallbacks :: () -&gt; ContT () IO a&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;The Buck Stops Here&lt;/h4&gt;&lt;br /&gt;How do we know when we are done and there are no continuations left?  Well, let's see what type the compiler infers if we have no more holes and never use the continuation: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; let done = ContT $ \_ -&gt; return ()&lt;br /&gt;&gt;&gt;&gt; :t done&lt;br /&gt;done :: Monad m =&gt; ContT () m a&lt;br /&gt;&lt;/pre&gt;It says the return type is polymorphic, meaning that there is no hole left to fill.  The above function just inserts &lt;tt&gt;return ()&lt;/tt&gt; in all holes and calls it a day.  We can even prove a chain of continuations is done if its final return value type-checks as &lt;tt&gt;Void&lt;/tt&gt;, the empty type: &lt;pre&gt;&lt;br /&gt;absurd :: Void -&gt; a  -- from the "void" package&lt;br /&gt;&lt;br /&gt;run :: (Monad m) =&gt; ContT r m Void -&gt; m r&lt;br /&gt;run c = runContT c absurd&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;run&lt;/tt&gt; only accepts completed programs that have no holes left.  We can use &lt;tt&gt;run&lt;/tt&gt; for our previous GLUT example, since the final user callback handler leaves no unfinished holes: &lt;pre&gt;&lt;br /&gt;run ((glut &gt;=&gt; userCallbacks) ()) :: IO ()&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;I hope this post inspires people to use the continuation monad to structure and modularize code completion boundaries.  The continuation monad naturally arises at the boundaries between programmers and cleanly abstracts away callback hell into a simple and uniform interface with a single entry point.</description><link>http://www.haskellforall.com/2012/12/the-continuation-monad.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>11</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5027778649124539337</guid><pubDate>Wed, 12 Dec 2012 17:09:00 +0000</pubDate><atom:updated>2012-12-12T10:00:31.266-08:00</atom:updated><title>pipes-3.0 - A simpler, unified API</title><description>&lt;h4&gt;Introduction&lt;/h4&gt;&lt;br /&gt;I'm releasing &lt;tt&gt;pipes-3.0&lt;/tt&gt;, which significantly simplifies the &lt;a href="http://hackage.haskell.org/package/pipes"&gt;entire library&lt;/a&gt;.  This release began as the misnamed &lt;tt&gt;2.6&lt;/tt&gt; branch of my Github repository, but then I finally cleanly solved the polymorphic constraints issue and this solution unlocked several features that I could finally implement.&lt;br /&gt;&lt;br /&gt;The large change log includes: &lt;ul&gt;&lt;li&gt; Type-classing the entire &lt;tt&gt;Proxy&lt;/tt&gt; API &lt;li&gt; Offering both fast and correct base implementations &lt;li&gt; Fixing type synonyms &lt;li&gt; Unifying the Pipes and Proxy APIs and dropping Frames &lt;li&gt; Adding the PFunctor type class (functors over proxies) &lt;li&gt; Performance improvements &lt;li&gt; Expanded laws and guarantees &lt;li&gt; Smaller dependencies &lt;/ul&gt;As always, if you want to learn how to use &lt;tt&gt;pipes&lt;/tt&gt;, just consult the &lt;a href="http://hackage.haskell.org/packages/archive/pipes/3.0.0/doc/html/Control-Proxy-Tutorial.html"&gt;tutorial&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Code&lt;/h4&gt;&lt;br /&gt;I can demonstrate a lot of the new improvements just by taking the &lt;tt&gt;take'&lt;/tt&gt; function from the &lt;tt&gt;pipes-2.4&lt;/tt&gt; announcement post and showing the difference before and after the new changes.&lt;br /&gt;&lt;br /&gt;Here is the previous version: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE GeneralizedNewtypeDeriving #-}&lt;br /&gt;&lt;br /&gt;import Control.Monad.Trans.Class (MonadTrans(lift))&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Either as E&lt;br /&gt;import Control.Proxy.Trans.State as S&lt;br /&gt;import Data.Monoid ((&lt;&gt;))&lt;br /&gt;import Data.Text as T&lt;br /&gt;&lt;br /&gt;newtype ParseP p a' a b' b m r = ParseP {&lt;br /&gt;    unParseP :: StateP Text (EitherP Text p) a' a b' b m r }&lt;br /&gt;    deriving (Monad, MonadTrans, Channel)&lt;br /&gt;&lt;br /&gt;take' :: (Monad m, Monad (p () Text b' b m), Interact p,&lt;br /&gt;          Channel p)&lt;br /&gt;      =&gt; Int -&gt; () -&gt; ParseP p () Text b' b m Text&lt;br /&gt;take' n () = ParseP go where&lt;br /&gt;    go = do&lt;br /&gt;        s &lt;- S.get&lt;br /&gt;        if (T.length s &lt; n)&lt;br /&gt;        then do&lt;br /&gt;            s' &lt;- liftP $ liftP $ request ()&lt;br /&gt;            S.put (s &lt;&gt; s')&lt;br /&gt;            go&lt;br /&gt;        else do&lt;br /&gt;            let (h, t) = T.splitAt n s&lt;br /&gt;            S.put t&lt;br /&gt;            return h&lt;br /&gt;&lt;/pre&gt;Here is the new version: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE GeneralizedNewtypeDeriving #-}&lt;br /&gt;&lt;br /&gt;-- Smaller import list&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Either as E&lt;br /&gt;import Control.Proxy.Trans.State as S&lt;br /&gt;import Data.Monoid ((&lt;&gt;))&lt;br /&gt;import Data.Text as T&lt;br /&gt;&lt;br /&gt;newtype ParseP p a' a b' b m r = ParseP {&lt;br /&gt;    unParseP :: StateP Text (EitherP Text p) a' a b' b m r }&lt;br /&gt;    deriving (Monad, MonadTrans, Proxy)&lt;br /&gt;&lt;br /&gt;instance ProxyTrans ParseP where&lt;br /&gt;    liftP = liftP . liftP&lt;br /&gt;&lt;br /&gt;--                 +-- Cleaner constraints&lt;br /&gt;--                 |&lt;br /&gt;--                 v&lt;br /&gt;take' :: (Monad m, Proxy p)&lt;br /&gt;      =&gt; Int -&gt; () -&gt; Consumer (ParseP p) Text m Text&lt;br /&gt;--                    ^         ^&lt;br /&gt;--                    |         |&lt;br /&gt;--                    +-- Type synonyms work&lt;br /&gt;--                        with extensions!&lt;br /&gt;&lt;br /&gt;take' n () = ParseP go where&lt;br /&gt;    go = do&lt;br /&gt;        s &lt;- S.get&lt;br /&gt;        if (T.length s &lt; n)&lt;br /&gt;        then do&lt;br /&gt;            s' &lt;- request () -- No more liftP!&lt;br /&gt;            S.put (s &lt;&gt; s')&lt;br /&gt;            go&lt;br /&gt;        else do&lt;br /&gt;            let (h, t) = T.splitAt n s&lt;br /&gt;            S.put t&lt;br /&gt;            return h&lt;br /&gt;&lt;/pre&gt;You can already see several differences: &lt;ul&gt;&lt;li&gt; Type synonyms work with everything, so you can always use them now. &lt;li&gt; Constraints are MUCH simpler and significantly more polymorphic &lt;li&gt; Proxy transformers can now &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; natively &lt;li&gt; Control.Proxy now imports useful things from other libraries (like &lt;tt&gt;lift&lt;/tt&gt;). &lt;/ul&gt;However, this release includes several more great changes as well.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Polymorphic Constraints&lt;/h4&gt;&lt;br /&gt;The big issue that held back the library in the wake of the &lt;tt&gt;2.4&lt;/tt&gt; release was that I could not type class the &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; operations.  The &lt;tt&gt;pipes&lt;/tt&gt; library really only has three fundamental operations: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;request&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;respond&lt;/tt&gt;&lt;/ul&gt;Unfortunately, I could not type class &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; to work with proxy transformers, meaning any standard libraries would be substantially crippled.&lt;br /&gt;&lt;br /&gt;The problem boiled down to my inability to write polymorphic type class contexts like this: &lt;pre&gt;&lt;br /&gt;instance  -- Not valid Haskell&lt;br /&gt;    (forall a' a b' b m .&lt;br /&gt;        (Monad m) =&gt; Monad (p a' a b' b m), Proxy p)&lt;br /&gt;    =&gt; Proxy (EitherP e p) where&lt;br /&gt;    ...&lt;br /&gt;&lt;/pre&gt;The solution (in hindsight) is simple.  You define a higher-kinded type class and you copy the lower-kinded class's functions: &lt;pre&gt;&lt;br /&gt;class MonadP p where&lt;br /&gt;    (?&gt;=) :: (Monad m)&lt;br /&gt;          =&gt; p a' a b' b m r1&lt;br /&gt;          -&gt; (r1 -&gt; p a' a b' b m r2)&lt;br /&gt;          -&gt; p a' a b' b m r2&lt;br /&gt;    return_P :: (Monad m) =&gt; r -&gt; p a 'a b' b m r&lt;br /&gt;&lt;br /&gt;-- In practice, 'MonadP' is part of 'Proxy'&lt;br /&gt;&lt;/pre&gt;Then you can write Haskell98 contexts like: &lt;pre&gt;&lt;br /&gt;instance (MonadP p, Proxy p) =&gt; Proxy (EitherP e p) where ...&lt;br /&gt;&lt;/pre&gt;... but at the same time you can still keep the original lower-kinded type class for the user API: &lt;pre&gt;&lt;br /&gt;instance (MonadP p, Monad m)&lt;br /&gt;    =&gt; Monad (EitherP e p a' a b' b m) where ...&lt;br /&gt;&lt;/pre&gt;This method has one drawback, which is that sometimes you need to embed the code in a newtype if all the type variables are polymorphic.  The &lt;tt&gt;IdentityP&lt;/tt&gt; proxy transformer fits this purpose perfectly, meaning that if you don't use any proxy transformers, you just write: &lt;pre&gt;&lt;br /&gt;myPipe () = runIdentityP $ pipeCode&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;()&lt;/tt&gt; and &lt;tt&gt;runIdentityP&lt;/tt&gt; are the only syntactic noise now.  The &lt;tt&gt;()&lt;/tt&gt; is essential, as I will describe below, and the &lt;tt&gt;runIdentityP&lt;/tt&gt; avoids &lt;tt&gt;OverlappingInstances&lt;/tt&gt; when all the type variables are polymorphic.&lt;br /&gt;&lt;br /&gt;With this change I could then lift &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; over proxy transformers and consolidate the entire &lt;tt&gt;Proxy&lt;/tt&gt; API into the single &lt;tt&gt;Proxy&lt;/tt&gt; type class.  this solution is entirely Haskell98 and no longer requires &lt;tt&gt;FlexibleContexts&lt;/tt&gt;.  If you use &lt;tt&gt;pipes&lt;/tt&gt; already you will discover that your new type signatures will become gorgeous now.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Type-classed API&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;pipes-3.0&lt;/tt&gt; type classes the entire Proxy API using the &lt;tt&gt;Proxy&lt;/tt&gt; type class, which defines the following three essential functions: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;request&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;respond&lt;/tt&gt;&lt;/ul&gt;The entire library implement EVERYTHING using these three functions and the upcoming prompt finalization library also is built entirely on these three functions.  I can safely say that you don't need to use any other functions to write fully featured &lt;tt&gt;pipes&lt;/tt&gt; libraries, which dramatically simplifies the API.&lt;br /&gt;&lt;br /&gt;I type-classed all the utilities which means that I can now offer two base proxy implementations: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;ProxyFast&lt;/tt&gt; The fast proxy implementation from &lt;tt&gt;pipes-2.5&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;ProxyCorrect&lt;/tt&gt; The correct proxy implementation from &lt;tt&gt;pipes-2.4&lt;/tt&gt;&lt;/ul&gt;So now you can choose which implementation you prefer.  &lt;tt&gt;Control.Proxy&lt;/tt&gt; exports &lt;tt&gt;ProxyFast&lt;/tt&gt; implementation by default, but you can easily switch to the correct implementation.  Because all &lt;tt&gt;pipes&lt;/tt&gt; code builds on the &lt;tt&gt;Proxy&lt;/tt&gt; type class you are completely free to pick whichever implementation you prefer and they will both work transparently with all standard libraries.&lt;br /&gt;&lt;br /&gt;However, these utilities don't just work with both base proxy implementations; they also now work as proxy transformers, too!  This means you can now use these utilities seamlessly within any feature set without any lifting.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Laws&lt;/h4&gt;&lt;br /&gt;I briefly touched on the proxy laws in my previous post: &lt;a href="http://www.haskellforall.com/2012/09/concurrency-lists-of-kleisli-arrows.html"&gt;Concurrency = Lists of Kleisli Arrows&lt;/a&gt;.  However, there were two mistakes with those sets of laws: &lt;ul&gt;&lt;li&gt; The double &lt;tt&gt;request&lt;/tt&gt; law was incorrect &lt;li&gt; The laws were insufficiently general &lt;/ul&gt;Fixing the double &lt;tt&gt;request&lt;/tt&gt; law was an interesting challenge, but it was ultimately very rewarding and led to the correct formulation of the laws in terms of two symmetric proxy composition categories: &lt;ul&gt;&lt;li&gt; Pull-based category: &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt; and &lt;tt&gt;idT&lt;/tt&gt; (the current one) &lt;li&gt; Push-based category: &lt;tt&gt;(&gt;~&gt;)&lt;/tt&gt; and &lt;tt&gt;coidT&lt;/tt&gt; (the new one) &lt;/ul&gt;The pull-based category composes proxies blocked on &lt;tt&gt;respond&lt;/tt&gt; and returns a new proxy blocked on &lt;tt&gt;respond&lt;/tt&gt;.  The push-based category composes proxies blocked on &lt;tt&gt;request&lt;/tt&gt; and returns a new proxy blocked on &lt;tt&gt;request&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The proxy laws say that these two categories are perfectly symmetric and that your code's behavior never changes under the following functor, which is an isomorphism between the two categories: &lt;ul&gt;&lt;li&gt;&lt;tt&gt;(&gt;~&gt;)&lt;/tt&gt; to &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt;&lt;li&gt;&lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt; to &lt;tt&gt;(&gt;~&gt;)&lt;/tt&gt;&lt;li&gt;&lt;tt&gt;request&lt;/tt&gt; to &lt;tt&gt;respond&lt;/tt&gt;&lt;li&gt;&lt;/tt&gt;respond&lt;/tt&gt; to &lt;tt&gt;request&lt;/tt&gt;&lt;/ul&gt;This means that the choice of composition operator is arbitrary, and I standardize on using the pull-based &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt; operator because the library already uses it and also matches the lazy demand-based expectations of Haskell programmers.  Therefore, you never have to use the &lt;tt&gt;(&gt;~&gt;)&lt;/tt&gt; operator, but I include in the library as a theoretical curiosity.&lt;br /&gt;&lt;br /&gt;I've already spoken about the practical benefit of centralizing on proxies (duplex channels), but I also standardized on proxies because of their elegance, even more elegant than even pipes.  For example: &lt;ul&gt;&lt;li&gt; The &lt;tt&gt;Proxy&lt;/tt&gt; laws have a purely categorical formulation.  &lt;tt&gt;Pipe&lt;/tt&gt;s do not permit such a formulation. &lt;li&gt; Proxy Kleisli arrows form morphisms in at least 5 categories, all of which have the same shape.  Pipes are morphisms in just two categories (composition and Kleisli categories), and their morphisms do not overlap. &lt;li&gt; You can assemble most useful proxies purely using composition operators: i.e. &lt;tt&gt;(&gt;=&gt;)&lt;/tt&gt; and &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt;, unlike &lt;tt&gt;Pipe&lt;/tt&gt;s, which have an impedance mismatch between the two categories. &lt;li&gt; You cannot implement a push-based category using &lt;tt&gt;Pipe&lt;/tt&gt;s. &lt;/ul&gt;&lt;br /&gt;&lt;h4&gt;Type synonyms&lt;/h4&gt;&lt;br /&gt;Now type synonyms work incredibly well after I parametrized them to take the &lt;tt&gt;Proxy&lt;/tt&gt; instance as a type parameter.  This means that you never have to give them up when things get hairy and if you loved your good old-fashioned and simple &lt;tt&gt;Pipe&lt;/tt&gt;, &lt;tt&gt;Consumer&lt;/tt&gt; and &lt;tt&gt;Producer&lt;/tt&gt; types, you can now use them transparently with the entire proxy ecosystem and they mesh perfectly with everything.&lt;br /&gt;&lt;br /&gt;There is another reason I really like proxies: The &lt;tt&gt;Producer&lt;/tt&gt; type synonym forbids &lt;tt&gt;request&lt;/tt&gt;s.  You can't do that with the unidirectional pipe implementation.  I special case the &lt;tt&gt;Producer&lt;/tt&gt; type synonym to close the upstream end to forbid communication upstream, so now you have a stronger guarantee.&lt;br /&gt;&lt;br /&gt;I also went back to using &lt;tt&gt;()&lt;/tt&gt; and &lt;tt&gt;C&lt;/tt&gt; for type synonyms instead of &lt;tt&gt;Rank2Types&lt;/tt&gt; to universally quantify unused ends.  &lt;tt&gt;Rank2Types&lt;/tt&gt; caused all sorts of problems when you tried to write proxy combinators that accepted pipes as arguments, whereas the simple approach always works and gives clearer types.  The only disadvantage is that if you want to insert a pipe with a blocked end within an open one (like a &lt;tt&gt;Producer&lt;/tt&gt; within a &lt;tt&gt;Pipe&lt;/tt&gt;), you must explicitly reopen the end using the &lt;tt&gt;unitD&lt;/tt&gt; and &lt;tt&gt;unitU&lt;/tt&gt; helper functions.&lt;br /&gt;&lt;br /&gt;Also, I chose not to include the initial parameter of proxies in the type synonym.  The main reason is that you then lose the type synonym any time you define anything other than a composable proxy, which defeats all the other gains I just mentioned.  Also, proxies lie along 5 categories, and special-casing the type synonyms for just one of those categories is a bad idea, especially when at least one of those other categories (the Kleisli category) is commonly used as well.&lt;br /&gt;&lt;br /&gt;I also empirically experimented with both approaches in my own projects, and I can pretty confidently state that the type synonyms should never include the initial parameter.  It does mean that your type signatures will be slightly longer, but it's worth it.  Also, it makes it much easier for people less familiar with the &lt;tt&gt;pipes&lt;/tt&gt; library to consume &lt;tt&gt;pipes&lt;/tt&gt; utilities because they don't need to remember what the initial argument for any given type synonym is supposed to be.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;API Consolidation&lt;/h4&gt;&lt;br /&gt;I went to a great deal of trouble to clean up the fragmentation that I began when I released &lt;tt&gt;Frame&lt;/tt&gt;s.  &lt;tt&gt;Frame&lt;/tt&gt;s are gone and I've merged &lt;tt&gt;Pipe&lt;/tt&gt; functionality into &lt;tt&gt;Proxy&lt;/tt&gt;s, so the library now only has three operations you ever need to use: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;(&gt;-&gt;)&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;request&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;respond&lt;/tt&gt;&lt;/ul&gt;There is now just one way to compose things, something which a lot of users have requested.&lt;br /&gt;&lt;br /&gt;I've deprecated the old &lt;tt&gt;Pipe&lt;/tt&gt; API and included a "Control.Proxy.Pipe" module which helps users transition from &lt;tt&gt;Pipe&lt;/tt&gt;s to &lt;tt&gt;Proxy&lt;/tt&gt;s.  This module not only provides the transition API but also has detailed instructions for how to upgrade your library while still keeping the niceties of the &lt;tt&gt;Pipe&lt;/tt&gt;s API.&lt;br /&gt;&lt;br /&gt;In addition, I've consolidated all the tutorials into a single coherent tutorial in &lt;tt&gt;Control.Proxy.Tutorial&lt;/tt&gt; with a single logical progression.  The tutorial is long, but describes a great deal of the pipe idioms I've collected through my extensive usage of &lt;tt&gt;pipes&lt;/tt&gt; in my own projects.  More importantly, the tutorial collects all of the documentation for the library into a single location again so that users don't need to hunt over several tutorial modules or several blog posts of mine to learn about some key concept.&lt;br /&gt;&lt;br /&gt;I also spent a lot of effort into guiding people towards a single natural coding style for &lt;tt&gt;pipes&lt;/tt&gt; to make it easier for &lt;tt&gt;pipes&lt;/tt&gt; users to read each other's code.  The API exported from &lt;tt&gt;Control.Proxy&lt;/tt&gt; has very little redundancy, and many old redundant API features (like the old &lt;tt&gt;await&lt;/tt&gt; and &lt;tt&gt;yield&lt;/tt&gt;) require you to pay an "import tax" to the tune of one extra import if you want to deviate from the new &lt;tt&gt;pipes&lt;/tt&gt; "style guide".  The tutorial also spends a lot of time talking about common idioms to encourage a uniform coding style.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Performance&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;pipes&lt;/tt&gt; library now includes rewrite rules that rewrite unoptimized user code into the equivalent hand-tuned code.  Despite type-classing the entire standard library these rewrite rules fire very robustly without any assistance on your part.  Just enjoy the extra performance.  There are no performance regressions in this release and all the standard library utilities perform just as damn fast as they did in &lt;tt&gt;pipes-2.5&lt;/tt&gt;, despite now being fully polymorphic and written using ordinary &lt;tt&gt;do&lt;/tt&gt; notation.&lt;br /&gt;&lt;br /&gt;Like always, "Control.Proxy.Prelude.Base" provides tons of examples of how to write idiomatic and high-performance &lt;tt&gt;pipes&lt;/tt&gt; code, so feel free to consult that if you are learning how to write your own utilities.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Lightweight&lt;/h4&gt;&lt;br /&gt;I've dropped &lt;tt&gt;Frame&lt;/tt&gt;s, which means that I can now drop the &lt;tt&gt;index-core&lt;/tt&gt; dependency.  This means that the library only has one dependency: &lt;tt&gt;transformers-0.2&lt;/tt&gt;.  &lt;tt&gt;pipes&lt;/tt&gt; is now the lightest dependency for any streaming library.&lt;br /&gt;&lt;br /&gt;I will not add any extra dependencies to the main package and I will release all additional features in separate packages that build on top of &lt;tt&gt;pipes&lt;/tt&gt;.  I would like to see the core &lt;tt&gt;pipes&lt;/tt&gt; package go as viral as possible.  This is quite easy because in addition to having only a single dependency, &lt;tt&gt;pipes&lt;/tt&gt; is: &lt;ul&gt;&lt;li&gt; Quick to compile &lt;li&gt; Safe Haskell &lt;li&gt; Light on extensions: Only &lt;tt&gt;KindSignatures&lt;/tt&gt; and &lt;tt&gt;Rank2Types&lt;/tt&gt; (for &lt;tt&gt;MFunctor&lt;/tt&gt; and &lt;tt&gt;PFunctor&lt;/tt&gt;) &lt;/ul&gt;&lt;br /&gt;&lt;h4&gt;Convenience imports&lt;/h4&gt;&lt;br /&gt;I added some extra imports from other modules to &lt;tt&gt;Control.Proxy&lt;/tt&gt;, like &lt;tt&gt;lift&lt;/tt&gt; and &lt;tt&gt;forever&lt;/tt&gt;.  I was pretty conservative in what I added and stuck to things that I considered essential for using &lt;tt&gt;pipes&lt;/tt&gt; idiomatically.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;hoist&lt;/tt&gt; and &lt;tt&gt;lift&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;I renamed &lt;tt&gt;MFunctor&lt;/tt&gt;'s &lt;tt&gt;mapT&lt;/tt&gt; to &lt;tt&gt;hoist&lt;/tt&gt;.  Sorry for the inconvenience, but &lt;tt&gt;mapT&lt;/tt&gt; was a terrible name for several reasons and instead went with Edward's naming convention which I felt was more tasteful.&lt;br /&gt;&lt;br /&gt;One of the really nice things to come out of &lt;tt&gt;pipes&lt;/tt&gt; is a clean mechanism for mixing arbitrary monad transformer stacks and arbitrary proxy transformer stacks.  It turns out that if two transformer stacks have the same base monad, then you can always interleave them in any way using the right combination of &lt;tt&gt;hoist&lt;/tt&gt; and &lt;tt&gt;lift&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The exact same trick also applies to proxy transformer stacks.  You can always interleave them using the right combination of &lt;tt&gt;hoistP&lt;/tt&gt; (from the new &lt;tt&gt;PFunctor&lt;/tt&gt; class) and &lt;tt&gt;liftP&lt;/tt&gt;, which are just the higher-kinded versions of &lt;tt&gt;hoist&lt;/tt&gt; and &lt;tt&gt;lift&lt;/tt&gt; (and they also obey more laws, too).&lt;br /&gt;&lt;br /&gt;The &lt;a href="http://hackage.haskell.org/packages/archive/pipes/3.0.0/doc/html/Control-Proxy-Tutorial.html"&gt;tutorial&lt;/a&gt; describes this trick in more detail and I find that this works phenomenally well and is very easy to reason about.  For this reason I think &lt;tt&gt;MFunctor&lt;/tt&gt; needs to be somewhere in the standard libraries as soon as possible because it is incredibly useful for this purpose.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Stability&lt;/h4&gt;&lt;br /&gt;I can state confidently that the &lt;tt&gt;pipes&lt;/tt&gt; API can now handle any problem you throw at it and that the core is feature complete.  The tutorial shows how you can combine the incredibly small &lt;tt&gt;pipes&lt;/tt&gt; core into all the functionality you need.  The only exception is prompt finalization, which I will describe in a separate upcoming library, but finalization similarly builds entirely on this core and does not add any new concepts or primitives.&lt;br /&gt;&lt;br /&gt;There are only a few changes I foresee making to the main library in the future, which are: &lt;ul&gt;&lt;li&gt; Moving &lt;tt&gt;MFunctor&lt;/tt&gt; to a better home &lt;li&gt; Adding a base proxy implementation with strictness annotations (never leaks, but half the performance of the fast implementation) &lt;/ul&gt;Note that this doesn't mean that &lt;tt&gt;pipes&lt;/tt&gt; frequently leaks space.  I've only found one case of leaking, which is the following code segment: &lt;pre&gt;&lt;br /&gt;runProxy $ enumFromS 1&lt;br /&gt;&lt;/pre&gt;Everything else I have tried does not leak and I currently use &lt;tt&gt;pipes&lt;/tt&gt; in long-running server applications of my own that also do not leak without any strictness annotations.  However, if users do encounter leaks then I will go ahead and add the strict base implementation.&lt;br /&gt;&lt;br /&gt;I will also be pretty conservative about expanding the core library because I want to stabilize it now.  Almost all new functions will go in separate libraries now.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;At this point I am very happy with the state of the main &lt;tt&gt;pipes&lt;/tt&gt; library and I'm currently devoting my next efforts to standard libraries.  The next libraries I will release will be (in this order): &lt;ul&gt;&lt;li&gt; Finalization support &lt;li&gt; &lt;tt&gt;bytestring&lt;/tt&gt; / &lt;tt&gt;text&lt;/tt&gt; support &lt;li&gt; Parsing extensions &lt;/ul&gt;</description><link>http://www.haskellforall.com/2012/12/pipes-30-simpler-unified-api.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>12</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-6720598980634542475</guid><pubDate>Thu, 01 Nov 2012 05:59:00 +0000</pubDate><atom:updated>2012-10-31T23:05:44.457-07:00</atom:updated><title>pipes-2.5: Faster and slimmer</title><description>&lt;h4&gt;Introduction&lt;/h4&gt;&lt;br /&gt;I optimized the entire &lt;tt&gt;pipes&lt;/tt&gt; library very aggressively for version 2.5, and now the library runs faster than &lt;tt&gt;conduit&lt;/tt&gt; on my micro-benchmarks.  I'll begin with the purest benchmark which gives the greatest difference in speed since it only measure the efficiency of each library's implementation without any &lt;tt&gt;IO&lt;/tt&gt; bottlenecks: &lt;pre&gt;&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Data.Conduit&lt;br /&gt;import Data.Conduit.List as L&lt;br /&gt;&lt;br /&gt;n = 1000000 :: Int&lt;br /&gt;&lt;br /&gt;-- Pipes&lt;br /&gt;main = runProxy $ discard &lt;-&lt; enumFromToS 1 n&lt;br /&gt;&lt;br /&gt;-- Conduit&lt;br /&gt;main = L.enumFromTo 1 n $$ L.sinkNull&lt;br /&gt;&lt;/pre&gt;Note some differences from last time.  This time I'm using &lt;tt&gt;conduit&lt;/tt&gt;'s built-in optimized &lt;tt&gt;discard&lt;/tt&gt; equivalent: &lt;tt&gt;sinkNull&lt;/tt&gt;.  Also, I've multiplied &lt;tt&gt;n&lt;/tt&gt; by 10 to more accurately measure throughput.  I compile both implementations with &lt;tt&gt;-O2&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;pipes&lt;/tt&gt; now spends about 112 ns per round-trip: &lt;pre&gt;&lt;br /&gt;real    0m0.112s&lt;br /&gt;user    0m0.104s&lt;br /&gt;sys     0m0.004s&lt;br /&gt;&lt;/pre&gt;... while &lt;tt&gt;conduit&lt;/tt&gt; spends about 167 ns per round-trip: &lt;pre&gt;&lt;br /&gt;real    0m0.167s&lt;br /&gt;user    0m0.156s&lt;br /&gt;sys     0m0.008s&lt;br /&gt;&lt;/pre&gt;I achieved this speed increase by reverting to the &lt;tt&gt;pipes-1.0&lt;/tt&gt; trick of making the base monad optional, at the expense of breaking the monad transformer laws.  I spent a considerable amount of effort trying to get the correct version to work, but I was led inexorably to the same conclusion that Michael already reached, which was that the original approach was best and that the gain in performance is worth bending the monad transformer laws.&lt;br /&gt;&lt;br /&gt;Note that the above benchmark exaggerates the differences and is not indicative of real-world performance differences.  For typical code you will not observe measurable differences between &lt;tt&gt;pipes&lt;/tt&gt; and &lt;tt&gt;conduit&lt;/tt&gt; when &lt;tt&gt;IO&lt;/tt&gt; is the bottle-neck.&lt;br /&gt;&lt;br /&gt;There is also one area in which &lt;tt&gt;conduit&lt;/tt&gt; may still give (very slightly) better performance, which is in speeding up user-defined pipes.  One goal I did not complete for this release was copying Michael's trick of using rewrite &lt;tt&gt;RULES&lt;/tt&gt; to inline the &lt;tt&gt;Monad&lt;/tt&gt; instance for user-defined pipes.  I plan to copy this same trick in a separate release because I want to take the time to ensure that I can get the rewrite &lt;tt&gt;RULES&lt;/tt&gt; to always fire without interfering with other optimizations.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Light-weight&lt;/h4&gt;&lt;br /&gt;The big focus of this release was to make &lt;tt&gt;pipes&lt;/tt&gt; a very light-weight dependency, both in terms of performance and transitive dependencies.  In the rewrite I dropped the &lt;tt&gt;free&lt;/tt&gt; dependency so now the package only has two non-&lt;tt&gt;base&lt;/tt&gt; dependencies: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;transformers &gt;= 0.2.0.0&lt;/tt&gt;&lt;li&gt; &lt;tt&gt;index-core&lt;/tt&gt;&lt;/ul&gt;... and I plan on dropping &lt;tt&gt;index-core&lt;/tt&gt; along with &lt;tt&gt;Frame&lt;/tt&gt;s once I complete my resource management solution, leaving just a &lt;tt&gt;transformers&lt;/tt&gt; dependency, which is about as light-weight as it could possibly get.&lt;br /&gt;&lt;br /&gt;I also stole a page from Michael's book, by removing the &lt;tt&gt;-O2&lt;/tt&gt; flag from the &lt;tt&gt;pipes.cabal&lt;/tt&gt; file.  This flag no longer has any effect on performance after the rewrite, so you should see quicker compile times, making the &lt;tt&gt;pipes&lt;/tt&gt; dependency even lighter.&lt;br /&gt;&lt;br /&gt;There is still one other way I could make the &lt;tt&gt;pipes&lt;/tt&gt; dependency even lighter, which is to remove the &lt;tt&gt;MFunctor&lt;/tt&gt; class.  The &lt;tt&gt;Control.MFunctor&lt;/tt&gt; module requires &lt;tt&gt;Rank2Types&lt;/tt&gt;, which might rule out &lt;tt&gt;pipes&lt;/tt&gt; for projects that use non-GHC compilers, so if this is an issue for you, just let me know and I will try to migrate &lt;tt&gt;MFunctor&lt;/tt&gt; to a separate library.  &lt;tt&gt;Frame&lt;/tt&gt;s use a lot of extensions, but those will be on the way out, leaving behind just &lt;tt&gt;FlexibleContexts&lt;/tt&gt; and &lt;tt&gt;KindSignatures&lt;/tt&gt;, which are very mild extensions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Resource management&lt;/h4&gt;&lt;br /&gt;I also wanted to use this update to point out that you can get deterministic resource management with &lt;tt&gt;pipes&lt;/tt&gt; today if you use Michael's &lt;tt&gt;ResourceT&lt;/tt&gt; in the base monad.  So if you want to use &lt;tt&gt;pipes&lt;/tt&gt; and all you care about is resource determinism then you can switch over already.&lt;br /&gt;&lt;br /&gt;However, that alone will NOT give you prompt finalization and if you want promptness you will have to wait until I complete my own resource management extension.  The extension I have in mind will be released as a proxy transformer that you can layer in any proxy transformer stack, so any proxy code you currently write can be transparently upgraded to work with resource management later on when I release the extension.&lt;br /&gt;&lt;br /&gt;Another thing I want to mention is that while I will release the tools to manage resources promptly and deterministically, I do not plan on using these tools in the proxy standard libraries that I will release.  The main reason for this is that: &lt;ul&gt;&lt;li&gt; There is no one true solution to finalization and I don't want people to have to buy in to my finalization approach to use the standard libraries I provide. &lt;li&gt; Most people I've talked to who care about finalization usually take the initiative write their own higher-level abstractions on top of whatever finalization primitives I provide them. &lt;/ul&gt;So my plan is that the standard libraries I will write will purely focus on the streaming part of the problem and leave initialization/finalization to the end user, which they can optionally implement using my resource management solution or whatever other approach they prefer (such as &lt;tt&gt;ResourceT&lt;/tt&gt;, for example).&lt;br /&gt;&lt;br /&gt;If you want to know what I personally use in my own projects at the moment, I just use the following pattern: &lt;pre&gt;&lt;br /&gt;do withResource $ \h -&gt; &lt;br /&gt;   runProxy $ ... &lt;-&lt; streamFromResource h&lt;br /&gt;&lt;/pre&gt;This gives "good enough" behavior for my purposes and out of all the finalization alternatives I've tried, it is by far the easiest one to understand and use.&lt;br /&gt;&lt;br /&gt;The other reason I'm trying out this agnostic approach to finalization is due to discussion with Gregory Collins about his upcoming &lt;tt&gt;io-streams&lt;/tt&gt; library, where he takes a very similar approach to the one I just described of leaving initialization/finalization to the end user to avoid cross-talk between abstractions and to emphasize handling the streaming aspect correctly.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Goals for the near future&lt;/h4&gt;&lt;br /&gt;I focused on improving the performance of pure code because I plan to release &lt;tt&gt;bytestring&lt;/tt&gt;/&lt;tt&gt;text&lt;/tt&gt; standard libraries and their corresponding parsing proxy transformers very soon, which demand exceptional pure performance.  The goal of the upcoming proxy-based parsing libraries is not to beat &lt;tt&gt;attoparsec&lt;/tt&gt; in speed (which I'm reasonably sure is impossible), but rather to: &lt;ul&gt;&lt;li&gt; Interleave parsing with with effects &lt;li&gt; Provide a low-memory streaming parser by allowing the user to selectively control backtracking &lt;li&gt; Still be really fast &lt;/ul&gt;The first two features are sorely missing from &lt;tt&gt;attoparsec&lt;/tt&gt;, which can't interleave effects and always backtracks so that the file isn't cleared from memory until the parsing completes.  For my own projects I need the second feature the most because I get a lot of requests to parse huge files (i.e. 20 GB) that do not fit in my computer's memory.  More generally, I want &lt;tt&gt;pipes&lt;/tt&gt; to be the fallback parser of choice for all problems that &lt;tt&gt;attoparsec&lt;/tt&gt; does not solve.</description><link>http://www.haskellforall.com/2012/10/pipes-25-faster-and-slimmer.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>13</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-4841430318735649264</guid><pubDate>Sat, 20 Oct 2012 15:39:00 +0000</pubDate><atom:updated>2012-10-20T08:39:48.801-07:00</atom:updated><title>"Hello, core!"</title><description>Haskell optimization is very opaque and getting tight inner loops is something of a black art for people who don't take the time to learn GHC's core output.  If you like fine-grained optimization, this post will walk you through a very simple example to help you learn to read core.&lt;br /&gt;&lt;br /&gt;I'm planning to write some posts in the future discussing optimizing Haskell code and I would like to use this post as a foundation for those latter discussions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;ghc-core&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;When you practice reading core, stick to really simple programs.  In fact, let's study the core generated by the simplest possible Haskell program: &lt;pre&gt;&lt;br /&gt;main :: IO ()&lt;br /&gt;main = return ()&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;ghc-core&lt;/tt&gt; tool produces a (slightly) readable core output.  To install it, just type: &lt;pre&gt;&lt;br /&gt;cabal install ghc-core&lt;br /&gt;&lt;/pre&gt;... and &lt;tt&gt;cabal&lt;/tt&gt; should install it to &lt;tt&gt;~/.cabal/bin/ghc-core&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;We generate core output by running: &lt;pre&gt;&lt;br /&gt;~/.cabal/bin/ghc-core --no-cast --no-asm program.hs&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;--no-cast&lt;/tt&gt; flag improves the readability by removing type casts and the &lt;tt&gt;--no-asm&lt;/tt&gt; flag says not to include the final assembly code.&lt;br /&gt;&lt;br /&gt;The above command automatically enables all optimizations and outputs to a pager the following two sections: &lt;ul&gt;&lt;li&gt; A list of optimizations that fired &lt;li&gt; The core section, which contains the intermediate core representation &lt;/ul&gt;The optimization section should look something like this: &lt;pre&gt;&lt;br /&gt;0 Lets floated to top level; 0 Lets floated elsewhere; from ...&lt;br /&gt;&lt;br /&gt;0 Lets floated to top level; 0 Lets floated elsewhere; from ...&lt;br /&gt;&lt;br /&gt;Total ticks:     15&lt;br /&gt;&lt;br /&gt;2 PreInlineUnconditionally&lt;br /&gt;  1 x_abD&lt;br /&gt;  1 s_abE&lt;br /&gt;5 UnfoldingDone&lt;br /&gt;  1 returnIO&lt;br /&gt;  1 runMainIO&lt;br /&gt;  1 main&lt;br /&gt;  1 returnIO1&lt;br /&gt;  1 $fMonadIO_$creturn&lt;br /&gt;1 RuleFired 1 Class op return&lt;br /&gt;2 LetFloatFromLet 2&lt;br /&gt;2 EtaExpansion&lt;br /&gt;  1 :main&lt;br /&gt;  1 main&lt;br /&gt;3 BetaReduction&lt;br /&gt;  1 a_abC&lt;br /&gt;  1 x_abD&lt;br /&gt;  1 s_abE&lt;br /&gt;10 SimplifierDone 10&lt;br /&gt;&lt;/pre&gt;... and the core should look something like this: &lt;pre&gt;&lt;br /&gt;Result size = 20&lt;br /&gt;&lt;br /&gt;main1&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;[GblId,&lt;br /&gt; Arity=1,&lt;br /&gt;&lt;br /&gt; Unf=Unf{Src=&lt;vanilla&gt;, TopLvl=True, Arity=1, Value=True,&lt;br /&gt;         ConLike=True, Cheap=True, Expandable=True,&lt;br /&gt;         Guidance=ALWAYS_IF(unsat_ok=True,boring_ok=True)}]&lt;br /&gt;main1 =&lt;br /&gt;  \ (eta_B1 :: State# RealWorld) -&gt;&lt;br /&gt;    (# eta_B1, () #)&lt;br /&gt;&lt;br /&gt;main :: IO ()&lt;br /&gt;[GblId,&lt;br /&gt; Arity=1,&lt;br /&gt;&lt;br /&gt; Unf=Unf{Src=&lt;vanilla&gt;, TopLvl=True, Arity=0, Value=True,&lt;br /&gt;         ConLike=True, Cheap=True, Expandable=True,&lt;br /&gt;         Guidance=ALWAYS_IF(unsat_ok=True,boring_ok=True)}]&lt;br /&gt;main =&lt;br /&gt;  main1&lt;br /&gt;  &lt;br /&gt;&lt;br /&gt;main2&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;[GblId,&lt;br /&gt; Arity=1,&lt;br /&gt;&lt;br /&gt; Unf=Unf{Src=&lt;vanilla&gt;, TopLvl=True, Arity=1, Value=True,&lt;br /&gt;         ConLike=True, Cheap=True, Expandable=True,&lt;br /&gt;         Guidance=IF_ARGS [0] 30 0}]&lt;br /&gt;main2 =&lt;br /&gt;  \ (eta_X7 :: State# RealWorld) -&gt;&lt;br /&gt;    runMainIO1&lt;br /&gt;      @ ()&lt;br /&gt;      (main1&lt;br /&gt;       )&lt;br /&gt;      eta_X7&lt;br /&gt;&lt;br /&gt;:main :: IO ()&lt;br /&gt;[GblId,&lt;br /&gt; Arity=1,&lt;br /&gt;&lt;br /&gt; Unf=Unf{Src=&lt;vanilla&gt;, TopLvl=True, Arity=0, Value=True,&lt;br /&gt;         ConLike=True, Cheap=True, Expandable=True,&lt;br /&gt;         Guidance=ALWAYS_IF(unsat_ok=True,boring_ok=True)}]&lt;br /&gt;:main =&lt;br /&gt;  main2&lt;br /&gt;&lt;/pre&gt;That still looks pretty ugly, so let's filter it a bit.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Core&lt;/h4&gt;&lt;br /&gt;You'll notice that every function has a type signature, without exception.  For example, &lt;tt&gt;main1&lt;/tt&gt;'s type is: &lt;pre&gt;&lt;br /&gt;main1&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;&lt;/pre&gt;However, each function also has a set of attributes that &lt;tt&gt;ghc&lt;/tt&gt; uses to guide various optimization passes.  &lt;tt&gt;main1&lt;/tt&gt;'s attributes are: &lt;pre&gt;&lt;br /&gt;[GblId,&lt;br /&gt; Arity=1,&lt;br /&gt;&lt;br /&gt; Unf=Unf{Src=&lt;vanilla&gt;, TopLvl=True, Arity=0, Value=True,&lt;br /&gt;         ConLike=True, Cheap=True, Expandable=True,&lt;br /&gt;         Guidance=ALWAYS_IF(unsat_ok=True,boring_ok=True)}]&lt;br /&gt;&lt;/pre&gt;For example, &lt;tt&gt;Cheap=True&lt;/tt&gt; says that it is cheap to inline &lt;tt&gt;main1&lt;/tt&gt;.  Similarly, &lt;tt&gt;ConLike=True&lt;/tt&gt; says it is okay if a rewrite rule requires duplicating &lt;tt&gt;main1&lt;/tt&gt;'s code.&lt;br /&gt;&lt;br /&gt;However, for the purposes of this post, we will just completely ignore these annotations and just focus on the type signatures and code.  I'll remove the attributes to leave behind something easier on the eyes: &lt;pre&gt;&lt;br /&gt;main1&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;main1 =&lt;br /&gt;  \ (eta_B1 :: State# RealWorld) -&gt;&lt;br /&gt;    (# eta_B1, () #)&lt;br /&gt;&lt;br /&gt;main :: IO ()&lt;br /&gt;main =&lt;br /&gt;  main1&lt;br /&gt;&lt;br /&gt;main2&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;main2 =&lt;br /&gt;  \ (eta_X7 :: State# RealWorld) -&gt;&lt;br /&gt;    runMainIO1&lt;br /&gt;      @ ()&lt;br /&gt;      (main1&lt;br /&gt;       )&lt;br /&gt;      eta_X7&lt;br /&gt;&lt;br /&gt;:main :: IO ()&lt;br /&gt;:main =&lt;br /&gt;  main2&lt;br /&gt;&lt;/pre&gt;Now we see that there are four functions total, but a lot of noise still remain.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Primitive types and values&lt;/h4&gt;&lt;br /&gt;Let's walk through this core, beginning with the type signature of &lt;tt&gt;main1&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;main1&lt;br /&gt;  :: State# RealWorld&lt;br /&gt;     -&gt; (# State# RealWorld, () #)&lt;br /&gt;&lt;/pre&gt;Somebody sprinkled &lt;tt&gt;#&lt;/tt&gt;s all over our type signature.  These &lt;tt&gt;#&lt;/tt&gt;s denote primitive types and values exposed by the compiler that are not defined within the Haskell language.  You can check out &lt;a href="http://www.haskell.org/ghc/docs/7.2.2/html/libraries/ghc-prim-0.2.0.0/src/GHC-Prim.html"&gt;the &lt;tt&gt;GHC.Prim&lt;/tt&gt; module&lt;/a&gt; which declares these values and type.  Notice how it cheats and declares all types empty and the values are all set to &lt;tt&gt;let x = x in x&lt;/tt&gt; just so that everything type-checks.&lt;br /&gt;&lt;br /&gt;You can learn more about these primitive types and operations by reading the section on &lt;a href="http://www.haskell.org/ghc/docs/latest/html/users_guide/primitives.html"&gt;Unboxed types and primitive operations&lt;/a&gt; in the GHC user guide.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;IO&lt;/tt&gt; is a state monad&lt;/h4&gt;&lt;br /&gt;GHC implements &lt;tt&gt;IO&lt;/tt&gt; as a &lt;tt&gt;newtype&lt;/tt&gt; wrapper around a state monad: &lt;pre&gt;&lt;br /&gt;newtype IO a = IO (State# RealWorld -&gt; (# State# RealWorld, a #))&lt;br /&gt;&lt;/pre&gt;Notice that this is just the right type to wrap &lt;tt&gt;main1&lt;/tt&gt;, which uses the same stateful pattern: &lt;pre&gt;&lt;br /&gt;main1 :: State# RealWorld -&gt; (# State# RealWorld, () #)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;IO&lt;/tt&gt;s state-based implementation ensures proper sequencing of computations and the &lt;tt&gt;State# RealWorld&lt;/tt&gt; token is an empty token that exists solely to ensure that each sequenced computation depends on the previous one so that the compiler does not rearrange, merge or duplicate them.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The chain of command&lt;/h4&gt;&lt;br /&gt;Now, let's study the definition of &lt;tt&gt;main1&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;main1 =&lt;br /&gt;  \ (eta_B1 :: State# RealWorld) -&gt;&lt;br /&gt;    (# eta_B1, () #)&lt;br /&gt;&lt;/pre&gt;If we tidy this up and remove the type annotation, we get: &lt;pre&gt;&lt;br /&gt;main1 = \s -&gt; (s, ())&lt;br /&gt;&lt;/pre&gt;This is just &lt;tt&gt;return ()&lt;/tt&gt; in the &lt;tt&gt;State (State# RealWorld)&lt;/tt&gt; monad.  The compiler translated our original &lt;tt&gt;return ()&lt;/tt&gt; statement into the equivalent stateful function under hood.&lt;br /&gt;&lt;br /&gt;However, the next function seems to accomplish nothing: &lt;pre&gt;&lt;br /&gt;main :: IO ()&lt;br /&gt;main =&lt;br /&gt;  main1&lt;br /&gt;&lt;/pre&gt;... but that's only because the &lt;tt&gt;--no-casts&lt;/tt&gt; flag removed type casts.  If we add them back in, we get: &lt;pre&gt;&lt;br /&gt;main =&lt;br /&gt;  main1&lt;br /&gt;  `cast` (Sym (NTCo:IO &lt;()&gt;)&lt;br /&gt;          :: (State# RealWorld&lt;br /&gt;              -&gt; (# State# RealWorld, () #))&lt;br /&gt;               ~#&lt;br /&gt;             IO ())&lt;br /&gt;&lt;/pre&gt;That &lt;tt&gt;`cast`&lt;/tt&gt; statement corresponds to the &lt;tt&gt;IO&lt;/tt&gt; constructor from our &lt;tt&gt;IO&lt;/tt&gt; &lt;tt&gt;newtype&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;IO :: (State# RealWorld -&gt; (# State# RealWorld, a #)) -&gt; IO a&lt;br /&gt;&lt;/pre&gt;This constructor hides the underlying stateful representation behind the opaque &lt;tt&gt;IO&lt;/tt&gt; &lt;tt&gt;newtype&lt;/tt&gt;.  However, unlike &lt;tt&gt;data&lt;/tt&gt; constructors, &lt;tt&gt;newtype&lt;/tt&gt; constructors cost nothing and don't translate into functions with a run-time overhead.  Instead, they translate into free compile-time &lt;tt&gt;cast&lt;/tt&gt; statements which the compiler erases once compilation is complete.&lt;br /&gt;&lt;br /&gt;This explains why &lt;tt&gt;main&lt;/tt&gt; has a different type from &lt;tt&gt;main1&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;main :: IO ()&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;main&lt;/tt&gt; packages our impure code inside the &lt;tt&gt;IO&lt;/tt&gt; newtype, whereas &lt;tt&gt;main1&lt;/tt&gt; contains the raw underlying stateful representation.&lt;br /&gt;&lt;br /&gt;In fact, &lt;tt&gt;main&lt;/tt&gt; corresponds &lt;b&gt;exactly&lt;/b&gt; to the &lt;tt&gt;main&lt;/tt&gt; function we wrote in our original code (which is why it has the exact same name): &lt;pre&gt;&lt;br /&gt;-- The original program&lt;br /&gt;main :: IO ()&lt;br /&gt;main = return ()&lt;br /&gt;&lt;/pre&gt;The next function appears to run our code: &lt;pre&gt;&lt;br /&gt;main2 =&lt;br /&gt;  \ (eta_X7 :: State# RealWorld) -&gt;&lt;br /&gt;    runMainIO1&lt;br /&gt;      @ ()&lt;br /&gt;      (main1&lt;br /&gt;       )&lt;br /&gt;      eta_X7&lt;br /&gt;&lt;/pre&gt;With a little tidying up, this becomes: &lt;pre&gt;&lt;br /&gt;main2 = \s -&gt; runMainIO1 main1 s&lt;br /&gt;&lt;/pre&gt;But wait, it runs &lt;tt&gt;main1&lt;/tt&gt; and not &lt;tt&gt;main&lt;/tt&gt;!  I'm guessing that the &lt;tt&gt;main&lt;/tt&gt; token exists solely to establish the correspondence to the user-written code, but perhaps &lt;tt&gt;ghc&lt;/tt&gt; doesn't actually care about it and instead uses the raw &lt;tt&gt;main1&lt;/tt&gt; directly.&lt;br /&gt;&lt;br /&gt;Now, to be honest, I don't actually know what &lt;tt&gt;runMainIO1&lt;/tt&gt; does, but &lt;a href="http://blog.ezyang.com/2011/05/unraveling-the-mystery-of-the-io-monad/"&gt;according to Edward Yang&lt;/a&gt;, it initializes some things like interrupt handlers before running the program.&lt;br /&gt;&lt;br /&gt;Finally, we reach the true entry point of our program: &lt;pre&gt;&lt;br /&gt;:main :: IO ()&lt;br /&gt;:main =&lt;br /&gt;  main2 -- There is a hidden cast here&lt;br /&gt;&lt;/pre&gt;This passes our program to the Haskell runtime to be executed.  That's it!  We're done.</description><link>http://www.haskellforall.com/2012/10/hello-core.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>7</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-4133366526611054153</guid><pubDate>Tue, 16 Oct 2012 04:30:00 +0000</pubDate><atom:updated>2012-10-21T07:37:04.210-07:00</atom:updated><title>Parsing chemical substructures</title><description>This is the second in a series of coding examples from my own work.  &lt;a href="http://www.reddit.com/r/programming/"&gt;/r/programming&lt;/a&gt; asked for non-trivial, yet digestible, Haskell examples, so I hope this fits the bill.&lt;br /&gt;&lt;br /&gt;In this post I will show how learning Haskell changes the way you think.  I will take a common Haskell idiom (monadic parsing) and apply it in a new way to solve a structural bioinformatics problem.  To make this post more accessible to non-Haskell programmers, I'm going to gloss over implementation details and instead try to discuss at a high-level how I apply Haskell idioms to solve my problem.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The &lt;tt&gt;Parser&lt;/tt&gt; type&lt;/h4&gt;&lt;br /&gt;When we approach parsing problems we normally focus on the text as the central element of our algorithm and design our program around combining and manipulating text.  Monadic parsing turns this approach on its head and places the parser front and center, where we instead combine and manipulate parsers.&lt;br /&gt;&lt;br /&gt;This means we need to define a &lt;tt&gt;Parser&lt;/tt&gt; type: &lt;pre&gt;&lt;br /&gt;type Parser a = String -&gt; [(a, String)]&lt;br /&gt;&lt;/pre&gt;A &lt;tt&gt;Parser a&lt;/tt&gt; takes a starting &lt;tt&gt;String&lt;/tt&gt; as its input and parses it to return a single value of type &lt;tt&gt;a&lt;/tt&gt; and the remaining unconsumed &lt;tt&gt;String&lt;/tt&gt;.  There might be multiple valid parses, so we actually return a list of possible parsings instead of a single one.  If the parse fails, we return an empty list signifying no valid parsings.&lt;br /&gt;&lt;br /&gt;We can also use Haskell's &lt;tt&gt;newtype&lt;/tt&gt; feature to encapsulate the implementation and hide it from the user: &lt;pre&gt;&lt;br /&gt;newtype Parser a&lt;br /&gt;  = Parser { runParser :: String -&gt; [(a, String)] }&lt;br /&gt;&lt;/pre&gt;This defines the &lt;tt&gt;Parser&lt;/tt&gt; constructor which we use to wrap our parsing functions: &lt;pre&gt;&lt;br /&gt;Parser :: (String -&gt; [(a, String)]) -&gt; Parser a&lt;br /&gt;&lt;/pre&gt;.. and the &lt;tt&gt;runParser&lt;/tt&gt; function which unwraps the &lt;tt&gt;Parser&lt;/tt&gt; to retrieve the underlying function: &lt;pre&gt;&lt;br /&gt;runParser :: Parser a -&gt; (String -&gt; [(a, String)])&lt;br /&gt;&lt;/pre&gt;Additionally, this encapsulation enables some "magic" later on.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Parsers&lt;/h4&gt;&lt;br /&gt;Haskell has a &lt;tt&gt;Bool&lt;/tt&gt; data type, defined as: &lt;pre&gt;&lt;br /&gt;data Bool = True | False&lt;br /&gt;&lt;/pre&gt;... so let's define a &lt;tt&gt;Parser&lt;/tt&gt; that parses a &lt;tt&gt;True&lt;/tt&gt; value: &lt;pre&gt;&lt;br /&gt;import Data.List&lt;br /&gt;&lt;br /&gt;parseTrue :: Parser Bool&lt;br /&gt;parseTrue = Parser (\str -&gt;&lt;br /&gt;    if (isPrefixOf "True" str)&lt;br /&gt;    then [(True, drop 4 str)] -- Parse succeeds: 1 result&lt;br /&gt;    else []                   -- Parse fails   : 0 results&lt;br /&gt;    )&lt;br /&gt;&lt;/pre&gt;Similarly, we can define a &lt;tt&gt;Parser&lt;/tt&gt; for &lt;tt&gt;False&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;parseFalse :: Parser Bool&lt;br /&gt;parseFalse = Parser (\str -&gt;&lt;br /&gt;    if (isPrefixOf "False" str)&lt;br /&gt;    then [(False, drop 5 str)] -- Parse succeeds: 1 result&lt;br /&gt;    else []                    -- Parse fails   : 0 results&lt;br /&gt;    )&lt;br /&gt;&lt;/pre&gt;Let's test out our parsers using &lt;tt&gt;ghci&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runParser parseTrue "True Story"&lt;br /&gt;[(True, " Story")]&lt;br /&gt;&gt;&gt;&gt; runParser parseFalse "True Story" -- Fails: not False&lt;br /&gt;[]&lt;br /&gt;&gt;&gt;&gt; runParser parseFalse "Falsehood"&lt;br /&gt;[(False, "hood")]&lt;br /&gt;&gt;&gt;&gt; runParser parseFalse " Falsehood" -- Fails: leading space&lt;br /&gt;[]&lt;br /&gt;&lt;/pre&gt;What if we want to also skip initial spaces?  We can define a parser that always succeeds and returns the string trimmed of all leading spaces: &lt;pre&gt;&lt;br /&gt;skipSpaces :: Parser ()&lt;br /&gt;skipSpaces = Parser (\str -&gt;&lt;br /&gt;    [((), dropWhile (== ' ') str)] -- Always succeeds: 1 result&lt;br /&gt;    )&lt;br /&gt;&lt;/pre&gt;Let's confirm it works: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runParser skipSpaces "          Falsehood"&lt;br /&gt;[((), "Falsehood")]&lt;br /&gt;&gt;&gt;&gt; runParser skipSpaces "Apple"&lt;br /&gt;[((), "Apple")]&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Monads&lt;/h4&gt;&lt;br /&gt;Now we want to combine our &lt;tt&gt;Parser&lt;/tt&gt;s so we can parse both a &lt;tt&gt;True&lt;/tt&gt; and a &lt;tt&gt;False&lt;/tt&gt; with optional spaces in between.  This means we need some elegant way to take the unconsumed input from each &lt;tt&gt;Parser&lt;/tt&gt; and feed it directly into the next &lt;tt&gt;Parser&lt;/tt&gt; in the chain.&lt;br /&gt;&lt;br /&gt;Fortunately, Haskell solves this problem cleanly using monads.  A &lt;tt&gt;Monad&lt;/tt&gt; defines an interface to two functions: &lt;pre&gt;&lt;br /&gt;class Monad m where&lt;br /&gt;    return :: a -&gt; m a&lt;br /&gt;    (&gt;&gt;=)  :: m a -&gt; (a -&gt; m b) -&gt; m b&lt;br /&gt;&lt;/pre&gt;Like interfaces in any other language, we can program generically to that interface.  Haskell's &lt;tt&gt;do&lt;/tt&gt; notation works with this generic &lt;tt&gt;Monad&lt;/tt&gt; interface, so we can use the imperative &lt;tt&gt;do&lt;/tt&gt; syntax to manipulate anything that implements &lt;tt&gt;Monad&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Our &lt;tt&gt;Parser&lt;/tt&gt; implements the &lt;tt&gt;Monad&lt;/tt&gt; interface quite nicely: &lt;pre&gt;&lt;br /&gt;instance Monad Parser where&lt;br /&gt;    return a = Parser (\str  -&gt; [(a, str)])&lt;br /&gt;    m &gt;&gt;= f  = Parser (\str1 -&gt;&lt;br /&gt;        -- This is a list comprehension, basically&lt;br /&gt;        [(b, str3) | (a, str2) &lt;- runParser m     str1,&lt;br /&gt;                     (b, str3) &lt;- runParser (f a) str2]&lt;br /&gt;        )&lt;br /&gt;&lt;/pre&gt;This is not a monad tutorial, so I'm glossing over why that is the correct definition or what it even means, but if you want to learn more about monads, I highly recommend: &lt;a href="http://blog.sigfpe.com/2006/08/you-could-have-invented-monads-and.html"&gt;You could have invented monads&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;When we make &lt;tt&gt;Parser&lt;/tt&gt; a &lt;tt&gt;Monad&lt;/tt&gt;, we gain the ability to assemble &lt;tt&gt;Parser&lt;/tt&gt;s using &lt;tt&gt;do&lt;/tt&gt; notation, so let's use &lt;tt&gt;do&lt;/tt&gt; notation to combine multiple parsers in an imperative style: &lt;pre&gt;&lt;br /&gt;trueThenFalse :: Parser (Bool, Bool)&lt;br /&gt;trueThenFalse = do&lt;br /&gt;    t &lt;- parseTrue&lt;br /&gt;    skipSpaces&lt;br /&gt;    f &lt;- parseFalse&lt;br /&gt;    return (t, f)&lt;br /&gt;&lt;/pre&gt;That reads just like imperative code: parse a &lt;tt&gt;True&lt;/tt&gt;, skip some spaces, then parse a &lt;tt&gt;False&lt;/tt&gt;.  Finally, return the two values you parsed.  This seems straightforward enough until you realize we haven't actually parsed any text, yet!  All we've done is combine our smaller parsers into a larger parser poised to be run on as many inputs as we please.&lt;br /&gt;&lt;br /&gt;Let's make sure it works as advertised: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runParser trueThenFalse "True   False leftovers"&lt;br /&gt;[((True, False), " leftovers")]&lt;br /&gt;&gt;&gt;&gt; runParser trueThenFalse "False   True"&lt;br /&gt;[]&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Alternatives&lt;/h4&gt;&lt;br /&gt;Sometimes we want to try multiple parsing alternatives.  For example, what if I want to parse a &lt;tt&gt;True&lt;/tt&gt; or a &lt;tt&gt;False&lt;/tt&gt;?  I can define a &lt;tt&gt;(&lt;|&gt;)&lt;/tt&gt; operator that tries both parsers and then returns the union of their results: &lt;pre&gt;&lt;br /&gt;(&lt;|&gt;) :: Parser a -&gt; Parser a -&gt; Parser a&lt;br /&gt;p1 &lt;|&gt; p2 = Parser (\str -&gt;&lt;br /&gt;    runParser p1 str ++ runParser p2 str&lt;br /&gt;    )&lt;br /&gt;&lt;/pre&gt;Now I can parse a &lt;tt&gt;Bool&lt;/tt&gt; value without specifying which one and the parser will return which one it parsed: &lt;pre&gt;&lt;br /&gt;parseBool :: Parser Bool&lt;br /&gt;parseBool = parseFalse &lt;|&gt; parseTrue&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runParser parseBool "True Story"&lt;br /&gt;[(True, " Story")]&lt;br /&gt;&gt;&gt;&gt; runParser parseBool "Falsehood"&lt;br /&gt;[(False, "hood")]&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Parsing chemistry&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;Parser&lt;/tt&gt;s have one more feature that might surprise you: There is nothing &lt;tt&gt;String&lt;/tt&gt;-specific about them!  With one tiny modification, we can generalize them to accept any type of input: &lt;pre&gt;&lt;br /&gt;newtype Parser s a&lt;br /&gt;  = Parser { runParser :: s -&gt; [(a, s)] }&lt;br /&gt;&lt;br /&gt;instance Monad (Parser s) where&lt;br /&gt;    &amp;lt;EXACT same code as before&amp;gt;&lt;br /&gt;&lt;br /&gt;(&lt;|&gt;) :: Parser s a -&gt; Parser s a -&gt; Parser s a&lt;br /&gt;(&lt;|&gt;) = &amp;lt;EXACT same code as before&amp;gt;&lt;br /&gt;&lt;/pre&gt;Since &lt;tt&gt;s&lt;/tt&gt; is "polymorphic", we can set it to any conceivable type and the above code still works.  The only &lt;tt&gt;String&lt;/tt&gt;-specific behavior lies within the specific parser definitions, and their new compiler-inferred types reflect that: &lt;pre&gt;&lt;br /&gt;-- These parsers only accept &lt;tt&gt;String&lt;/tt&gt;s as input&lt;br /&gt;parseFalse    :: Parser String Bool&lt;br /&gt;parseTrue     :: Parser String Bool&lt;br /&gt;trueThenFalse :: Parser String (Bool, Bool)&lt;br /&gt;&lt;/pre&gt;But there's no reason we can't define entirely different &lt;tt&gt;Parser&lt;/tt&gt;s that accept completely different non-textual input, such as chemical structures.  So I'll switch gears and define parsers for chemical &lt;tt&gt;Structure&lt;/tt&gt;s, where a &lt;tt&gt;Structure&lt;/tt&gt; is some sort of a labeled graph: &lt;pre&gt;&lt;br /&gt;data Structure = Structure {&lt;br /&gt;    graph :: Graph          , -- Adjacency list&lt;br /&gt;    atoms :: Vector AtomName} -- The node labels&lt;br /&gt;&lt;/pre&gt;... with some convenience functions I've defined for manipulating the &lt;tt&gt;Graph&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;-- Return the edges of the graph&lt;br /&gt;bonds :: Graph -&gt; [Edge]&lt;br /&gt;&lt;br /&gt;-- Remove an edge from the graph&lt;br /&gt;deleteBond :: Edge -&gt; Graph -&gt; Graph&lt;br /&gt;&lt;/pre&gt;Now, I can define new &lt;tt&gt;Parser&lt;/tt&gt;s that operate on &lt;tt&gt;Structure&lt;/tt&gt;s instead of &lt;tt&gt;String&lt;/tt&gt;s.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Parsing bonds&lt;/h4&gt;&lt;br /&gt;The most primitive parser I'm interested in parses a single bond.  It requires two &lt;tt&gt;AtomName&lt;/tt&gt;s which specify what kind of bond to look for (i.e. a carbon-carbon bond, except it can be even more specific).  Then, it outputs which two indices in the graph matched that bond-specification: &lt;pre&gt;&lt;br /&gt;parseBond :: AtomName -&gt; AtomName -&gt; Parser Structure (Int, Int)&lt;br /&gt;&lt;/pre&gt;I can use the list monad (i.e. a list comprehension) to define this primitive parser (and don't worry if you can't precisely follow this code): &lt;pre&gt;&lt;br /&gt;parseBond name1 name2&lt;br /&gt;  = Parser $ \(Structure oldGraph atoms) -&gt; do&lt;br /&gt;    -- The first atom must match "name1"&lt;br /&gt;    i1 &lt;- toList (findIndices (== name1) atoms)&lt;br /&gt;&lt;br /&gt;    -- Some neighboring atom must match "name2"&lt;br /&gt;    i2 &lt;- filter (\i -&gt; atoms ! i == name2) (oldGraph ! i1)&lt;br /&gt;&lt;br /&gt;    -- Remove our matched bond from the graph&lt;br /&gt;    let newGraph = deleteBond (i1, i2) oldGraph&lt;br /&gt;&lt;br /&gt;    -- .. and return the matched indices&lt;br /&gt;    return ((i1, i2), Structure newGraph atoms)&lt;br /&gt;&lt;/pre&gt;Haskell strongly encourages a pure functional style, which keeps me from "cheating" and using side effects or mutation to do the parsing.  By sticking to a pure implementation, I gain several bonus features for free: &lt;ul&gt;&lt;li&gt; If our bond occurs more than once, this correctly matches each occurrence, even if some matches share an atom &lt;li&gt; If both &lt;tt&gt;AtomName&lt;/tt&gt;s are identical, this correctly returns both orientations for each matched bond &lt;li&gt; This handles backtracking with &lt;tt&gt;(&lt;|&gt;)&lt;/tt&gt; correctly &lt;li&gt; I can parallelize the search easily since every search branch is pure &lt;/ul&gt;I got all of that for just 6 lines of code!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Parsing substructures&lt;/h4&gt;&lt;br /&gt;Now I can build more sophisticated parsers on top of this simple bond parsers.  For example, I can build a generic substructure parser which takes a sub-&lt;tt&gt;Structure&lt;/tt&gt; to match and returns a list of matched indices: &lt;pre&gt;&lt;br /&gt;parseSubstructure :: Structure -&gt; Parse Structure [Int]&lt;br /&gt;&lt;/pre&gt;Again, if you don't precisely understand the code, that's okay: &lt;pre&gt;&lt;br /&gt;parseSubstructure (Structure graph as)&lt;br /&gt;    -- Use the State monad to keep track of matches&lt;br /&gt;  = (`evalStateT` (V.replicate (V.length as) Nothing)) $ do&lt;br /&gt;&lt;br /&gt;        -- foreach (i1, i2) in (bonds graph):&lt;br /&gt;        forM_ (bonds graph) $ \(i1, i2) -&gt; do&lt;br /&gt;&lt;br /&gt;            -- Match the bond&lt;br /&gt;            (i1', i2') &lt;- lift $ parseBond (as ! i1) (as ! i2)&lt;br /&gt;&lt;br /&gt;            -- The match must be consistent with other matches&lt;br /&gt;            matches    &lt;- get&lt;br /&gt;            let consistent i1 i1' = case (matches ! i1) of&lt;br /&gt;                    Nothing   -&gt; True&lt;br /&gt;                    Just iOld -&gt; iOld == i1'&lt;br /&gt;            guard (consistent i1 i1' &amp;&amp; consistent i2 i2')&lt;br /&gt;&lt;br /&gt;            -- Update the match list&lt;br /&gt;            put (matches // [(i1, Just i1'), (i2, Just i2')])&lt;br /&gt;&lt;br /&gt;        -- Return the final list of matches&lt;br /&gt;        matchesFinal &lt;- get&lt;br /&gt;        justZ . sequence . toList $ matchesFinal&lt;br /&gt;&lt;/pre&gt;Like before, the code detects all matching permutations and backtracks if any step fails.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Reusable abstractions&lt;/h4&gt;&lt;br /&gt;I find it pretty amazing that you can build a substructure parser in just 18 lines of Haskell code.  You might say I'm cheating because I'm not counting the amount of lines of code I took to define the &lt;tt&gt;Parser&lt;/tt&gt; type, the &lt;tt&gt;Monad&lt;/tt&gt; implementation, and the &lt;tt&gt;(&lt;|&gt;)&lt;/tt&gt; type.  However, the truth is I can actually get all of those features using 1 line of Haskell: &lt;pre&gt;&lt;br /&gt;type Parser s = StateT s []&lt;br /&gt;-- and rename all 'Parser' constructors to 'StateT'&lt;br /&gt;&lt;/pre&gt;So I lied: it's actually 19 lines of code.&lt;br /&gt;&lt;br /&gt;I don't expect the reader to know what &lt;tt&gt;StateT&lt;/tt&gt; or &lt;tt&gt;[]&lt;/tt&gt; are, but what you should take away from this is that both of them are part of every Haskell programmer's standard repertoire of abstractions.&lt;br /&gt;&lt;br /&gt;Moreover, when I combine them I automatically get a correct &lt;tt&gt;Monad&lt;/tt&gt; implementation (i.e. &lt;tt&gt;do&lt;/tt&gt; notation) and a correct &lt;tt&gt;Alternative&lt;/tt&gt; implementation (which provides the &lt;tt&gt;(&lt;|&gt;)&lt;/tt&gt; function), both for free!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;This is just one of many abstractions I used to complete a structural search engine for proteins.  Now that it's done, I'll be blogging more frequently about various aspects of the engine's design to give people ideas for how they could use Haskell in their own projects.  I hope these kinds of code examples pique people's interest in learning Haskell.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Appendix&lt;/h4&gt;&lt;br /&gt;I've included the full code for the &lt;tt&gt;String&lt;/tt&gt;-based &lt;tt&gt;Parser&lt;/tt&gt;s.  The &lt;tt&gt;Structure&lt;/tt&gt;-based &lt;tt&gt;Parser&lt;/tt&gt;s depend on several project-specific data types, so I will just release them later as part of my protein search engine and perhaps factor them out into their own library.&lt;br /&gt;&lt;br /&gt;Also, as a stylistic note, I prefer to use &lt;tt&gt;($)&lt;/tt&gt; to remove dangling final parentheses like so: &lt;pre&gt;&lt;br /&gt;Parse (\str -&gt;        =&gt;  Parse $ \str -&gt;&lt;br /&gt;    someCode          =&gt;      someCode&lt;br /&gt;    )                 =&gt;&lt;br /&gt;&lt;/pre&gt;... but I didn't want to digress from the post's topic by explaining how the &lt;tt&gt;($)&lt;/tt&gt; operator behaves. &lt;pre&gt;&lt;br /&gt;import Data.List&lt;br /&gt;&lt;br /&gt;newtype Parser a&lt;br /&gt;  = Parser { runParser :: String -&gt; [(a, String)] }&lt;br /&gt;&lt;br /&gt;parseTrue :: Parser Bool&lt;br /&gt;parseTrue = Parser (\str -&gt;&lt;br /&gt;    if (isPrefixOf "True" str)&lt;br /&gt;    then [(True, drop 4 str)]&lt;br /&gt;    else []&lt;br /&gt;    )&lt;br /&gt;&lt;br /&gt;parseFalse :: Parser Bool&lt;br /&gt;parseFalse = Parser (\str -&gt;&lt;br /&gt;    if (isPrefixOf "False" str)&lt;br /&gt;    then [(False, drop 5 str)]&lt;br /&gt;    else []&lt;br /&gt;    )&lt;br /&gt;&lt;br /&gt;skipSpaces :: Parser ()&lt;br /&gt;skipSpaces = Parser (\str -&gt;&lt;br /&gt;    [((), dropWhile (== ' ') str)]&lt;br /&gt;    )&lt;br /&gt;&lt;br /&gt;instance Monad Parser where&lt;br /&gt;    return a = Parser (\str  -&gt; [(a, str)])&lt;br /&gt;    m &gt;&gt;= f  = Parser (\str1 -&gt;&lt;br /&gt;        [(b, str3) | (a, str2) &lt;- runParser m     str1,&lt;br /&gt;                     (b, str3) &lt;- runParser (f a) str2]&lt;br /&gt;        )&lt;br /&gt;&lt;br /&gt;trueThenFalse :: Parser (Bool, Bool)&lt;br /&gt;trueThenFalse = do&lt;br /&gt;    t &lt;- parseTrue&lt;br /&gt;    skipSpaces&lt;br /&gt;    f &lt;- parseFalse&lt;br /&gt;    return (t, f)&lt;br /&gt;&lt;br /&gt;(&lt;|&gt;) :: Parser a -&gt; Parser a -&gt; Parser a&lt;br /&gt;p1 &lt;|&gt; p2 = Parser (\str -&gt;&lt;br /&gt;    runParser p1 str ++ runParser p2 str&lt;br /&gt;    )&lt;br /&gt;&lt;br /&gt;parseBool :: Parser Bool&lt;br /&gt;parseBool = parseFalse &lt;|&gt; parseTrue&lt;br /&gt;&lt;/pre&gt;</description><link>http://www.haskellforall.com/2012/10/parsing-chemical-substructures.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>14</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-7453770074572573544</guid><pubDate>Sun, 07 Oct 2012 03:54:00 +0000</pubDate><atom:updated>2012-10-08T12:00:44.291-07:00</atom:updated><title>pipes-2.4: Proxy transformers, extra categories, utilities, and benchmarks</title><description>This release packs a LOT of new features, so I will begin with the most significant feature: proxy transformers.  The proxy transformer pattern provides a very simple extension framework that cleanly solves many problems that iteratee library authors face.&lt;br /&gt;&lt;br /&gt;Users of the library should read &lt;a href="http://hackage.haskell.org/packages/archive/pipes/2.4.0/doc/html/Control-Proxy-Trans-Tutorial.html"&gt;Control.Proxy.Trans.Tutorial&lt;/a&gt;, which explains how proxy transformers work.  However, this post also provides a decent introduction to them, too.&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Introduction&lt;/h4&gt;&lt;br /&gt;Wouldn't it be nice if you could catch and handle errors within a proxy?  Now you can!  It's as simple as: &lt;pre&gt;&lt;br /&gt;import Control.Monad (forever)&lt;br /&gt;import Control.Monad.Trans (lift)&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Either as E&lt;br /&gt;import Safe (readMay)&lt;br /&gt;&lt;br /&gt;promptInts :: () -&gt; EitherP String Proxy C () () Int IO r&lt;br /&gt;promptInts () = recover $ forever $ do&lt;br /&gt;    str &lt;- lift getLine&lt;br /&gt;    case readMay str of&lt;br /&gt;        Nothing -&gt; E.throw "Could not parse an integer"&lt;br /&gt;        Just n  -&gt; liftP $ respond n&lt;br /&gt;&lt;br /&gt;recover p =&lt;br /&gt;    p `E.catch` (\str -&gt; lift (putStrLn str) &gt;&gt; recover p)&lt;br /&gt;&lt;br /&gt;main = runProxy $ runEitherK $ mapP printD &lt;-&lt; promptInts&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; main&lt;br /&gt;1&amp;lt;Enter&amp;gt;&lt;br /&gt;1&lt;br /&gt;Test&amp;lt;Enter&amp;gt;&lt;br /&gt;Could not parse an integer&lt;br /&gt;Apple&amp;lt;Enter&amp;gt;&lt;br /&gt;Could not parse an integer&lt;br /&gt;5&amp;lt;Enter&amp;gt;&lt;br /&gt;5&lt;br /&gt;&lt;/pre&gt;The above program condenses many new features of this release into a nice compact example and I'll use it to show-case each feature.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Proxy transformers&lt;/h4&gt;&lt;br /&gt;The above program uses the &lt;tt&gt;EitherP&lt;/tt&gt; proxy transformer.  To access this feature, you just import the transformer you wish to use: &lt;pre&gt;&lt;br /&gt;import Control.Proxy.Trans.Either as E&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;Control.Proxy&lt;/tt&gt; imports all the remaining machinery you need.&lt;br /&gt;&lt;br /&gt;&lt;tt&gt;EitherP&lt;/tt&gt; extends any proxy-like type with the ability to &lt;tt&gt;throw&lt;/tt&gt; and &lt;tt&gt;catch&lt;/tt&gt; errors locally, as if it lived inside a native &lt;tt&gt;EitherT&lt;/tt&gt; block.  It does so in such a way that preserves composition (and the category laws!), so you can directly compose the result without unwrapping the &lt;tt&gt;EitherP&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;When you are done composing, just use &lt;tt&gt;runEitherK&lt;/tt&gt; to convert it back to the underlying proxy: &lt;pre&gt;&lt;br /&gt;runEitherK&lt;br /&gt;  :: (q -&gt; EitherP e p a' a b' b m r )&lt;br /&gt;  -&gt; (q -&gt; p a' a b' b m (Either e r))&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Utilities&lt;/h4&gt;&lt;br /&gt;This release introduces the "proxy prelude", a set of convenience functions for users of the library.  &lt;tt&gt;Control.Proxy&lt;/tt&gt; automatically exports these and they don't clash with the Prelude or any common libraries.&lt;br /&gt;&lt;br /&gt;Our old friend &lt;tt&gt;printer&lt;/tt&gt; got a name-change and now goes by &lt;tt&gt;printD&lt;/tt&gt;.  This utility function prints all values bound downstream: &lt;pre&gt;&lt;br /&gt;printD :: Show a =&gt; x -&gt; Proxy x a x a IO r&lt;br /&gt;&lt;/pre&gt;I provide many more utility functions under the &lt;tt&gt;Control.Proxy.Prelude&lt;/tt&gt; hierarchy, and people who enjoyed my &lt;a href="http://www.haskellforall.com/2012/09/the-functor-design-pattern.html"&gt;functor design pattern&lt;/a&gt; post will also enjoy the abundance of cute trivial examples of the functor pattern in the documentation for &lt;tt&gt;Control.Proxy.Prelude.Base&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Proxy transformers are functors&lt;/h4&gt;&lt;br /&gt;However, this release includes a far more sophisticated set of functors: the proxy transformers themselves.  Each proxy transformer implements the &lt;tt&gt;ProxyTrans&lt;/tt&gt; class which defines two functions: &lt;tt&gt;mapP&lt;/tt&gt; and &lt;tt&gt;liftP&lt;/tt&gt;, related by the equation: &lt;pre&gt;&lt;br /&gt;mapP = (liftP .)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;mapP&lt;/tt&gt; defines two separate functors.&lt;br /&gt;&lt;br /&gt;The first functor behaves like a traditional monad transformer, converting the base Kleisli category to the extended Kleisli category: &lt;pre&gt;&lt;br /&gt;mapP return = return&lt;br /&gt;&lt;br /&gt;mapP (f &gt;=&gt; g) = mapP f &gt;=&gt; mapP g&lt;br /&gt;&lt;/pre&gt;You can write these laws using &lt;tt&gt;liftP&lt;/tt&gt; to see that our proxy transformers behave like ordinary monad transformers: &lt;pre&gt;&lt;br /&gt;liftP $ return x = return x&lt;br /&gt;&lt;br /&gt;do x &lt;- liftP m&lt;br /&gt;   liftP $ f x&lt;br /&gt;= liftP $ do x &lt;- m&lt;br /&gt;             f x&lt;br /&gt;&lt;/pre&gt;The above program uses this capacity of &lt;tt&gt;liftP&lt;/tt&gt; to lift operations from the &lt;tt&gt;Proxy&lt;/tt&gt; monad to the &lt;tt&gt;EitherP String Proxy&lt;/tt&gt; monad.&lt;br /&gt;&lt;br /&gt;The second functor lifts the base proxy composition to the extended proxy composition: &lt;pre&gt;&lt;br /&gt;mapP idT = idT&lt;br /&gt;&lt;br /&gt;mapP (p1 &gt;-&gt; p2) = mapP p1 &gt;-&gt; mapP p2&lt;br /&gt;&lt;/pre&gt;This latter functor lets you compose simpler proxies with extended proxies.  The above program uses &lt;tt&gt;mapP&lt;/tt&gt; in this capacity to promote &lt;tt&gt;printD&lt;/tt&gt; for composition with &lt;tt&gt;promptInts&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;mapP printD &lt;-&lt; promptInts&lt;br /&gt;&lt;/pre&gt;This demonstrates a concrete application of the functor design pattern, allowing seamless interoperability between proxies written to varying feature sets.  The proxy transformers lift both the monad instance and the composition instance correctly so that simpler proxies play nicely with extended proxies.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Type signatures&lt;/h4&gt;&lt;br /&gt;The above program demos the new replacement for &lt;tt&gt;Void&lt;/tt&gt;: &lt;tt&gt;C&lt;/tt&gt;.  This will shorten type signatures and also removes the dependency on &lt;tt&gt;void&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Also, now the &lt;tt&gt;Proxy&lt;/tt&gt; type is a newtype around the underlying &lt;tt&gt;FreeT&lt;/tt&gt; implementation.  This gives nicer type errors when things go wrong.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Proxy Transformer Stacks&lt;/h4&gt;&lt;br /&gt;Just like monad transformers, you can stack proxy transformers to automatically combine their effects.  By combining the &lt;tt&gt;StateP&lt;/tt&gt; and &lt;tt&gt;EitherP&lt;/tt&gt; proxy transformers, you can implement non-backtracking parsers for free: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE GeneralizedNewtypeDeriving, OverloadedStrings #-}&lt;br /&gt;&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Either as E&lt;br /&gt;import Control.Proxy.Trans.State&lt;br /&gt;import Data.Text as T hiding (take)&lt;br /&gt;&lt;br /&gt;newtype ParseP p a' a b' b m r =&lt;br /&gt;    ParseP { unParseP ::&lt;br /&gt;        StateP Text (EitherP Text p) a' a b' b m r }&lt;br /&gt;    deriving (Monad, MonadTrans, Channel)&lt;br /&gt;&lt;br /&gt;instance ProxyTrans ParseP where&lt;br /&gt;    liftP = ParseP . liftP . liftP&lt;br /&gt;&lt;br /&gt;runParseK&lt;br /&gt;  :: (q -&gt; ParseP p a' a b' b m r)&lt;br /&gt;  -&gt; (q -&gt; p a' a b' b m (Either Text (r, Text)))&lt;br /&gt;runParseK = runEitherK . runStateK T.empty . (unParseP .)&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;Channel&lt;/tt&gt; type class defines proxy composition, so we can compose our parsing proxies seamlessly.&lt;br /&gt;&lt;br /&gt;Let's write a few parsing primitives: &lt;pre&gt;&lt;br /&gt;import Data.Monoid&lt;br /&gt;import Data.Text.IO as T&lt;br /&gt;import Prelude hiding (take)&lt;br /&gt;&lt;br /&gt;take n = ParseP go where&lt;br /&gt;    go = do&lt;br /&gt;        s &lt;- get&lt;br /&gt;        if (T.length s &lt; n)&lt;br /&gt;        then do&lt;br /&gt;            s' &lt;- liftP $ liftP $ request ()&lt;br /&gt;            put (s &lt;&gt; s')&lt;br /&gt;            go&lt;br /&gt;        else do&lt;br /&gt;            let (h, t) = T.splitAt n s&lt;br /&gt;            put t&lt;br /&gt;            return h&lt;br /&gt;&lt;br /&gt;parseFail str = ParseP $ liftP $ E.throw str&lt;br /&gt;&lt;br /&gt;string str = do&lt;br /&gt;    str' &lt;- take (T.length str)&lt;br /&gt;    if (str' == str)&lt;br /&gt;    then return str&lt;br /&gt;    else parseFail $&lt;br /&gt;        "Expected: " &lt;&gt; str &lt;&gt; " -- Found: " &lt;&gt; str'&lt;br /&gt;&lt;/pre&gt;You wouldn't even know those were proxies if it were not for that single &lt;tt&gt;request&lt;/tt&gt; statement.&lt;br /&gt;&lt;br /&gt;Let's write a contrived parser based off of those primitives: &lt;pre&gt;&lt;br /&gt;parser () = do&lt;br /&gt;    string "Hello"&lt;br /&gt;    str &lt;- take 5&lt;br /&gt;    lift $ T.putStrLn str&lt;br /&gt;&lt;/pre&gt;... and supply it with some input: &lt;pre&gt;&lt;br /&gt;source () = do&lt;br /&gt;    respond "Hell"&lt;br /&gt;    respond "o, world!"&lt;br /&gt;&lt;/pre&gt;Now compose! &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runProxy $ runParserK $ parser &lt;-&lt; mapP source&lt;br /&gt;, wor&lt;br /&gt;Right ((),"ld!")&lt;br /&gt;&lt;/pre&gt;Let's see how failed parses turn out: &lt;pre&gt;&lt;br /&gt;invalid () = do&lt;br /&gt;    respond "A"&lt;br /&gt;    respond "AAAAAAAA"&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runProxy $ runParseK $ parser &lt;-&lt; mapP invalid&lt;br /&gt;Left "Expected: Hello -- Found: AAAAA"&lt;br /&gt;&lt;/pre&gt;I didn't include parsers in the library because I didn't want to add a &lt;tt&gt;bytestring&lt;/tt&gt; or &lt;tt&gt;text&lt;/tt&gt; dependency to the main &lt;tt&gt;pipes&lt;/tt&gt; package.  Instead, I will release the parsing extension as a separate library.  This library will provide you with the streaming benefits of attoparsec with the ability to interleave effects.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Pushback&lt;/h4&gt;&lt;br /&gt;The above parsing example suggests my solution to push-back, which is to give each proxy its own local state using the &lt;tt&gt;StateP&lt;/tt&gt; proxy transformer.  You can then use the local state to keep track of unused input, as the above parsing example did.&lt;br /&gt;&lt;br /&gt;Like all proxy transformers, this extension requires no special integration with the underlying proxy type and you can layer it anywhere within a proxy transformer stack with no special considerations.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Extra categories&lt;/h4&gt;&lt;br /&gt;The library now provides two additional categories for interacting with the &lt;tt&gt;Proxy&lt;/tt&gt; type.  These are term-rewriting categories (I believe the technical term is "sesquicategory", but I may be mistaken).&lt;br /&gt;&lt;br /&gt;The first category's composition operator replaces all &lt;tt&gt;request&lt;/tt&gt; statements within a &lt;tt&gt;Proxy&lt;/tt&gt; with a suitably typed replacement: &lt;pre&gt;&lt;br /&gt;f /&amp;lt;/ g -- Replace all occurrences of 'request' in 'f' with 'g'&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;request&lt;/tt&gt; is the identity of this category, so we expect that: &lt;pre&gt;&lt;br /&gt;-- Replacing 'request' with 'request' changes nothing&lt;br /&gt;f /&amp;lt;/ request = f&lt;br /&gt;&lt;br /&gt;-- Replacing 'request' with 'f' gives 'f'&lt;br /&gt;request /&amp;lt;/ f = f&lt;br /&gt;&lt;/pre&gt;Also, this substitution is associative: &lt;pre&gt;&lt;br /&gt;(f /&amp;lt;/ g) /&amp;lt;/ h = f /&amp;lt;/ (g /&amp;lt;/ h)&lt;br /&gt;&lt;/pre&gt;Similarly, the &lt;tt&gt;respond&lt;/tt&gt; command has its own substition operator, &lt;tt&gt;(\&lt;\)&lt;/tt&gt;, and they form their own category: &lt;pre&gt;&lt;br /&gt;f \&amp;lt;\ g  -- Replaces all 'respond's in 'g' with 'f'&lt;br /&gt;&lt;br /&gt;f \&amp;lt;\ respond = f&lt;br /&gt;&lt;br /&gt;respond \&lt;\ f = f&lt;br /&gt;&lt;br /&gt;(f \&amp;lt;\ g) \&amp;lt;\ h = f \&amp;lt;\ (g \&amp;lt;\ h)&lt;br /&gt;&lt;/pre&gt;Each category distributes in one direction over the Kleisli category: &lt;pre&gt;&lt;br /&gt;-- Distributivity&lt;br /&gt;r \&amp;lt;\ (f &lt;=&lt; g) = (r \&amp;lt;\ f) &lt;=&lt; (r \&amp;lt;\ g)&lt;br /&gt;&lt;br /&gt;-- Zero&lt;br /&gt;r \&amp;lt;\ return = return&lt;br /&gt;&lt;br /&gt;-- Distributivity&lt;br /&gt;(f &lt;=&lt; g) /&amp;lt;/ r = (f /&amp;lt;/ r) &lt;=&lt; (g /&amp;lt;/ r)&lt;br /&gt;&lt;br /&gt;-- Zero&lt;br /&gt;return /&amp;lt;/ r = return&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Lifting &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;I originally envisioned that proxy transformers would also automatically lift &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; statements.  The laws for this lifting are quite simple: &lt;pre&gt;&lt;br /&gt;mapP request = request&lt;br /&gt;&lt;br /&gt;mapP respond = respond&lt;br /&gt;&lt;/pre&gt;In other words, the functor laws, applied to the identity of the two new categories I just introduced.  However, unfortunately Haskell's type class system severely got in my way and I could not solve the issue before the release.  I have a tentative plan for how to solve this using Edward's &lt;tt&gt;constraint&lt;/tt&gt; package but it will take time.  Until then, you will have to manually lift &lt;tt&gt;request&lt;/tt&gt; and &lt;tt&gt;respond&lt;/tt&gt; statements from the base &lt;tt&gt;Proxy&lt;/tt&gt; type.&lt;br /&gt;&lt;br /&gt;Overall, I was pretty disappointed with Haskell's type class system (more so than usual).  This library really exercised it considerably and I even had to drop an additional proxy transformer because it was unimplementable due to the broken constraint system.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Performance&lt;/h4&gt;&lt;br /&gt;Raw proxies give performance comparable to &lt;tt&gt;conduit&lt;/tt&gt; when doing simple &lt;tt&gt;IO&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;import Control.Proxy hiding (await)&lt;br /&gt;import Data.Conduit&lt;br /&gt;import Data.Conduit.List as L&lt;br /&gt;import Data.Maybe (fromJust) -- You did not see this&lt;br /&gt;&lt;br /&gt;n = 100000 :: Int&lt;br /&gt;&lt;br /&gt;-- Choose your poison&lt;br /&gt;main = runProxy $ printD &lt;-&lt; enumFromToS 1 n&lt;br /&gt;main = L.enumFromTo 1 n&lt;br /&gt;    $$ forever (await &gt;&gt;= lift . print . fromJust)&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;pipes&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;real    0m1.761s&lt;br /&gt;user    0m0.384s&lt;br /&gt;sys     0m0.712s&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;conduit&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;real    0m1.528s&lt;br /&gt;user    0m0.224s&lt;br /&gt;sys     0m0.660s&lt;br /&gt;&lt;/pre&gt;Conduit is 15% faster.&lt;br /&gt;&lt;br /&gt;The margin is substantially larger for entirely pure code: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;import Control.Proxy hiding (await)&lt;br /&gt;import Data.Conduit&lt;br /&gt;import Data.Conduit.List as L&lt;br /&gt;&lt;br /&gt;n = 100000 :: Int&lt;br /&gt;&lt;br /&gt;main = runProxy $ discard &lt;-&lt; enumFromToS 1 n&lt;br /&gt;&lt;br /&gt;discard' = do&lt;br /&gt;    a &lt;- await&lt;br /&gt;    case a of&lt;br /&gt;        Nothing -&gt; return ()&lt;br /&gt;        Just _  -&gt; discard'&lt;br /&gt;&lt;br /&gt;main = L.enumFromTo 1 n $$ discard'&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;pipes&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;real    0m0.085s&lt;br /&gt;user    0m0.088s&lt;br /&gt;sys     0m0.000s&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;conduit&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;real    0m0.011s&lt;br /&gt;user    0m0.004s&lt;br /&gt;sys     0m0.004s&lt;br /&gt;&lt;/pre&gt;Conduit is almost 8(!) times faster.&lt;br /&gt;&lt;br /&gt;Conduit dramatically improves for entirely pure code since it bends the monad transformer laws to skip binds in the base monad.  This is one reason that this &lt;tt&gt;pipes&lt;/tt&gt; release type-classes all the &lt;tt&gt;Proxy&lt;/tt&gt; operations.  If people request that I copy &lt;tt&gt;conduit&lt;/tt&gt;'s approach, I will release a separate library that copies &lt;tt&gt;conduit&lt;/tt&gt;'s optional monad bind and have it implement all the same type-classes.  Then all the proxy transformers are guaranteed to work transparently with it because they abstract completely over the type classes.&lt;br /&gt;&lt;br /&gt;Additionally, I want to note that the &lt;tt&gt;pipes&lt;/tt&gt; library currently has only one optimization &lt;tt&gt;PRAGMA&lt;/tt&gt; in the entire library: &lt;pre&gt;&lt;br /&gt;{-# INLINABLE mapK #-} -- An obscure utility function&lt;br /&gt;&lt;/pre&gt;... whereas &lt;tt&gt;conduit&lt;/tt&gt; uses a considerable number of rewrite rules and &lt;tt&gt;INLINABLE&lt;/tt&gt; statements.  I don't know how much these contribute to &lt;tt&gt;conduit&lt;/tt&gt;'s speed, but I will copy Michael's optimizations in the next few releases and benchmark how much they contribute to performance.&lt;br /&gt;&lt;br /&gt;Additionally, I've also benchmarked the overhead of proxy transformers.  First, comparing performance for some trivial &lt;tt&gt;IO&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Writer&lt;br /&gt;import Data.Monoid&lt;br /&gt;&lt;br /&gt;n = 100000 :: Int&lt;br /&gt;&lt;br /&gt;main = runProxy $ without &lt;-&lt; enumFromToS 1 n&lt;br /&gt;&lt;br /&gt;main :: IO ((), Sum Int)&lt;br /&gt;main = runProxy $ runWriterK $ with &lt;-&lt; mapP (enumFromToS 1 n)&lt;br /&gt;&lt;br /&gt;with&lt;br /&gt; :: (Monoid w, Show a)&lt;br /&gt; =&gt; () -&gt; WriterP w Proxy () a () C IO r&lt;br /&gt;with () = forever $ do&lt;br /&gt;    n &lt;- liftP $ request ()&lt;br /&gt;    lift $ print n&lt;br /&gt;&lt;br /&gt;without :: (Show a) =&gt; () -&gt; Proxy () a () C IO r&lt;br /&gt;without () = forever $ do&lt;br /&gt;    n &lt;- request ()&lt;br /&gt;    lift $ print n&lt;br /&gt;&lt;/pre&gt;Using the bind in the &lt;tt&gt;WriterP w Proxy&lt;/tt&gt; monad (i.e. &lt;tt&gt;with&lt;/tt&gt;): &lt;pre&gt;&lt;br /&gt;real    0m1.739s&lt;br /&gt;user    0m0.396s&lt;br /&gt;sys     0m0.680s&lt;br /&gt;&lt;/pre&gt;Using the bind in the &lt;tt&gt;Proxy&lt;/tt&gt; monad (i.e. &lt;tt&gt;without&lt;/tt&gt;): &lt;pre&gt;&lt;br /&gt;real    0m1.704s&lt;br /&gt;user    0m0.368s&lt;br /&gt;sys     0m0.668s&lt;br /&gt;&lt;/pre&gt;A difference of 2%(!).&lt;br /&gt;&lt;br /&gt;Again, the difference widens if you switch to pure code: &lt;pre&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;import Control.Proxy&lt;br /&gt;import Control.Proxy.Trans.Writer&lt;br /&gt;import Data.Monoid&lt;br /&gt;&lt;br /&gt;n = 100000 :: Int&lt;br /&gt;&lt;br /&gt;main = runProxy $ without &lt;-&lt; enumFromToS 1 n&lt;br /&gt;&lt;br /&gt;main :: IO ((), Sum Int)&lt;br /&gt;main = runProxy $ runWriterK $ with &lt;-&lt; mapP (enumFromToS 1 n)&lt;br /&gt;&lt;br /&gt;with&lt;br /&gt; :: (Monoid w, Show a)&lt;br /&gt; =&gt; () -&gt; WriterP w Proxy () a () C IO r&lt;br /&gt;with () = forever $ liftP $ request ()&lt;br /&gt;&lt;br /&gt;without :: (Show a) =&gt; () -&gt; Proxy () a () C IO r&lt;br /&gt;without () = forever $ request ()&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;WriterP w Proxy&lt;/tt&gt;'s bind: &lt;pre&gt;&lt;br /&gt;real    0m0.134s&lt;br /&gt;user    0m0.124s&lt;br /&gt;sys     0m0.008s&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;Proxy&lt;/tt&gt;'s bind: &lt;pre&gt;&lt;br /&gt;real    0m0.084s&lt;br /&gt;user    0m0.076s&lt;br /&gt;sys     0m0.004s&lt;br /&gt;&lt;/pre&gt;Now it's about a factor of 2.&lt;br /&gt;&lt;br /&gt;So I can summarize these benchmarks by saying that if you are doing even a little bit of &lt;tt&gt;IO&lt;/tt&gt;, the performance differences are pretty small, and as I aggressively optimize the library, they should get even smaller.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Switch to &lt;tt&gt;free&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;Edward was kind enough to migrate my &lt;tt&gt;transformers-free&lt;/tt&gt; functionality into his &lt;tt&gt;free&lt;/tt&gt; package, so now &lt;tt&gt;pipes&lt;/tt&gt; uses &lt;tt&gt;free&lt;/tt&gt; for its free monad transformer dependency.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Resource management&lt;/h4&gt;&lt;br /&gt;I plan on releasing a &lt;tt&gt;Proxy&lt;/tt&gt;-like type that implements resource management that will replace the &lt;tt&gt;Frame&lt;/tt&gt; type.  This type will include functions to promote existing &lt;tt&gt;Proxy&lt;/tt&gt; code to this resource-managed version.  Until then, you will have to manually manage resources by opening all file handles before composition, and closing them all afterwards, like so: &lt;pre&gt;&lt;br /&gt;import Control.Proxy&lt;br /&gt;import System.IO&lt;br /&gt;&lt;br /&gt;main = do&lt;br /&gt;    h &lt;- openFile "test.txt" WriteMode&lt;br /&gt;    runProxy $ hPrintD h &lt;-&lt; enumFromToS 1 10&lt;br /&gt;    hClose h&lt;br /&gt;&lt;/pre&gt;... or you can use Michael's &lt;tt&gt;ResourceT&lt;/tt&gt; in the base monad, if that is your thing.&lt;br /&gt;&lt;br /&gt;You won't get the benefit of conserving handles, but you will still get predictable streaming performance.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Library writers&lt;/h4&gt;&lt;br /&gt;If you are considering building off the &lt;tt&gt;pipes&lt;/tt&gt; library, I recommend implementing any functionality using the &lt;tt&gt;Proxy&lt;/tt&gt; type, which I guarantee will be promotable to any future extensions, and I plan on personally writing several &lt;tt&gt;Proxy&lt;/tt&gt;-based libraries over the next few months.&lt;br /&gt;&lt;br /&gt;While I still preserve the &lt;tt&gt;Pipe&lt;/tt&gt; type, I fully endorse the &lt;tt&gt;Proxy&lt;/tt&gt; type as the type to standardize on as it has many more nice theoretical properties than the &lt;tt&gt;Pipe&lt;/tt&gt; type and also supports greater functionality.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;This release is very close to the final state I envisioned for the core &lt;tt&gt;pipes&lt;/tt&gt; library.  Most existing features won't disappear, with the exception of &lt;tt&gt;Control.Frame&lt;/tt&gt;, which I will phase out once I release a suitable replacement in a separate library.&lt;br /&gt;&lt;br /&gt;Most additional features that I plan on implementing will go into separate libraries that build on top of this one.  I only plan on adding functionality to the core library if I discover additional interesting structure for the &lt;tt&gt;Proxy&lt;/tt&gt; type.</description><link>http://www.haskellforall.com/2012/10/pipes-24-proxy-transformers-extra.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>5</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-3246352678551094332</guid><pubDate>Thu, 20 Sep 2012 04:52:00 +0000</pubDate><atom:updated>2012-09-19T21:54:15.269-07:00</atom:updated><title>The MonadTrans class is missing a method</title><description>My work on &lt;tt&gt;pipes-2.4&lt;/tt&gt; leads me to the inescapable conclusion that the &lt;tt&gt;MonadTrans&lt;/tt&gt; class is incomplete.  In an ideal world, this is what it should actually look like: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE Rank2Types #-}&lt;br /&gt;&lt;br /&gt;class MonadTrans t where&lt;br /&gt;    lift  :: (Monad m, Monad (t m)) =&gt; m a -&gt; t m a&lt;br /&gt;    embed :: (Monad m, Monad (t m), Monad (t n))&lt;br /&gt;          =&gt; (forall a .   m a -&gt; t n a)&lt;br /&gt;          -&gt; (forall b . t m b -&gt; t n b)&lt;br /&gt;          -- This last forall is optional&lt;br /&gt;&lt;br /&gt;(&gt;|&gt;)&lt;br /&gt; :: (Monad f, Monad g, Monad (t g), Monad (t h),&lt;br /&gt;     MonadTrans t)&lt;br /&gt; =&gt; (forall a . f a -&gt; t g a)&lt;br /&gt; -&gt; (forall b . g b -&gt; t h b)&lt;br /&gt; -&gt; (forall c . f c -&gt; t h c) -- This last forall is optional&lt;br /&gt;(f &gt;|&gt; g) x = embed g (f x)&lt;br /&gt;&lt;br /&gt;squash :: (Monad (t (t m)), Monad (t m), MonadTrans t)&lt;br /&gt;       =&gt; t (t m) a -&gt; t m a&lt;br /&gt;squash = embed id&lt;br /&gt;&lt;br /&gt;mapT&lt;br /&gt; :: (Monad m, Monad n, Monad (t m), Monad (t n), MonadTrans t)&lt;br /&gt; =&gt; (forall a . m a -&gt; n a) -&gt; t m b -&gt; t n b&lt;br /&gt;mapT morph = embed (lift . morph)&lt;br /&gt;&lt;/pre&gt;I can justify this additional method just by changing the names around and using a type operator: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE Rank2Types, TypeOperators #-}&lt;br /&gt;&lt;br /&gt;type a :~&gt; b = forall r . a r -&gt; b r&lt;br /&gt;&lt;br /&gt;class MonadM m where&lt;br /&gt;    returnM :: (Monad a, Monad (m a))&lt;br /&gt;            =&gt;  a :~&gt; m a&lt;br /&gt;    bindM   :: (Monad a, Monad (m a), Monad (m b))&lt;br /&gt;            =&gt; (a :~&gt; m b) -&gt; (m a :~&gt; m b)&lt;br /&gt;&lt;br /&gt;(&gt;|&gt;) :: (Monad a, Monad b, Monad (m b), Monad (m c),&lt;br /&gt;          MonadTrans m)&lt;br /&gt;      =&gt; (a :~&gt; m b) -&gt; (b :~&gt; m c) -&gt; (a :~&gt; m c)&lt;br /&gt;(f &gt;|&gt; g) x = bindM g (f x)&lt;br /&gt;&lt;br /&gt;joinM :: (Monad (m (m a)), Monad (m a), MonadTrans m)&lt;br /&gt;       =&gt; m (m a) :~&gt; m a&lt;br /&gt;joinM = bindM id&lt;br /&gt;&lt;br /&gt;fmapM&lt;br /&gt; :: (Monad a, Monad b, Monad (m a), Monad (m b), MonadTrans m)&lt;br /&gt; =&gt; (a :~&gt; b) -&gt; (m a :~&gt; m b)&lt;br /&gt;fmapM f = bindM (returnM . f)&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;In otherwords, I've stolen a page from &lt;a href="https://personal.cis.strath.ac.uk/conor.mcbride/Kleisli.pdf"&gt;Conor McBride's notebook&lt;/a&gt; and defined &lt;tt&gt;lift&lt;/tt&gt; and &lt;tt&gt;embed&lt;/tt&gt; as a higher-order monad in the category of monad morphisms.  Going back to the previous names, we can establish that certain laws must hold: &lt;pre&gt;&lt;br /&gt;-- Categorical version&lt;br /&gt;lift &gt;|&gt; f = f&lt;br /&gt;f &gt;|&gt; lift = f&lt;br /&gt;(f &gt;|&gt; g) &gt;|&gt; h = f &gt;|&gt; (g &gt;|&gt; h)&lt;br /&gt;&lt;br /&gt;-- bind/return version&lt;br /&gt;embed lift m = m&lt;br /&gt;embed f (lift m) = f m&lt;br /&gt;embed g (embed f m) = embed (\x -&gt; embed g (f x)) m&lt;br /&gt;&lt;br /&gt;-- join/return version&lt;br /&gt;squash (lift m) = m&lt;br /&gt;squash (mapT lift m) = m&lt;br /&gt;squash (squash m) = squash (mapT squash m)&lt;br /&gt;&lt;/pre&gt;Obviously, I won't suggest we break the existing &lt;tt&gt;MonadTrans&lt;/tt&gt; class by adding an additional method.  All we have to do is simply define a new &lt;tt&gt;MonadM&lt;/tt&gt; class and make all existing monad transformers instances of it and possibly make &lt;tt&gt;MonadTrans&lt;/tt&gt; a super-class of it.&lt;br /&gt;&lt;br /&gt;I'll bet more experienced Haskell programmers have wanted &lt;tt&gt;mapT&lt;/tt&gt; or &lt;tt&gt;squash&lt;/tt&gt; in one form or another.  The above type-class provides a uniform interface to these operations, so that you don't have to rely on transformer-specific functions like &lt;tt&gt;mapStateT&lt;/tt&gt; or &lt;tt&gt;mapMaybeT&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Note that all monad transformers have a sensible instance for &lt;tt&gt;MonadM&lt;/tt&gt; that obeys the above laws.  Usually the easiest route is to first define &lt;tt&gt;squash&lt;/tt&gt; (i.e. &lt;tt&gt;joinM&lt;/tt&gt;) and &lt;tt&gt;mapT&lt;/tt&gt; (i.e. &lt;tt&gt;fmapM&lt;/tt&gt;).  &lt;tt&gt;mapT&lt;/tt&gt; is usually very straight-forward to write and simply involves type-chasing.  &lt;tt&gt;squash&lt;/tt&gt; simply takes the inner monad transformer and combines its operations with the outer monad transformer.  Once you define these two, then you can easily define &lt;tt&gt;embed&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;-- i.e.: (bindM f) = joinM . fmapM f&lt;br /&gt;embed f = squash . mapT f&lt;br /&gt;&lt;/pre&gt;In the near future I will release a package containing this type-class and appropriate instances for the standard monad transformers.  Additionally, the &lt;tt&gt;pipes-2.4&lt;/tt&gt; release will include an extra motivation for defining the above type-class, besides the obvious utility of having &lt;tt&gt;mapT&lt;/tt&gt; and &lt;tt&gt;squash&lt;/tt&gt; functions.</description><link>http://www.haskellforall.com/2012/09/the-monadtrans-class-is-missing-method.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>5</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5213878713371325770</guid><pubDate>Sat, 15 Sep 2012 17:19:00 +0000</pubDate><atom:updated>2012-10-23T12:32:42.536-07:00</atom:updated><title>The functor design pattern</title><description>This post builds on my previous post on the &lt;a href="http://www.haskellforall.com/2012/08/the-category-design-pattern.html"&gt;category design pattern&lt;/a&gt; and this time I will discuss the functor design pattern.  If you are an intermediate Haskell programmer and you think you already understand functors, then think again, because I promise you this post will turn most of your preconceptions about functors on their head and show you how functors are much more powerful and generally applicable than you might realize.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Mixing features&lt;/h4&gt;&lt;br /&gt;So let's pretend that my previous post on categories inflamed your interest in compositional programming.  The first thing you might ask is "Which category do I use?".  This seems like a perfectly reasonable question, since you'd like to pick a category that: &lt;ul&gt;&lt;li&gt; attracts a lot of mindshare, &lt;li&gt; contains a large library of reusable components, &lt;li&gt; boasts many features, and &lt;li&gt; is simple to use. &lt;/ul&gt;Unfortunately, reality says that we seldom get all of the above qualities and they often conflict with one another.  For example, let's compare two categories I previously discussed: &lt;ul&gt;&lt;li&gt; Ordinary functions of type &lt;tt&gt;a -&gt; b&lt;/tt&gt; that you compose using: &lt;tt&gt;(.)&lt;/tt&gt;&lt;li&gt; Monadic functions of type &lt;tt&gt;a -&gt; m b&lt;/tt&gt; that you compose using: &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt;&lt;/ul&gt;Ordinary functions are simpler to read, write, use, and you can reason about their behavior more easily.  However, monadic functions boast more useful features, some of which are indispensable (such as side effects when we use the &lt;tt&gt;IO&lt;/tt&gt; monad).  We really need some way to mix these two categories together to get the best of both worlds.&lt;br /&gt;&lt;br /&gt;Fortunately, programmers solve compatibility problems like this all the time.  We often have tools written in different languages or different frameworks and if we want to mix features from multiple frameworks we write code to bridge between them.  So let's solve our category mixing problem by writing an adapter layer between the two categories.  We write some function that transforms all the components in one category into components in the other category, so that we can then freely mix components from the two categories.&lt;br /&gt;&lt;br /&gt;Typically, one category will be more featureful than the other, so the transformation is unidirectional.  Using the above example, monadic functions are strictly more featureful and powerful than ordinary functions. Fortunately, we can promote all ordinary functions to monadic functions using the following &lt;tt&gt;map&lt;/tt&gt; function: &lt;pre&gt;&lt;br /&gt;-- This "map"s an ordinary function to a monadic function&lt;br /&gt;map :: (Monad m) =&gt; (a -&gt; b) -&gt; (a -&gt; m b)&lt;br /&gt;map f = return . f&lt;br /&gt;&lt;/pre&gt;... but we cannot write the reverse function and automatically map every monadic function to an ordinary function.&lt;br /&gt;&lt;br /&gt;We use &lt;tt&gt;map&lt;/tt&gt; to combine a pure function &lt;tt&gt;f&lt;/tt&gt; and a monadic function &lt;tt&gt;g&lt;/tt&gt;.  To do this, we promote &lt;tt&gt;f&lt;/tt&gt; using &lt;tt&gt;map&lt;/tt&gt; and then combine both of them using Kleisli composition: &lt;pre&gt;&lt;br /&gt;f     ::              a -&gt;   b&lt;br /&gt;map f :: (Monad m) =&gt; a -&gt; m b&lt;br /&gt;&lt;br /&gt;g     :: (Monad m) =&gt; b -&gt; m c&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;g &lt;=&lt; map f :: (Monad m) =&gt; a -&gt; m c&lt;br /&gt;&lt;/pre&gt;Perfect!  Now we can reuse all of our ordinary functions within this Kleisli category and not have to rewrite anything!&lt;br /&gt;&lt;br /&gt;However, there's still a problem.  Monad binds are not free and sometimes they get in the way of compiler optimization, so you can imagine that it would be wasteful if we lifted two pure functions in a row: &lt;pre&gt;&lt;br /&gt;f     ::              a -&gt;   b&lt;br /&gt;map f :: (Monad m) =&gt; a -&gt; m b&lt;br /&gt;&lt;br /&gt;g     ::              b -&gt;   c&lt;br /&gt;map g :: (Monad m) =&gt; b -&gt; m c&lt;br /&gt;&lt;br /&gt;h     :: (Monad m) =&gt; c -&gt; m d&lt;br /&gt;&lt;br /&gt;-- Wasteful!&lt;br /&gt;h &lt;=&lt; map g &lt;=&lt; map f :: (Monad m) =&gt; a -&gt; m d&lt;br /&gt;&lt;/pre&gt;However, we're smart and we know that we can just optimize those two ordinary functions by using ordinary function composition first before lifting them with &lt;tt&gt;map&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;-- Smarter!&lt;br /&gt;h &lt;=&lt; map (g . f)&lt;br /&gt;&lt;/pre&gt;In other words, we assumed that the following transformation should be safe: &lt;pre&gt;&lt;br /&gt;map g &lt;=&lt; map f = map (g . f)&lt;br /&gt;&lt;/pre&gt;Similarly, we expect that if we lift an identity function into a chain of Kleisli compositions: &lt;pre&gt;&lt;br /&gt;g &lt;=&lt; map id &lt;=&lt; f&lt;br /&gt;&lt;/pre&gt;... then it should have no effect.  Well, we can easily prove that because: &lt;pre&gt;&lt;br /&gt;map id = return . id = return&lt;br /&gt;&lt;/pre&gt;.. and &lt;tt&gt;return&lt;/tt&gt; is the identity of Kleisli composition, therefore: &lt;pre&gt;&lt;br /&gt;f :: (Monad m) =&gt; a -&gt; m b&lt;br /&gt;g :: (Monad m) =&gt; b -&gt; m c&lt;br /&gt;&lt;br /&gt;map id :: (Monad m) =&gt; b -&gt; m b&lt;br /&gt;&lt;br /&gt;g &lt;=&lt; map id &lt;=&lt; f&lt;br /&gt;= g &lt;=&lt; return &lt;=&lt; f&lt;br /&gt;= g &lt;=&lt; f  :: (Monad m) =&gt; a -&gt; m c&lt;br /&gt;&lt;/pre&gt;Well, we just unwittingly defined our first functor!  But where is the functor?&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Functors&lt;/h4&gt;&lt;br /&gt;A functor transforms one category into another category.  In the previous section we transformed the category of Haskell functions into the category of monadic functions and that transformation is our functor.&lt;br /&gt;&lt;br /&gt;I will notationally distinguish between the two categories in question so I can be crystal clear about the mathematical definition of a functor.  I will denote our "source" category's identity as &lt;tt&gt;idA&lt;/tt&gt; and its composition as &lt;tt&gt;(._A)&lt;/tt&gt;, and these must obey the category laws: &lt;pre&gt;&lt;br /&gt;-- Yes, "._A" is ugly, I know&lt;br /&gt;idA ._A f = f                      -- Left identity&lt;br /&gt;&lt;br /&gt;f ._A id = f                       -- Right identity&lt;br /&gt;&lt;br /&gt;(f ._A g) ._A h = f ._A (g ._A h)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Similarly, I denote the "destination" category's identity as &lt;tt&gt;idB&lt;/tt&gt; and its composition as &lt;tt&gt;(._B)&lt;/tt&gt;, which also must obey the category laws: &lt;pre&gt;&lt;br /&gt;idB ._B f = f                      -- Left identity&lt;br /&gt;&lt;br /&gt;f ._B idB = f                      -- Right identity&lt;br /&gt;&lt;br /&gt;(f ._B g) ._B h = f ._B (g ._B h)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Then a functor uses a function that we will call &lt;tt&gt;map&lt;/tt&gt; to convert every component in the source category into a component in the destination category.&lt;br /&gt;&lt;br /&gt;We expect this &lt;tt&gt;map&lt;/tt&gt; function to satisfy two rules:&lt;br /&gt;&lt;br /&gt;Rule #1: &lt;tt&gt;map&lt;/tt&gt; must transform the composition operator in the source category to the composition operator in the destination category: &lt;pre&gt;&lt;br /&gt;map (f ._A g) = map f ._B map g&lt;br /&gt;&lt;/pre&gt;This is the "composition law".&lt;br /&gt;&lt;br /&gt;Rule #2: &lt;tt&gt;map&lt;/tt&gt; must transform the identity in the source category to the identity in the destination category: &lt;pre&gt;&lt;br /&gt;map idA = idB&lt;br /&gt;&lt;/pre&gt;This is the "identity law".&lt;br /&gt;&lt;br /&gt;Together these two rules are the "functor laws" (technically, the covariant functor laws).&lt;br /&gt;&lt;br /&gt;In the last section, our source category "A" was the category of ordinary functions: &lt;pre&gt;&lt;br /&gt;idA   = id&lt;br /&gt;(._A) = (.)&lt;br /&gt;&lt;/pre&gt;... and our destination category "B" was the Kleisli category: &lt;pre&gt;&lt;br /&gt;idB   = return&lt;br /&gt;(._B) = (&lt;=&lt;)&lt;br /&gt;&lt;/pre&gt;... and our &lt;tt&gt;map&lt;/tt&gt; function obeyed the functor laws: &lt;pre&gt;&lt;br /&gt;map id = return&lt;br /&gt;map (f . g) = map f &lt;=&lt; map g&lt;br /&gt;&lt;/pre&gt;In other words, functors serve as adapters between categories that promote code written for the source category to be automatically compatible with the destination category.  Functors arise every time we write compatibility layers and adapters between different pieces of software.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Functors hidden everywhere&lt;/h4&gt;&lt;br /&gt;I'll provide a few more examples of functors to tickle people's brains and show how functors arise all the time in your code without you even realizing it.  For example, consider the &lt;tt&gt;length&lt;/tt&gt; function: &lt;pre&gt;&lt;br /&gt;length :: [a] -&gt; Int&lt;br /&gt;&lt;/pre&gt;We can treat list concatenation as a category, where: &lt;pre&gt;&lt;br /&gt;(.) = (++)&lt;br /&gt;id  = []&lt;br /&gt;&lt;br /&gt;[] ++ x = x                    -- Left  identity&lt;br /&gt;x ++ [] = x                    -- Right identity&lt;br /&gt;(x ++ y) ++ z = x ++ (y ++ z)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Similarly, we can treat addition as a category, where: &lt;pre&gt;&lt;br /&gt;(.) = (+)&lt;br /&gt;id  = 0&lt;br /&gt;&lt;br /&gt;0 + x = x                  -- Left  identity&lt;br /&gt;x + 0 = x                  -- Right identity&lt;br /&gt;(x + y) + z = x + (y + z)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Then &lt;tt&gt;length&lt;/tt&gt; is a functor from the category of list concatentation to the category of integer addition: &lt;pre&gt;&lt;br /&gt;-- Composition law&lt;br /&gt;length (xs ++ ys) = length xs + length ys&lt;br /&gt;&lt;br /&gt;-- Identity law&lt;br /&gt;length [] = 0&lt;br /&gt;&lt;/pre&gt;Or consider the &lt;tt&gt;pipe&lt;/tt&gt; function from &lt;tt&gt;Control.Pipe&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;pipe :: (Monad m) =&gt; (a -&gt; b) -&gt; Pipe a b m r&lt;br /&gt;&lt;br /&gt;-- Composition law&lt;br /&gt;pipe (f . g) = pipe f &lt;+&lt; pipe g&lt;br /&gt;&lt;br /&gt;-- Identity law&lt;br /&gt;pipe id = idP&lt;br /&gt;&lt;/pre&gt;Also, &lt;tt&gt;concat&lt;/tt&gt; defines a functor from one list concatenation to another: &lt;pre&gt;&lt;br /&gt;-- Composition&lt;br /&gt;concat (x ++ y) = concat x ++ concat y&lt;br /&gt;&lt;br /&gt;-- Identity&lt;br /&gt;concat [] = []&lt;br /&gt;&lt;/pre&gt;So don't assume that the &lt;tt&gt;Functor&lt;/tt&gt; class is in any way representative of the full breadth of functors.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The &lt;tt&gt;Functor&lt;/tt&gt; class&lt;/h4&gt;&lt;br /&gt;So far I've deliberately picked examples that do not fit within the mold of Haskell's &lt;tt&gt;Functor&lt;/tt&gt; class to open people's minds about functors.  A lot of new Haskell programmers mistakenly believe that functors only encompass "container-ish" things and I hope the previous examples dispel that notion.&lt;br /&gt;&lt;br /&gt;However, the &lt;tt&gt;Functor&lt;/tt&gt; class still behaves the same way as the functors I've already discussed.  The only restriction is that the &lt;tt&gt;Functor&lt;/tt&gt; class only encompass the narrow case where the source and target categories are both categories of ordinary functions: &lt;pre&gt;&lt;br /&gt;class Functor f where&lt;br /&gt;    fmap :: (a -&gt; b) -&gt; (f a -&gt; f b)&lt;br /&gt;&lt;br /&gt;fmap (f . g) = fmap f . fmap g  -- Composition law&lt;br /&gt;&lt;br /&gt;fmap id = id                    -- Identity law&lt;br /&gt;&lt;/pre&gt;Haskell &lt;tt&gt;Functor&lt;/tt&gt;s recapitulate the themes of compatibility between categories and component reuse.  For example, we might have several ordinary functions lying around in our toolbox: &lt;pre&gt;&lt;br /&gt;f :: a -&gt; b&lt;br /&gt;g :: b -&gt; c&lt;br /&gt;&lt;/pre&gt;.. but we need to manipulate lists using functions of type: &lt;pre&gt;&lt;br /&gt;h :: [a] -&gt; [c]&lt;br /&gt;&lt;/pre&gt;Rather than rewrite all our old functions to work on lists, we can instead automatically promote all of them to work on lists using the &lt;tt&gt;map&lt;/tt&gt; function from the Prelude: &lt;pre&gt;&lt;br /&gt;map :: (a -&gt; b) -&gt; ([a] -&gt; [b])&lt;br /&gt;&lt;br /&gt;map f :: [a] -&gt; [b]&lt;br /&gt;map g :: [b] -&gt; [c]&lt;br /&gt;&lt;br /&gt;h = map f . map g :: [a] -&gt; [c]&lt;br /&gt;&lt;/pre&gt;We know that we can combine two passes over a list into a single pass: &lt;pre&gt;&lt;br /&gt;h = map (f . g) :: [a] -&gt; [c]&lt;br /&gt;&lt;/pre&gt;.. and doing nothing to each element does nothing to the list: &lt;pre&gt;&lt;br /&gt;map id = id&lt;br /&gt;&lt;/pre&gt;Once again, we've just stated the functor laws: &lt;pre&gt;&lt;br /&gt;map (f . g) = map f . map g  -- Composition law&lt;br /&gt;&lt;br /&gt;map id = id                  -- Identity law&lt;br /&gt;&lt;/pre&gt;Notice that functors free us from having to write code that targets some monolithic category.  Instead, we write all our code using whatever category we deem most appropriate and then promote it as necessary to whatever other categories might need the code we just wrote.  This lets us work within focused and specialized categories suitable for their respective tasks rather than waste our time arguing over what category to standardize on.&lt;br /&gt;&lt;br /&gt;Another benefit of functors is that they make our code automatically future-proof.  We write our components using whatever category we have at our disposal and then as new categories arise we just define new functors to promote our existing code to work within those new categories.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Monad morphisms&lt;/h4&gt;&lt;br /&gt;Compatibility issues arise all the time between various Haskell frameworks.  For example, let's assume I have a sizeable code-base written using the &lt;tt&gt;iteratee&lt;/tt&gt; library, but then I find a really useful library on hackage using &lt;tt&gt;enumerator&lt;/tt&gt;.  I would rather not rewrite the &lt;tt&gt;enumerator&lt;/tt&gt;-based library to use &lt;tt&gt;iteratee&lt;/tt&gt; so I instead choose to write an adapter function that allows me to mix the two.  I have to define some function, &lt;tt&gt;morph&lt;/tt&gt;, that transforms &lt;tt&gt;Iteratee&lt;/tt&gt;s from the &lt;tt&gt;iteratee&lt;/tt&gt; library into &lt;tt&gt;Iteratee&lt;/tt&gt;s from the &lt;tt&gt;enumerator&lt;/tt&gt; library: &lt;pre&gt;&lt;br /&gt;import qualified Data.Enumerator as E&lt;br /&gt;import qualified Data.Iteratee.Base as I&lt;br /&gt;&lt;br /&gt;morph :: I.Iteratee a m b -&gt; E.Iteratee a m b&lt;br /&gt;&lt;/pre&gt;However, I might suspect that the &lt;tt&gt;iteratee&lt;/tt&gt; library has a faster &lt;tt&gt;Monad&lt;/tt&gt; instance since it uses continuation-passing style (disclaimer: I have no idea if this is true, it's just a hypothetical example).  This means that I would like to be able to factor code to use the &lt;tt&gt;iteratee&lt;/tt&gt;library's monad whenever possible: &lt;pre&gt;&lt;br /&gt;f :: a -&gt; I.Iteratee s m b&lt;br /&gt;&lt;br /&gt;g :: b -&gt; I.Iteratee s m c&lt;br /&gt;&lt;br /&gt;h :: c -&gt; E.Iteratee s m d&lt;br /&gt;&lt;br /&gt;-- Hypothetically slower, since it uses &lt;tt&gt;E.Iteratee&lt;/tt&gt;'s bind&lt;br /&gt;code1 :: a -&gt; E.Iteratee s m d&lt;br /&gt;code1 a = do b &lt;- morph $ f a&lt;br /&gt;             c &lt;- morph $ g b&lt;br /&gt;             h c&lt;br /&gt;&lt;br /&gt;-- Hypothetically faster, since it uses &lt;tt&gt;I.Iteratee&lt;/tt&gt;'s bind&lt;br /&gt;code2 :: a -&gt; E.Iteratee s m d&lt;br /&gt;code2 a = do c &lt;- morph $ do b &lt;- f a&lt;br /&gt;                             g b&lt;br /&gt;             h c&lt;br /&gt;&lt;/pre&gt;I would also expect that if I do nothing using &lt;tt&gt;enumerator&lt;/tt&gt;, that it's equivalent to doing nothing using &lt;tt&gt;iteratee&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;morph $ return x&lt;br /&gt;= return x&lt;br /&gt;&lt;/pre&gt;Interestingly, we encounter a pattern when we write the above functions using a point-free style: &lt;pre&gt;&lt;br /&gt;code1 = h &lt;=&lt; (morph . g) &lt;=&lt; (morph . f)&lt;br /&gt;&lt;br /&gt;code2 = h &lt;=&lt; (morph . (g &lt;=&lt; f))&lt;br /&gt;&lt;br /&gt;morph . return = return&lt;br /&gt;&lt;/pre&gt;This pattern seems so familiar... &lt;pre&gt;&lt;br /&gt;map :: (a -&gt; I.Iteratee s m b) -&gt; (a -&gt; E.Iteratee s m b)&lt;br /&gt;map = (morph .)&lt;br /&gt;&lt;br /&gt;map (f &lt;=&lt; g) = map f &lt;=&lt; map g  -- Composition law&lt;br /&gt;&lt;br /&gt;map return = return              -- Identity law&lt;br /&gt;&lt;/pre&gt;Oh, I've accidentally defined a functor!  This time both the source and destination categories are Kleisli categories and the functor preserves both the composition and identity correctly.&lt;br /&gt;&lt;br /&gt;Category theorists have a very specific name for the above pattern: a monad morphism.  Specifically, a monad morphism is any function: &lt;pre&gt;&lt;br /&gt;morph :: (Monad m, Monad n) =&gt; forall r . m r -&gt; n r&lt;br /&gt;&lt;/pre&gt;... such that &lt;tt&gt;map = (morph .)&lt;/tt&gt; defines a functor between two Kleisli categories: &lt;pre&gt;&lt;br /&gt;map :: (Monad m, Monad n) =&gt; (a -&gt; m b) -&gt; (a -&gt; n b)&lt;br /&gt;map = (morph .)&lt;br /&gt;&lt;/pre&gt;Also, intermediate Haskell programmers will recognize a subtle variation on this pattern: &lt;pre&gt;&lt;br /&gt;lift :: (Monad m, MonadTrans t) =&gt; m r -&gt; t m r&lt;br /&gt;&lt;br /&gt;(lift .) :: (Monad m, MonadTrans t) =&gt; (a -&gt; m b) -&gt; (a -&gt; t m b)&lt;br /&gt;&lt;br /&gt;-- Identity law&lt;br /&gt;(lift .) return = return&lt;br /&gt;&lt;br /&gt;-- Composition law&lt;br /&gt;(lift .) (f &gt;=&gt; g) = (lift .) f &gt;=&gt; (lift .) g&lt;br /&gt;&lt;/pre&gt;These are just the monad transformer laws!  However, they are usually written in this form: &lt;pre&gt;&lt;br /&gt;lift $ return x = return x&lt;br /&gt;&lt;br /&gt;lift $ do y &lt;- f x&lt;br /&gt;          g y&lt;br /&gt;= do y &lt;- lift $ f x&lt;br /&gt;     lift $ g y&lt;br /&gt;&lt;/pre&gt;In other words, monad transformers are a special subset of monad morphisms and the monad transformer laws are just the functor laws in disguise!&lt;br /&gt;&lt;br /&gt;Now, every time you use a monad transformer you can appreciate that you are using a functor as an adapter layer between two categories: the base monad's Kleisli category and the transformed monad's Kleisli category.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;The functor design pattern embodies a philosophy of programming that emphasizes: &lt;ul&gt;&lt;li&gt; compatibility over standardization, &lt;li&gt; specialization over monolithic frameworks, and &lt;li&gt; short-term completion over future-proofing. &lt;/ul&gt;However, the above tenets, while popular, haven't completely taken hold because we associate: &lt;ul&gt;&lt;li&gt; compatibility with cruft, &lt;li&gt; specialization with fragmentation, and &lt;li&gt; short-term completion with lack of foresight. &lt;/ul&gt;In a future post I will discuss how the functor laws mitigate these problems and allow you to layer on as many abstractions over as many tools as you wish without the abstractions collapsing under their own weight.&lt;br /&gt;&lt;br /&gt;Functors don't even necessarily need to be within a single programming language.  A programmer could even use the category design pattern in completely separate programming languages and then use the functor design pattern to bridge components written in one language to another.  Please don't limit your imagination to just the examples I gave!&lt;br /&gt;&lt;br /&gt;However, the functor design pattern doesn't work at all if you aren't using categories in the first place.  This is why you should structure your tools using the compositional category design pattern so that you can take advantage of functors to easily mix your tools together.  This is true whether you are programming in one language or several languages.  As long as each tool forms its own category and you obey the functor laws when switching between them, you can be very confident that all your tools will mix correctly.</description><link>http://www.haskellforall.com/2012/09/the-functor-design-pattern.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>14</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-8386962382343802489</guid><pubDate>Sat, 08 Sep 2012 04:46:00 +0000</pubDate><atom:updated>2012-09-09T07:46:32.729-07:00</atom:updated><title>Concurrency = Lists of Kleisli arrows</title><description>I spend a lot of time thinking about concurrency and the more I study it the more I discover that concurrency is just a fancy name for merging lists.  I'm going to use my &lt;tt&gt;Proxy&lt;/tt&gt; type to demonstrate that this is not just a superficial analogy.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Merging lists&lt;/h4&gt;&lt;br /&gt;Let's imagine that a thread is just a list of values: &lt;pre&gt;&lt;br /&gt;type Thread a = [a]&lt;br /&gt;&lt;/pre&gt;Each &lt;tt&gt;a&lt;/tt&gt; represents one atomic step in our thread.&lt;br /&gt;&lt;br /&gt;Now let's assume we have two such threads and we need to schedule them.  The simplest way to schedule them would be to interleave them: &lt;pre&gt;&lt;br /&gt;zip :: Thread a -&gt; Thread a -&gt; Thread a&lt;br /&gt;zip [] ys = ys&lt;br /&gt;zip xs [] = xs&lt;br /&gt;zip (x:xs) (y:ys) = x:y:zip xs ys&lt;br /&gt;&lt;/pre&gt;However, I can think of three obvious problems with this approach.  First, it is not associative: &lt;pre&gt;&lt;br /&gt;(xs `zip` ys) `zip` zs /= xs `zip` (ys `zip` zs)&lt;br /&gt;&lt;/pre&gt;Second, it assumes that all thread actions have equal priority, which probably isn't the case.&lt;br /&gt;&lt;br /&gt;We can fix this by switching to cooperative threads which can either provide a value, yield "left" or yield "right": &lt;pre&gt;&lt;br /&gt;data Step a = YieldL | Step a | YieldR&lt;br /&gt;&lt;br /&gt;type Thread a = [Step a]&lt;br /&gt;&lt;/pre&gt;Now, we can merge threads in such a way that respects their yields: &lt;pre&gt;&lt;br /&gt;(&lt;&gt;) :: Thread a -&gt; Thread a -&gt; Thread a&lt;br /&gt;        []  &lt;&gt;         ys  = []&lt;br /&gt;(YieldL:xs) &lt;&gt;         ys  = YieldL:(xs &lt;&gt; ys)&lt;br /&gt;(Step a:xs) &lt;&gt;         ys  = Step a:(xs &lt;&gt; ys)&lt;br /&gt;(YieldR:xs) &lt;&gt; (YieldL:ys) =        (xs &lt;&gt; ys)&lt;br /&gt;-- From this point onward, xs = YieldR:xs'&lt;br /&gt;        xs  &lt;&gt; (Step a:ys) = Step a:(xs &lt;&gt; ys)&lt;br /&gt;        xs  &lt;&gt; (YieldR:ys) = YieldR:(xs &lt;&gt; ys)&lt;br /&gt;        xs  &lt;&gt;         []  = []&lt;br /&gt;&lt;/pre&gt;Interestingly, this new operation is associative: &lt;pre&gt;&lt;br /&gt;(xs &lt;&gt; ys) &lt;&gt; zs = xs &lt;&gt; (ys &lt;&gt; zs)&lt;br /&gt;&lt;/pre&gt;It also has an empty thread which acts like an identity: &lt;pre&gt;&lt;br /&gt;mempty = YieldR:YieldL:mempty&lt;br /&gt;&lt;br /&gt;mempty &lt;&gt; xs = xs&lt;br /&gt;xs &lt;&gt; mempty = xs&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Proxies&lt;/h4&gt;&lt;br /&gt;While working on &lt;tt&gt;Proxy&lt;/tt&gt;s, I discovered they had certain nice mathematical properties: &lt;pre&gt;&lt;br /&gt;         return  &lt;-&lt;               g  = return&lt;br /&gt;(respond  &gt;=&gt; f) &lt;-&lt;               g  = respond  &gt;=&gt; (f &lt;-&lt; g)&lt;br /&gt;(lift . k &gt;=&gt; f) &lt;-&lt;               g  = lift . k &gt;=&gt; (f &lt;-&lt; g)&lt;br /&gt;(request  &gt;=&gt; f) &lt;-&lt; (respond  &gt;=&gt; g) =              (f &lt;-&lt; g)&lt;br /&gt;-- For the following equations, f = request &gt;=&gt; f'&lt;br /&gt;              f  &lt;-&lt; (lift . k &gt;=&gt; g) = lift . k &gt;=&gt; (f &lt;-&lt; g)&lt;br /&gt;              f  &lt;-&lt; (request  &gt;=&gt; g) = request  &gt;=&gt; (f &lt;-&lt; g)&lt;br /&gt;              f  &lt;-&lt;          return  = return&lt;br /&gt;&lt;/pre&gt;Now, where have I seen that before?  Why, these are identical the equations for the above list merge, except we need to make the following substitutions to make the analogy complete: &lt;pre&gt;&lt;br /&gt;(&gt;=&gt;)     -&gt;  (++)&lt;br /&gt;return    -&gt;  []&lt;br /&gt;respond   -&gt;  [YieldL]&lt;br /&gt;request   -&gt;  [YieldR]&lt;br /&gt;lift . k  -&gt;  [], [Step a], [Step a, Step a'] ...&lt;br /&gt;(&lt;-&lt;)     -&gt;  (&lt;&gt;)&lt;br /&gt;&lt;/pre&gt;Well, if those substitutions were correct, we'd expect that we could use them to derive the correct form for &lt;tt&gt;idT&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;mempty = YieldR:YieldL:mempty&lt;br /&gt;mempty = [YieldR] ++  [YieldL] ++  mempty&lt;br /&gt;idT    = request  &gt;=&gt; respond  &gt;=&gt; idT&lt;br /&gt;&lt;/pre&gt;... and it works!&lt;br /&gt;&lt;br /&gt;This is what I mean when I say that &lt;tt&gt;Proxy&lt;/tt&gt; composition is just merging lists of Kleisli arrows.&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;I was a little bit skeptical at first when I had to give &lt;tt&gt;Proxy&lt;/tt&gt;s an extra input parameter to get them to be composable.  However, the surprising connection to lists of Kleisli arrows convinced me that the Kleisli arrow is the true currency of concurrency.</description><link>http://www.haskellforall.com/2012/09/concurrency-lists-of-kleisli-arrows.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>2</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-2489355138117852496</guid><pubDate>Thu, 06 Sep 2012 03:23:00 +0000</pubDate><atom:updated>2012-09-05T20:23:23.589-07:00</atom:updated><title>pipes-2.3 - Bidirectional pipes</title><description>One thing I love about Blogger is the detailed traffic information it provides out of the box.  I enjoy seeing what keywords direct people to my blog, and one particular search result came up a lot recently, namely &lt;tt&gt;bidirectional pipes&lt;/tt&gt;.  Every time I saw somebody searching for bidirectional pipes I would think to myself "You and me both!" since I've been wanting bidirectional pipes for quite some time now to implement features that users have been requesting.&lt;br /&gt;&lt;br /&gt;Well, anonymous googlers, today is your day!  I'm releasing &lt;tt&gt;pipes-2.3&lt;/tt&gt;which introduces a new bidirectional pipe type, which I call a &lt;tt&gt;Proxy&lt;/tt&gt;and I've proven the category laws for &lt;tt&gt;Proxy&lt;/tt&gt; composition.&lt;br /&gt;&lt;br /&gt;This blog post is not a proper tutorial but rather a meta-discussion of this release.  This post discusses context surrounding this release for people who follow iteratee development, so if you just want to see cool examples, then read the &lt;tt&gt;Proxy&lt;/tt&gt; &lt;a href="http://hackage.haskell.org/packages/archive/pipes/2.3.0/doc/html/Control-Proxy-Tutorial.html"&gt;tutorial&lt;/a&gt; over at &lt;tt&gt;Control.Proxy.Tutorial&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Also, this post is not technically part of my category theory series that I'm writing, but it does fortuitously tie in to it.  The &lt;tt&gt;Proxy&lt;/tt&gt; type provides an elegant framework for composing reusable client/proxy/server primitives into powerful applications, so if you started following my blog because of my discussion about compositionality, then I recommend you read the &lt;tt&gt;Proxy&lt;/tt&gt; &lt;a href="http://hackage.haskell.org/packages/archive/pipes/2.3.0/doc/html/Control-Proxy-Tutorial.html"&gt;tutorial&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Generalizing Pipes&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;Proxy&lt;/tt&gt; terminology is built on the client-server metaphor, and if you already understand &lt;tt&gt;Pipe&lt;/tt&gt;s the following translations will help you map your &lt;tt&gt;Pipe&lt;/tt&gt; intuition onto &lt;tt&gt;Proxy&lt;/tt&gt; terms: &lt;pre&gt;&lt;br /&gt;-- Types&lt;br /&gt;Pipe     -&gt; Proxy&lt;br /&gt;&lt;br /&gt;Producer -&gt; Server&lt;br /&gt;Consumer -&gt; Client&lt;br /&gt;Pipeline -&gt; Session&lt;br /&gt;&lt;br /&gt;-- commands&lt;br /&gt;await    -&gt; request&lt;br /&gt;yield    -&gt; respond&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;Client&lt;/tt&gt;s resemble &lt;tt&gt;Consumer&lt;/tt&gt;s, except you replace &lt;tt&gt;await&lt;/tt&gt; with &lt;tt&gt;request&lt;/tt&gt;, which provides an argument to upstream: &lt;pre&gt;&lt;br /&gt;myClient () = do&lt;br /&gt;    ...&lt;br /&gt;    answer &lt;- request argument&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;Server&lt;/tt&gt;s resemble &lt;tt&gt;Producer&lt;/tt&gt;s, except you replace &lt;tt&gt;yield&lt;/tt&gt; with &lt;tt&gt;respond&lt;/tt&gt;.  Composition requires a parameter to pass in the first request: &lt;pre&gt;&lt;br /&gt;--       +-- 1st request&lt;br /&gt;--       |&lt;br /&gt;--       v&lt;br /&gt;myServer argument = do&lt;br /&gt;    ...&lt;br /&gt;&lt;/pre&gt;... and every subsequent request is bound to the return value of &lt;tt&gt;respond&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;myServer argument = do&lt;br /&gt;    x &lt;- computeSomething argument&lt;br /&gt;    -- "respond" binds the next argument&lt;br /&gt;    nextArgument &lt;- respond x&lt;br /&gt;    myServer nextArgument&lt;br /&gt;&lt;br /&gt;-- or: myServer = computeSomething &gt;=&gt; respond &gt;=&gt; myServer&lt;br /&gt;&lt;/pre&gt;I provide the &lt;tt&gt;foreverK&lt;/tt&gt; function which abstracts away this common recursion pattern: &lt;pre&gt;&lt;br /&gt;-- i.e. forever 'K'leisli arrow&lt;br /&gt;foreverK f = f &gt;=&gt; foreverK f&lt;br /&gt;&lt;br /&gt;myServer = foreverK $ \argument -&gt; do&lt;br /&gt;    result &lt;- computeSomething argument&lt;br /&gt;    respond result&lt;br /&gt;&lt;br /&gt;-- or: myServer = foreverK (computeSomething &gt;=&gt; respond)&lt;br /&gt;&lt;/pre&gt;That looks just like the way you'd write a server's loop: get some argument, compute some result, respond with the result.  However, you can do significantly more sophisticated things than just loop.&lt;br /&gt;&lt;br /&gt;A &lt;tt&gt;Proxy&lt;/tt&gt; sits between servers and clients.  It can query servers on its upstream interface, and respond to clients on its downstream interface: &lt;pre&gt;&lt;br /&gt;      | Upstream  | Downstream |&lt;br /&gt;      | interface | interface  |&lt;br /&gt;Proxy   arg1 ret1    arg2 ret2   m r&lt;br /&gt;&lt;/pre&gt;As with &lt;tt&gt;Pipe&lt;/tt&gt;s, the intermediate &lt;tt&gt;Proxy&lt;/tt&gt; type is the unifying compositional type which generalizes the endpoint types.  &lt;tt&gt;Server&lt;/tt&gt; and &lt;tt&gt;Client&lt;/tt&gt; are just type synonyms around the &lt;tt&gt;Proxy&lt;/tt&gt; type with one of its two ends closed.&lt;br /&gt;&lt;br /&gt;You can then compose as many components as you please into a single &lt;tt&gt;Session&lt;/tt&gt; using composition and then use &lt;tt&gt;runSession&lt;/tt&gt; to convert the results back to the base monad: &lt;pre&gt;&lt;br /&gt;runSession $ client &lt;-&lt; proxy_1 &lt;-&lt;  ... &lt;-&lt; proxy_n &lt;-&lt; server&lt;br /&gt;&lt;/pre&gt;In the following sections, I will motivate this upgrade to bidirectional pipes by providing some examples of trivial problems that have embarrassed the entire iteratee community (myself included) up until now.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Dumb sources&lt;/h4&gt;&lt;br /&gt;The simplest example is a file reader.  Using any iteratee implementation out there, it is very awkward to specify how many bytes you wish to pull from the upstream source on a request-to-request basis.  Most implementations either: &lt;ul&gt;&lt;li&gt; Hard-code the number of bytes delivered on each request (i.e. &lt;tt&gt;conduit&lt;/tt&gt;/&lt;tt&gt;iterIO&lt;/tt&gt;) &lt;li&gt; Initialize the source with a given buffer size and then fix it from that point onward (i.e. &lt;tt&gt;enumerator&lt;/tt&gt;/&lt;tt&gt;iteratee&lt;/tt&gt;) &lt;/ul&gt;Now, there's nothing wrong with hard-coding the size for the read from the file since typically there is an optimum buffer size for disk I/O, but you'd still like to be able to layer another component downstream that can then parcel that out into chunk sizes that the user actually wants.&lt;br /&gt;&lt;br /&gt;Unfortunately, the gold standard solution (pushback) is unsatisfactory because it: &lt;ul&gt;&lt;li&gt; only solves this narrow use case and does not generalize, &lt;li&gt; cannot push back portions of input without imposing some sort of &lt;tt&gt;Monoid&lt;/tt&gt; restriction on the iteratee type itself, and &lt;li&gt; requires that the user maintain certain invariants to prevent breaking the &lt;tt&gt;Category&lt;/tt&gt; laws. &lt;/ul&gt;Wouldn't it be nice if we could just directly tell upstream what we wanted instead of playing all these games?  &lt;tt&gt;Proxy&lt;/tt&gt;s let you do that through the argument you supply to &lt;tt&gt;request&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Remote-procedure call&lt;/h4&gt;&lt;br /&gt;The next example is interfacing with some server.  This is a real-world example from my own work.  I've written a protein structural search engine and I've set it up as an RPC service: protein structure goes in, a bunch of search results come out.  I'd like to write a &lt;tt&gt;Pipe&lt;/tt&gt;s interface to this so I can stream the results coming out of the server, but unfortunately I can't.  If I tried, I might do something like this: &lt;pre&gt;&lt;br /&gt;searchEngine? :: Pipe Structure [Structure] IO r&lt;br /&gt;&lt;/pre&gt;I can't really accomplish this because &lt;tt&gt;Pipe&lt;/tt&gt;s only permit a unidirectional flow of information.  I can't both provide the query and receive the results within the same component without resorting to brittle non-compositional tricks like &lt;tt&gt;IORefs&lt;/tt&gt; that defeat the entire point of the iteratee abstraction.  However, with &lt;tt&gt;Proxy&lt;/tt&gt;s, the solution is incredibly easy: &lt;pre&gt;&lt;br /&gt;The input ---------+-------------------+          +- The results&lt;br /&gt;                   |                   |          |&lt;br /&gt;                   v                   v          v&lt;br /&gt;searchEngine :: Structure -&gt; Server Structure [Structure] IO r&lt;br /&gt;searchEngine = foreverK $ \structure -&gt; do&lt;br /&gt;    -- "search" might send a network query to the actual server&lt;br /&gt;    results &lt;- lift $ search structure&lt;br /&gt;    respond results&lt;br /&gt;&lt;br /&gt;-- searchEngine = foreverK ((lift . search) &gt;=&gt; respond)&lt;br /&gt;&lt;/pre&gt;Note that this time the query and response occupy the same interface, rather than two opposing interfaces, so I can now hook up a &lt;tt&gt;Client&lt;/tt&gt; to it that send in requests and receive responses within the same block of code.&lt;br /&gt;&lt;br /&gt;No other iteratee implementation out there can accomplish this.  Instead, they restrict us to using blind sources that don't know what downstream actually wants. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Closures&lt;/h4&gt;&lt;br /&gt;You can also implement imperative-style closures using &lt;tt&gt;Proxy&lt;/tt&gt;s.  Simply define: &lt;pre&gt;&lt;br /&gt;type Closure = Server&lt;br /&gt;&lt;/pre&gt;... and you are good to go!  Consider the Python example from the Wikipedia article on closures: &lt;pre&gt;&lt;br /&gt;def counter():&lt;br /&gt;    x = 0&lt;br /&gt;    def increment(y):&lt;br /&gt;        nonlocal x&lt;br /&gt;        x += y&lt;br /&gt;        print(x)&lt;br /&gt;    return increment&lt;br /&gt;&lt;/pre&gt;We can translate this directly into &lt;tt&gt;Proxy&lt;/tt&gt;s: &lt;pre&gt;&lt;br /&gt;counter :: Int -&gt; Closure Int () IO r&lt;br /&gt;counter = counter' 0&lt;br /&gt;&lt;br /&gt;counter' x y = do&lt;br /&gt;    let x' = x + y&lt;br /&gt;    lift $ print x'&lt;br /&gt;    y' &lt;- respond ()&lt;br /&gt;    counter' x' y'&lt;br /&gt;&lt;/pre&gt;We can then consume the closure in a structured way using composition: &lt;pre&gt;&lt;br /&gt;type Opening = Client -- The opposite of a closure?&lt;br /&gt;&lt;br /&gt;useClosure :: () -&gt; Opening Int () IO ()&lt;br /&gt;useClosure () = mapM_ request [1, 7, 1, 1]&lt;br /&gt;&lt;br /&gt;main = runSession $ useClosure &lt;-&lt; counter&lt;br /&gt;&lt;/pre&gt;... or we can manually peel off individual elements from the closure using &lt;tt&gt;runFreeT&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;pop :: (Monad m)&lt;br /&gt; =&gt; a&lt;br /&gt; -&gt; Closure a b m r&lt;br /&gt; -&gt; m (Maybe (b, Closure a b m r))&lt;br /&gt;pop y = do&lt;br /&gt;    f &lt;- runFreeT (counter y)&lt;br /&gt;    case f of&lt;br /&gt;        Pure          _  -&gt; return   Nothing&lt;br /&gt;        Free (Yield x c) -&gt; return $ Just (x, c)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;Proxy&lt;/tt&gt; internals are all exposed without compromising any safety, so if you choose not to buy in to the whole composition framework you can always manually deconstruct &lt;tt&gt;Proxy&lt;/tt&gt;s by hand and go along your way.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Compositional message passing&lt;/h4&gt;&lt;br /&gt;As far as I can tell, this is the only bidirectional message passing framework that satisfies the category laws.  This guarantees several nice properties: &lt;ul&gt;&lt;li&gt; The identity laws enforce that composition of components must be completely transparent. &lt;li&gt; The associativity law guarantees that each component can be written completely context-free. &lt;/ul&gt;Unlike most message passing frameworks, &lt;tt&gt;Proxy&lt;/tt&gt;s promote component decoupling by structuring message passing through typed interfaces and composing those interfaces to mix and match components.  This promotes code reuse and makes it easy to encapsulate complete functionality into single black-box objects instead of exposing a bunch of initialization/push/pull/finalization routines that your user must worry about threading together correctly with every other component.&lt;br /&gt;&lt;br /&gt;When you have compositional components, combining them together is as easy as snapping a bunch of legos together.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Extensions&lt;/h4&gt;&lt;br /&gt;Another motivation for this upgrade is finalization.  With the ability to send information back upstream, I can now implement bidirectional finalization using ordinary monads and not indexed monads.  This will replace &lt;tt&gt;Frame&lt;/tt&gt;s, which I will deprecate and either remove or migrate to a separate library.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Pipe compatibility&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;Pipe&lt;/tt&gt;s are a strict subset of &lt;tt&gt;Proxy&lt;/tt&gt;s so if you have existing &lt;tt&gt;Pipe&lt;/tt&gt; code you can replace &lt;tt&gt;Control.Pipe&lt;/tt&gt; with &lt;tt&gt;Control.Proxy&lt;/tt&gt; which provides backwards-compatible definitions for all &lt;tt&gt;Pipe&lt;/tt&gt; primitives and your previous code will still work.&lt;br /&gt;&lt;br /&gt;You can understand the relationship between &lt;tt&gt;Pipe&lt;/tt&gt;s and &lt;tt&gt;Proxy&lt;/tt&gt;s by checking out the type synonym for &lt;tt&gt;Pipe&lt;/tt&gt;s provided by &lt;tt&gt;Control.Proxy&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;type Pipe a b = Proxy () a () b&lt;br /&gt;&lt;/pre&gt;In other words, a &lt;tt&gt;Pipe&lt;/tt&gt; is a &lt;tt&gt;Proxy&lt;/tt&gt; that never sends any information upstream when it requests input.&lt;br /&gt;&lt;br /&gt;There is another advantage of &lt;tt&gt;Proxy&lt;/tt&gt;s over &lt;tt&gt;Pipe&lt;/tt&gt;s, which is that now it is possible to forbid &lt;tt&gt;await&lt;/tt&gt;s.  The &lt;tt&gt;Proxy&lt;/tt&gt; implementation is highly symmetric and fills a lot of elegance holes that &lt;tt&gt;Pipe&lt;/tt&gt;s had.&lt;br /&gt;&lt;br /&gt;However, if you love &lt;tt&gt;Pipe&lt;/tt&gt;s, never fear, because &lt;tt&gt;Control.Pipe&lt;/tt&gt; will never be deprecated, ever.  It provides the simplest iteratee API on Hackage, and I plan to continue to upgrade it with all features compatible with the &lt;tt&gt;Pipe&lt;/tt&gt; type.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Kleisli arrow&lt;/h4&gt;&lt;br /&gt;One of the surprising results of the bidirectional implementation was that it unifies Kleisli composition and &lt;tt&gt;Proxy&lt;/tt&gt; composition, whose arguments overlap.  One thing you will discover the more you program with &lt;tt&gt;Proxy&lt;/tt&gt;s is that most useful &lt;tt&gt;Proxy&lt;/tt&gt; components end up being Kleisli arrows and you'll often find that a lot of your code simplifies to the following point-free style: &lt;pre&gt;&lt;br /&gt;-- Not that I necessarily recommend writing it this way&lt;br /&gt;((p1 &lt;=&lt; p2 &lt;=&lt; p3) &lt;-&lt; (p4 &lt;=&lt; p5)) &lt;=&lt; (p6 &lt;-&lt; p7)&lt;br /&gt;&lt;/pre&gt;This isn't a coincidence.  A very abstract way to understand &lt;tt&gt;Proxy&lt;/tt&gt; composition is that it is just merging lists of Kleisli arrows in a structured way.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;I know in the past I've stated that bidirectional information flow does not form a category, so now I'm publicly eating my own words.&lt;br /&gt;&lt;br /&gt;There will be two more release in the next two months.  The first release will provide the first general mechanism for extending &lt;tt&gt;Pipes&lt;/tt&gt; with your own custom extensions and will include error handling and parsing extensions implemented using this approach.&lt;br /&gt;&lt;br /&gt;The second release will provide a second way to customize pipes and will include finalization/reinitialization and stack traces implemented using that approach.</description><link>http://www.haskellforall.com/2012/09/pipes-23-bidirectional-pipes.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>15</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-171760268230001678</guid><pubDate>Sat, 18 Aug 2012 15:07:00 +0000</pubDate><atom:updated>2012-09-10T17:30:16.903-07:00</atom:updated><title>The category design pattern</title><description>Functional programming is all the rage these days, but in this post I want to emphasize that functional programming is a subset of a more important overarching programming paradigm: compositional programming.&lt;br /&gt;&lt;br /&gt;If you've ever used Unix pipes, you'll understand the importance and flexibility of composing small reusable programs to get powerful and emergent behaviors. Similarly, if you program functionally, you'll know how cool it is to compose a bunch of small reusable functions into a fully featured program.&lt;br /&gt;&lt;br /&gt;Category theory codifies this compositional style into a design pattern, the category.  Moreover, category theory gives us a precise prescription for how to create our own abstractions that follow this design pattern: the category laws.  These laws differentiate category theory from other design patterns by providing rigorous criteria for what does and does not qualify as compositional.&lt;br /&gt;&lt;br /&gt;One could easily dismiss this compositional ideal as just that: an ideal, something unsuitable for "real-world" scenarios.  However, the theory behind category theory provides the meat that shows that this compositional ideal appears everywhere and can rise to the challenge of messy problems and complex business logic.&lt;br /&gt;&lt;br /&gt;This post is just one of many posts that I will write over time where I will demonstrate how to practically use this compositional style in your programs, even for things that may seem like they couldn't possibly lend themselves to compositional programming.  This first post starts off by introducing the category as a compositional design pattern.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Categories&lt;/h4&gt;&lt;br /&gt;I'm going to give a slightly different introduction to category theory than most people give.  I'm going to gloss over the definition of what a morphism or an object is and skip over domains and codomains and instead just go straight to composition, because from a programmer's point of view a category is just a compositional design pattern.&lt;br /&gt;&lt;br /&gt;Category theory says that for any given category there must be some sort of composition operator, which I will denote &lt;tt&gt;(.)&lt;/tt&gt;.  The first rule is that this composition operator is associative: &lt;pre&gt;&lt;br /&gt;(f . g) . h = f . (g . h) -- Associativity law&lt;br /&gt;&lt;/pre&gt;This is useful because it means we can completely ignore the order of grouping and write it without any parentheses at all: &lt;pre&gt;&lt;br /&gt;f . g . h&lt;br /&gt;&lt;/pre&gt;Category theory also says that this composition operator must have a left and right identity, which I will denote &lt;tt&gt;id&lt;/tt&gt;.  Being an identity means that: &lt;pre&gt;&lt;br /&gt;id . f = f  -- Left  identity law&lt;br /&gt;&lt;br /&gt;f . id = f  -- Right identity law&lt;br /&gt;&lt;/pre&gt;The associativity law and the two identity laws are known as the category laws.&lt;br /&gt;&lt;br /&gt;Notice that the definition of a category does not define: &lt;ul&gt;&lt;li&gt; what &lt;tt&gt;(.)&lt;/tt&gt; is, &lt;li&gt; what &lt;tt&gt;id&lt;/tt&gt; is, or &lt;li&gt; what &lt;tt&gt;f&lt;/tt&gt;, &lt;tt&gt;g&lt;/tt&gt;, and &lt;tt&gt;h&lt;/tt&gt; might be. &lt;/ul&gt;Instead, category theory leaves it up to us to discover what they might be.&lt;br /&gt;&lt;br /&gt;The brilliance behind the category design pattern is that any composition operator that observes these laws will be: &lt;ul&gt;&lt;li&gt; easy to use, &lt;li&gt; intuitive, &lt;li&gt; and free from edge cases. &lt;/ul&gt;This is why we try to formulate abstractions in terms of the category design pattern whenever possible.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The function category&lt;/h4&gt;&lt;br /&gt;Let's define our first category: the category of Haskell functions! &lt;pre&gt;&lt;br /&gt;id  :: (a -&gt; a)&lt;br /&gt;id x = x&lt;br /&gt;&lt;br /&gt;(.) :: (b -&gt; c) -&gt; (a -&gt; b) -&gt; (a -&gt; c)&lt;br /&gt;(f . g) x = f (g x)&lt;br /&gt;&lt;/pre&gt;Let's prove to ourselves that these obey the category laws: &lt;pre&gt;&lt;br /&gt;-- Left identity: id . f = f&lt;br /&gt;id . f&lt;br /&gt;= \x -&gt; id (f x)&lt;br /&gt;= \x -&gt; f x&lt;br /&gt;= f&lt;br /&gt;&lt;br /&gt;-- Right identity: f . id = f&lt;br /&gt;f . id&lt;br /&gt;= \x -&gt; f (id x)&lt;br /&gt;= \x -&gt; f x&lt;br /&gt;= f&lt;br /&gt;&lt;br /&gt;-- Associativity: (f . g) . h = f . (g . h)&lt;br /&gt;(f . g) . h&lt;br /&gt;= \x -&gt; (f . g) (h x)&lt;br /&gt;= \x -&gt; f (g (h x))&lt;br /&gt;= \x -&gt; f ((g . h) x)&lt;br /&gt;= \x -&gt; (f . (g . h)) x&lt;br /&gt;= f . (g . h)&lt;br /&gt;&lt;/pre&gt;Function composition is very easy to use, yet so powerful, precisely because it forms a category!  This lets us express complex transformations simply by composing a bunch of reusable parts: &lt;pre&gt;&lt;br /&gt;bestLangs :: [Language] -&gt; [Language]&lt;br /&gt;bestLangs = take 3 . sortBy (comparing speed) . filter isCool&lt;br /&gt;&lt;/pre&gt;Unfortunately, we can't express all of our programs as chains of ordinary functions.  I guess we just give up, right?  Wrong!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Kleisli category&lt;/h4&gt;&lt;br /&gt;The next most common category we encounter on a daily basis is the category of monadic functions, which generalize ordinary functions: &lt;pre&gt;&lt;br /&gt;return :: (Monad m) =&gt; (a -&gt; m a)&lt;br /&gt;&lt;br /&gt;(&lt;=&lt;)  :: (Monad m) =&gt; (b -&gt; m c) -&gt; (a -&gt; m b) -&gt; (a -&gt; m c)&lt;br /&gt;&lt;/pre&gt;Mathematicians call this the  "Kleisli" category, and &lt;tt&gt;Control.Monad&lt;/tt&gt; provides both of the above functions.&lt;br /&gt;&lt;br /&gt;Notice how the type signatures of &lt;tt&gt;return&lt;/tt&gt; and &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt; resemble their functional counterparts: &lt;pre&gt;&lt;br /&gt;id     ::              (a -&gt;   a)&lt;br /&gt;return :: (Monad m) =&gt; (a -&gt; m a)&lt;br /&gt;&lt;br /&gt;(.)    ::              (b -&gt;   c) -&gt; (a -&gt;   b) -&gt; (a -&gt;   c)&lt;br /&gt;(&lt;=&lt;)  :: (Monad m) =&gt; (b -&gt; m c) -&gt; (a -&gt; m b) -&gt; (a -&gt; m c)&lt;br /&gt;&lt;/pre&gt;The implementation for &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt; also resembles the implementation for function composition: &lt;pre&gt;&lt;br /&gt;(f  .  g) x = f     (g x)&lt;br /&gt;(f &lt;=&lt; g) x = f =&lt;&lt; (g x)&lt;br /&gt;&lt;br /&gt;-- Note (=&lt;&lt;) is the same as (&gt;&gt;=), but with the arguments flipped&lt;br /&gt;&lt;/pre&gt;Not a coincidence!  Monadic functions just generalize ordinary functions and the Kleisli category demonstrates that monadic functions are composable, too. They just use a different composition operator: &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt;, and a different identity: &lt;tt&gt;return&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Well, let's assume that category theorists aren't bullshitting us and that &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt; really is some sort of composition and &lt;tt&gt;return&lt;/tt&gt; really is its identity.  If that were true, we'd expect the following laws to hold: &lt;pre&gt;&lt;br /&gt;return &lt;=&lt; f = f                   -- Left  identity&lt;br /&gt;&lt;br /&gt;f &lt;=&lt; return = f                   -- Right identity&lt;br /&gt;&lt;br /&gt;(f &lt;=&lt; g) &lt;=&lt; h = f &lt;=&lt; (g &lt;=&lt; h)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Well, we already have the definition for &lt;tt&gt;(&lt;=&lt;)&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;(f &lt;=&lt; g) x = f =&lt;&lt; (g x)&lt;br /&gt;&lt;/pre&gt;... so let's use that definition to expand those laws: &lt;pre&gt;&lt;br /&gt;return =&lt;&lt; (f x) = (f x)&lt;br /&gt;&lt;br /&gt;f =&lt;&lt; (return x) = f x&lt;br /&gt;&lt;br /&gt;(\y -&gt; f =&lt;&lt; (g y)) =&lt;&lt; h x = f =&lt;&lt; (g =&lt;&lt; (h x))&lt;br /&gt;&lt;/pre&gt;If we simplify those a little and use &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt; to flip the order of arguments, we get: &lt;pre&gt;&lt;br /&gt;m &gt;&gt;= return = m&lt;br /&gt;&lt;br /&gt;return x &gt;&gt;= f = f x&lt;br /&gt;&lt;br /&gt;m &gt;&gt;= (\y -&gt; g y &gt;&gt;= f) = (m &gt;&gt;= g) &gt;&gt;= f&lt;br /&gt;&lt;/pre&gt;Look familiar?  Those are just the &lt;a href="http://www.haskell.org/haskellwiki/Monad_Laws"&gt;monad laws&lt;/a&gt;, which all &lt;tt&gt;Monad&lt;/tt&gt; instances are required to satisfy.  If you have ever wondered where those monad laws came from, now you know!  They are just the category laws in disguise.&lt;br /&gt;&lt;br /&gt;Consequently, every new &lt;tt&gt;Monad&lt;/tt&gt; we define gives us a category for free!  Let's try out some of these brave new categories: &lt;pre&gt;&lt;br /&gt;-- The Kleisli category for the Maybe monad&lt;br /&gt;lookup  :: k -&gt; [(k, v)] -&gt; Maybe v&lt;br /&gt;maximumByMay :: (a -&gt; a -&gt; Ordering) -&gt; [a] -&gt; Maybe a&lt;br /&gt;&lt;br /&gt;bestSuitor :: [(String, [Suitor])] -&gt; Maybe Suitor&lt;br /&gt;bestSuitor = maximumByMay (comparing handsome) &lt;=&lt; lookup "Tall"&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;-- The Kleisli category for the [] monad&lt;br /&gt;children :: Person -&gt; [Person]&lt;br /&gt;&lt;br /&gt;greatGrandChildren :: Person -&gt; [Person]&lt;br /&gt;greatGrandChildren = children &lt;=&lt; children &lt;=&lt; children&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;-- The Kleisli category for the IO monad&lt;br /&gt;-- * Stolen from /r/haskell today&lt;br /&gt;spawn      ::  IO a  -&gt; IO (IO a)&lt;br /&gt;mapM spawn :: [IO a] -&gt; IO [IO a]&lt;br /&gt;sequence   :: [IO a] -&gt; IO    [a]&lt;br /&gt;&lt;br /&gt;concurrentSequence :: [IO a] -&gt; IO [a]&lt;br /&gt;concurrentSequence = sequence &lt;=&lt; mapM spawn&lt;br /&gt;&lt;/pre&gt;Monads that don't observe these laws are buggy and unintuitive.  Don't believe me?  Just ask the people who tried to use &lt;a href="http://www.haskell.org/haskellwiki/ListT_done_right#Examples"&gt;ListT &lt;/a&gt;, which breaks the monad laws.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The &lt;tt&gt;Pipe&lt;/tt&gt; category&lt;/h4&gt;&lt;br /&gt;Not all categories are functions.  I'll use a primitive version of my &lt;tt&gt;Pipe&lt;/tt&gt; type (from the &lt;tt&gt;pipes&lt;/tt&gt; package) with effects removed to simplify the example: &lt;pre&gt;&lt;br /&gt;data Pipe a b r&lt;br /&gt;  = Pure r&lt;br /&gt;  | Await (a -&gt; Pipe a b r)&lt;br /&gt;  | Yield b (Pipe a b r)&lt;br /&gt;&lt;br /&gt;Pure    r  &lt;+&lt; _          = Pure r&lt;br /&gt;Yield b p1 &lt;+&lt; p2         = Yield b (p1 &lt;+&lt; p2)&lt;br /&gt;Await   f  &lt;+&lt; Yield b p2 = f b &lt;+&lt; p2&lt;br /&gt;p1         &lt;+&lt; Await   f  = Await $ \a -&gt; p1 &lt;+&lt; f a&lt;br /&gt;_          &lt;+&lt; Pure    r  = Pure r&lt;br /&gt;&lt;br /&gt;idP = Await $ \a -&gt; Yield a idP&lt;br /&gt;&lt;/pre&gt;Let's check out what types the compiler infers: &lt;pre&gt;&lt;br /&gt;idP   :: Pipe a a r&lt;br /&gt;&lt;br /&gt;(&lt;+&lt;) :: Pipe b c r -&gt; Pipe a b r -&gt; Pipe a c r&lt;br /&gt;&lt;/pre&gt;Those look an awful lot like an identity and composition.  I leave it as an exercise for the reader to prove that they actually do form a category: &lt;pre&gt;&lt;br /&gt;idP &lt;+&lt; p = p                            -- Right identity&lt;br /&gt;&lt;br /&gt;p &lt;+&lt; idP = p                            -- Left  identity&lt;br /&gt;&lt;br /&gt;(p1 &lt;+&lt; p2) &lt;+&lt; p3 = p1 &lt;+&lt; (p2 &lt;+&lt; p3)  -- Associativity&lt;br /&gt;&lt;/pre&gt;Pipes show how more complicated things that don't fit neatly into the functional programming paradigm can still be achieved with a compositional programming style.  I won't belabor the compositionality of pipes, though, since my &lt;a href="http://hackage.haskell.org/packages/archive/pipes/2.2.0/doc/html/Control-Pipe-Tutorial.html"&gt;tutorial&lt;/a&gt; already does that.&lt;br /&gt;&lt;br /&gt;So if you find something that doesn't seem like it could be compositional, don't give up!  Chances are that a compositional solution exists just beneath the surface!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;All category theory says is that composition is the best design pattern, but then leaves it up to you to define what precisely composition is.  It's up to you to discover new and interesting ways to compose things besides just composing functions.  As long as the composition operator you define obeys the category laws, you're golden.&lt;br /&gt;&lt;br /&gt;Also, I'm really glad too see a resurgence in functional programming (since functions form a category), but in the long run we really need to think about more interesting composition operators than just function composition if we are serious about tackling more complicated problem domains.&lt;br /&gt;&lt;br /&gt;Hopefully this post gets you a little bit excited about category theory.  In future posts, I will expand upon this post with the following topics: &lt;ul&gt;&lt;li&gt; Why the category laws ensure that code is easy, intuitive, and free of edge cases &lt;li&gt; How functors let you mix and match different categories &lt;li&gt; How to use categories to optimize your code &lt;li&gt; How to use categories to simplify equational reasoning &lt;/ul&gt;</description><link>http://www.haskellforall.com/2012/08/the-category-design-pattern.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>20</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5709960682784261967</guid><pubDate>Sat, 11 Aug 2012 00:14:00 +0000</pubDate><atom:updated>2012-08-10T22:06:10.584-07:00</atom:updated><title>Code Example #1</title><description>I've seen beginners on /r/haskell ask for practical code examples so I thought I would share some code from my own work.  Today's example will focus on how you can use Haskell to write clear and self-documenting code.&lt;br /&gt;&lt;br /&gt;Today my PI gave me the following task: &lt;ul&gt;&lt;li&gt; Parse the alpha carbons from a PDB file &lt;li&gt; Scan the sequence using a window of a given size &lt;li&gt; For each window, collect all residues within a certain distance (called the "context") &lt;li&gt; Split the context into contiguous chains &lt;/ul&gt;Don't worry if you don't understand the terminology, because I will explain the terms as I go along.&lt;br /&gt;&lt;br /&gt;If you want to follow along, use the full code sample in the appendix and download and extract the sample PDB file: &lt;a href="http://www.rcsb.org/pdb/files/1YU0.pdb.gz"&gt;1YU0.pdb&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Parsing&lt;/h4&gt;&lt;br /&gt;The first thing I had to do was to take a protein structure and parse it into its alpha carbons.  The input format is a Protein Data Bank (i.e. PDB) file, which has a well documented file format found &lt;a href="http://www.wwpdb.org/docs.html"&gt;here&lt;/a&gt;.  I'm interested in the &lt;tt&gt;ATOM&lt;/tt&gt; record, which specifies the coordinates of a single atom in the PDB file: &lt;pre&gt;&lt;br /&gt;COLUMNS        DATA  TYPE    FIELD        DEFINITION&lt;br /&gt;----------------------------------------------------------------&lt;br /&gt; 1 -  6        Record name   "ATOM  "&lt;br /&gt; 7 - 11        Integer       serial       Atom  serial number.&lt;br /&gt;13 - 16        Atom          name         Atom name.&lt;br /&gt;17             Character     altLoc       Alternate location ind&lt;br /&gt;18 - 20        Residue name  resName      Residue name.&lt;br /&gt;22             Character     chainID      Chain identifier.&lt;br /&gt;23 - 26        Integer       resSeq       Residue sequence numbe&lt;br /&gt;27             AChar         iCode        Code for insertion of &lt;br /&gt;31 - 38        Real(8.3)     x            Coordinates for X in A&lt;br /&gt;39 - 46        Real(8.3)     y            Coordinates for Y in A&lt;br /&gt;47 - 54        Real(8.3)     z            Coordinates for Z in A&lt;br /&gt;55 - 60        Real(6.2)     occupancy    Occupancy.&lt;br /&gt;61 - 66        Real(6.2)     tempFactor   Temperature  factor.&lt;br /&gt;77 - 78        LString(2)    element      Element symbol, right-&lt;br /&gt;79 - 80        LString(2)    charge       Charge  on the atom.&lt;br /&gt;&lt;/pre&gt;There are seven fields I have to parse out from an &lt;tt&gt;Atom&lt;/tt&gt; record: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;resName&lt;/tt&gt;: Alpha carbons have this set to "&lt;tt&gt; CA &lt;/tt&gt;".  Each residue has exactly one alpha carbon which is often used as a coarse-grained proxy for the entire residue. &lt;li&gt; &lt;tt&gt;chainID&lt;/tt&gt;: Chains are contiguous segments of proteins, labeled by a single letter. &lt;li&gt; &lt;tt&gt;resSeq&lt;/tt&gt;: Residues are the individual building blocks of proteins.  Each residue in a chain is sequentially numbered for unique identification. &lt;li&gt; &lt;tt&gt;altLoc&lt;/tt&gt;: Residues can have multiple coordinates, and I arbitrarily pick the first set of coordinates. &lt;li&gt; &lt;tt&gt;x&lt;/tt&gt;, &lt;tt&gt;y&lt;/tt&gt;, and &lt;tt&gt;z&lt;/tt&gt;: The atom's coordinates. &lt;/ul&gt;Out of those fields, I only want to retain the &lt;tt&gt;chainID&lt;/tt&gt;, &lt;tt&gt;resSeq&lt;/tt&gt;, &lt;tt&gt;x&lt;/tt&gt;, &lt;tt&gt;y&lt;/tt&gt;, and &lt;tt&gt;z&lt;/tt&gt; fields, so I create a data structure to hold them: &lt;pre&gt;&lt;br /&gt;import Numeric.LinearAlgebra -- from the "hmatrix" package&lt;br /&gt;&lt;br /&gt;type Point = Vector Double&lt;br /&gt;&lt;br /&gt;data Atom = Atom {&lt;br /&gt;    chainID :: Char  ,&lt;br /&gt;    resSeq  :: Int   ,&lt;br /&gt;    coord   :: Point }&lt;br /&gt;    deriving (Show)&lt;br /&gt;&lt;/pre&gt;Here I use a type synonym to document what I want to use &lt;tt&gt;coord&lt;/tt&gt; for. This has the added advantage that I can use a different &lt;tt&gt;Point&lt;/tt&gt; type later on (such as a length-indexed type), and I need only update the type synonym to update my type signatures.&lt;br /&gt;&lt;br /&gt;Now I need a way to parse an atom record, and I'll use &lt;tt&gt;attoparsec&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;{-# LANGUAGE OverloadedStrings #-}&lt;br /&gt;&lt;br /&gt;import Control.Monad&lt;br /&gt;import Data.Attoparsec.Char8 as P hiding (skipWhile)&lt;br /&gt;import Data.Attoparsec (skipWhile)&lt;br /&gt;&lt;br /&gt;skip n = void $ P.take n&lt;br /&gt;decimal' = skipSpace &gt;&gt; decimal&lt;br /&gt;double'  = skipSpace &gt;&gt; double&lt;br /&gt;&lt;br /&gt;pAtom :: Parser Atom&lt;br /&gt;pAtom = do&lt;br /&gt;    string "ATOM  "        -- Must be an "ATOM  " record&lt;br /&gt;    skip 6&lt;br /&gt;    string " CA "          -- Must be an alpha carbon&lt;br /&gt;    satisfy (inClass " A") -- First conformation (' ' or 'A')&lt;br /&gt;    skip 4&lt;br /&gt;    _chainID &lt;- anyChar&lt;br /&gt;    _resSeq &lt;- decimal'&lt;br /&gt;    skip 1&lt;br /&gt;    x &lt;- double'&lt;br /&gt;    y &lt;- double'&lt;br /&gt;    z &lt;- double'&lt;br /&gt;    skip 26&lt;br /&gt;    endOfLine&lt;br /&gt;    return $ Atom {&lt;br /&gt;        chainID = _chainID,&lt;br /&gt;        resSeq  = _resSeq,&lt;br /&gt;        coord   = fromList [x, y, z] }&lt;br /&gt;&lt;/pre&gt;That was pretty easy!  Notice how I rename &lt;tt&gt;P.take&lt;/tt&gt; to &lt;tt&gt;skip&lt;/tt&gt; as a sort of in-line comment to document my intention to discard the output.  I also use &lt;tt&gt;void&lt;/tt&gt; to force it to discard the result and match the intention. &lt;br /&gt;&lt;br /&gt;The next step is to create a parser for the entire file that throws out all lines that do not match: &lt;pre&gt;&lt;br /&gt;import Control.Applicative&lt;br /&gt;import Data.Maybe&lt;br /&gt;&lt;br /&gt;pLine = skipWhile (not . isEndOfLine) *&gt; endOfLine&lt;br /&gt;&lt;br /&gt;pPDB :: Parser [Atom]&lt;br /&gt;pPDB = catMaybes &lt;$&gt; (many $     (Just    &lt;$&gt; pAtom)&lt;br /&gt;                             &lt;|&gt; (Nothing &lt;$  pLine) )&lt;br /&gt;&lt;/pre&gt;Now, the awesome thing about Haskell is that you can very quickly test things out in &lt;tt&gt;ghci&lt;/tt&gt;, so let's fire up the module and see if it works: &lt;pre&gt;&lt;br /&gt;*Main&gt; import qualified Data.ByteString.Char8 as B&lt;br /&gt;*Main B&gt; str &lt;- B.readFile "/path/to/1YU0.pdb"&lt;br /&gt;*Main B&gt; parseOnly pPDB str&lt;br /&gt;...&lt;br /&gt;sSeq = 376, coord = fromList [5.274,108.854,3.352]},Atom {chainI&lt;br /&gt;D = 'A', resSeq = 377, coord = fromList [5.643,111.164,6.349]},A&lt;br /&gt;tom {chainID = 'A', resSeq = 378, coord = fromList [4.35,109.87,&lt;br /&gt;9.685]},Atom {chainID = 'A', resSeq = 379, coord = fromList [3.2&lt;br /&gt;33,112.127,12.52]},Atom {chainID = 'A', resSeq = 380, coord = fr&lt;br /&gt;omList [1.9729999999999999,110.268,15.618]}]&lt;br /&gt;&lt;/pre&gt;Great!  It works!  (Note: It actually is not correct because it doesn't remove multiple protein models for NMR structures, but I'm glossing over that for now). &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Distances&lt;/h4&gt;&lt;br /&gt;I can't really calculate distance cutoffs without some sort of a distance function: &lt;pre&gt;&lt;br /&gt;import Data.Function (on)&lt;br /&gt;&lt;br /&gt;dist :: Point -&gt; Point -&gt; Double&lt;br /&gt;dist v1 v2 = norm2 (v1 - v2)&lt;br /&gt;&lt;br /&gt;distA :: Atom -&gt; Atom -&gt; Double&lt;br /&gt;distA = dist `on` coord&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;on&lt;/tt&gt; is a very handy utility to extend binary functions.  More importantly, it makes the code read more like English.  The definition for &lt;tt&gt;distA&lt;/tt&gt; reads like saying "Take the distance on the coord field".&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Context&lt;/h4&gt;&lt;br /&gt;Now I have to associate each atom with its neighbors within some distance. Before I write a potentially confusing function, I write out the type to focus my mind: &lt;pre&gt;&lt;br /&gt;type Context = [Atom]&lt;br /&gt;type Cutoff  = Double&lt;br /&gt;&lt;br /&gt;addContext :: Cutoff -&gt; [Atom] -&gt; [(Atom, Context)]&lt;br /&gt;&lt;/pre&gt;This function takes a list of atoms, and associates each atom with a list of its neighbors within some distance cutoff.  I will be joining these lists of neighbors later on, so really a more efficient data structure would be a &lt;tt&gt;Set&lt;/tt&gt;, but this is good enough for now, and I can optimize it later if necessary.&lt;br /&gt;&lt;br /&gt;Also, note the use of a type synonyms as a quick and dirty documentation.  A well-chosen type synonym can go a long way towards making your code easy to understand.  Also, if I go back and decide to use &lt;tt&gt;Set&lt;/tt&gt;, I only need to change the type synonym definition to: &lt;pre&gt;&lt;br /&gt;type Context = Set Atom&lt;br /&gt;&lt;/pre&gt;.. and all my type signatures will be fixed.&lt;br /&gt;&lt;br /&gt;Anyway, let's compute some neighbors: &lt;pre&gt;&lt;br /&gt;for = flip fmap&lt;br /&gt;&lt;br /&gt;addContext cutoff as = for as $ \a1 -&gt;&lt;br /&gt;    (a1, filter (\a2 -&gt; distA a1 a2 &lt; cutoff) as)&lt;br /&gt;&lt;/pre&gt;This is definitely not an efficient algorithm (a &lt;tt&gt;HashMap&lt;/tt&gt;-based binning algorithm would work faster), but I will let it slide for now since this is just a simple script.  Also, notice that it does not eliminate an atom from its own neighbor list.  This is because the atom will be reintroduced later when joining contexts, so I postpone doing this. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Windows&lt;/h4&gt;&lt;br /&gt;My PI wants a sliding window of 7 residues and a context generated for each window.  Rather than manually slide the window in an imperative style, I instead generate the set of all windows: &lt;pre&gt;&lt;br /&gt;import Data.List&lt;br /&gt;&lt;br /&gt;windows :: Int -&gt; [a] -&gt; [[a]]&lt;br /&gt;windows n = filter (\xs -&gt; length xs == n)&lt;br /&gt;          . map (Prelude.take n)&lt;br /&gt;          . tails&lt;br /&gt;&lt;/pre&gt;For each given window, I have to join the contexts together and eliminate duplicates.  This requires defining what a duplicate is: &lt;pre&gt;&lt;br /&gt;duplicate a1 a2 = chainID a1 == chainID a2&lt;br /&gt;               &amp;&amp; resSeq  a1 == resSeq  a2&lt;br /&gt;&lt;/pre&gt;I could have also used &lt;tt&gt;on&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;duplicate a1 a2 = ((==) `on` chainID) a1 a2&lt;br /&gt;               &amp;&amp; ((==) `on` resSeq ) a1 a2&lt;br /&gt;&lt;/pre&gt;Now I need to specify what it means to join contexts.  I write out a type signature to be precise about what I want: &lt;pre&gt;&lt;br /&gt;joinContexts :: [(Atom, Context)] -&gt; ([Atom], Context)&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;joinContexts&lt;/tt&gt; takes a window of atoms and their individual contexts, and joins all the contexts into one, leaving behind just a list of atoms: &lt;pre&gt;&lt;br /&gt;joinContexts ps = (self, nonSelf)&lt;br /&gt;  where self = map fst ps&lt;br /&gt;        context = concat $ map snd ps&lt;br /&gt;        totalContext = nubBy duplicate context&lt;br /&gt;        nonSelf = deleteFirstsBy duplicate totalContext self&lt;br /&gt;&lt;/pre&gt;Using &lt;tt&gt;let&lt;/tt&gt; or &lt;tt&gt;where&lt;/tt&gt; clauses is another great way to annotate intermediate steps in a function, although that will be pretty obvious to most readers.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Chains&lt;/h4&gt;&lt;br /&gt;Finally, I have to split each context into chains, defined as consecutive residues with the same &lt;tt&gt;chainID&lt;/tt&gt;.  I have a utility function for this purpose that I keep lying around, defined as: &lt;pre&gt;&lt;br /&gt;import Data.Monoid&lt;br /&gt;import Data.Ord&lt;br /&gt;&lt;br /&gt;sequential a1 a2 = chainID a1     == chainID a2&lt;br /&gt;               &amp;&amp; (resSeq  a1 + 1 == resSeq  a2)&lt;br /&gt;&lt;br /&gt;type Chain = [Atom]&lt;br /&gt;&lt;br /&gt;chains' :: ([Atom] -&gt; [Atom]) -&gt; [Atom] -&gt; [Chain]&lt;br /&gt;chains' c []  = [c [] ]&lt;br /&gt;chains' c [a] = [c [a]]&lt;br /&gt;chains' c (a1:bs@(a2:as))&lt;br /&gt;    | sequential a1 a2 =         chains' c' bs&lt;br /&gt;    | otherwise        = (c' []):chains' id bs&lt;br /&gt;  where c' = c . (a1:)&lt;br /&gt;&lt;br /&gt;-- The actual function I use&lt;br /&gt;chains :: [Atom] -&gt; [Chain]&lt;br /&gt;chains = chains' id&lt;br /&gt;       . sortBy (comparing chainID `thenBy` comparing resSeq)&lt;br /&gt;  where thenBy = mappend&lt;br /&gt;&lt;/pre&gt;I want to draw attention to the &lt;tt&gt;sortBy&lt;/tt&gt; call in the &lt;tt&gt;chains&lt;/tt&gt;function.  This takes advantage of two very useful tricks.  The first is the &lt;tt&gt;comparing&lt;/tt&gt; function from &lt;tt&gt;Data.Ord&lt;/tt&gt;.  The second is the &lt;tt&gt;Monoid&lt;/tt&gt; trick to &lt;a href="http://stackoverflow.com/questions/11486436/composing-two-comparison-functions"&gt;compose two orderings&lt;/a&gt;, giving priority to the first one.  Combining the two tricks gives code that reads like English: "Sort by comparing &lt;tt&gt;chainID&lt;/tt&gt; first, then by comparing &lt;tt&gt;resSeq&lt;/tt&gt;".&lt;br /&gt;&lt;br /&gt;The last step is that I have to take each window and the chains in its context and pair the window with each chain.  If that didn't make sense, I'm pretty sure the type signature would make it clear: &lt;pre&gt;&lt;br /&gt;type Window = [Atom]&lt;br /&gt;&lt;br /&gt;distribute :: (Window, [Chain]) -&gt; [(Window, Chain)]&lt;br /&gt;&lt;/pre&gt;This shows how Haskell type signatures can often be "self-documenting" and can say a lot of things that we might have difficulty articulating clearly in words: &lt;pre&gt;&lt;br /&gt;-- most polymorphic type :: (a, [b]) -&gt; [(a, b)]&lt;br /&gt;distribute (x, ys) = map ((,) x) ys&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Combining Everything&lt;/h4&gt;&lt;br /&gt;Now I combine all the small functions I wrote into one pipeline: &lt;pre&gt;&lt;br /&gt;import Control.Arrow (second)&lt;br /&gt;&lt;br /&gt;type WindowSize = Int&lt;br /&gt;&lt;br /&gt;pairs :: WindowSize -&gt; Cutoff -&gt; [Atom] -&gt; [(Window, Chain)]&lt;br /&gt;pairs windowSize cutoff =&lt;br /&gt;    concat&lt;br /&gt;  . map (distribute . second chains . joinContexts)&lt;br /&gt;  . windows windowSize&lt;br /&gt;  . addContext cutoff&lt;br /&gt;&lt;/pre&gt;The above function pipeline clearly illustrates the flow of information and makes it easy to reason about what my code actually does.  I could even use it as a high-level specification of my program.  Reading from bottom to top it says that you: &lt;ul&gt;&lt;li&gt; Attach contexts &lt;li&gt; Partition the sequence into windows &lt;li&gt; For each window: &lt;ul&gt;&lt;li&gt; Join the contexts &lt;li&gt; Group the joined context into chains &lt;li&gt; Distribute the window over each chain &lt;/ul&gt;&lt;li&gt; Concatenate all the results &lt;/ul&gt;If you prefer to order things from left to write (or top to bottom), then you can use the &lt;tt&gt;(&gt;&gt;&gt;)&lt;/tt&gt; operation from &lt;tt&gt;Control.Category&lt;/tt&gt; to reverse the direction in which you compose functions: &lt;pre&gt;&lt;br /&gt;import Control.Category&lt;br /&gt;import Prelude hiding ((.), id)&lt;br /&gt;&lt;br /&gt;pairs windowSize cutoff =&lt;br /&gt;     addContext cutoff&lt;br /&gt; &gt;&gt;&gt; windows windowSize&lt;br /&gt; &gt;&gt;&gt; map (joinContexts &gt;&gt;&gt; second chains &gt;&gt;&gt; distribute)&lt;br /&gt; &gt;&gt;&gt; concat&lt;br /&gt;&lt;/pre&gt;A compositional style where you chain lots of small functions makes the final overarching program much easier to follow.&lt;br /&gt;&lt;br /&gt;All that remains is to quickly test out the code in &lt;tt&gt;ghci&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;*Main&gt; import qualified Data.ByteString.Char8 as B&lt;br /&gt;*Main B&gt; str &lt;- B.readFile "/path/to/1YU0.pdb"&lt;br /&gt;*Main B&gt; let atoms = parseOnly pPDB str&lt;br /&gt;*Main B&gt; -- I use fmap since parseOnly returns an Either&lt;br /&gt;*Main B&gt; let ps = fmap (pairs 7 12.0) atoms&lt;br /&gt;*Main B&gt; -- How many pairs?&lt;br /&gt;*Main B&gt; fmap length ps&lt;br /&gt;Right 3559&lt;br /&gt;*Main B&gt; -- What is the largest contiguous chain in a context?&lt;br /&gt;*Main B&gt; let size = length . snd&lt;br /&gt;*Main B&gt; let largest = fmap (maximumBy (comparing size)) ps&lt;br /&gt;*Main B&gt; fmap size largest&lt;br /&gt;Right 38&lt;br /&gt;*Main B&gt; -- Which residues did it span?&lt;br /&gt;*Main B&gt; fmap (map resSeq . snd) largest&lt;br /&gt;Right [337,338,339,340,341,342,343,344,345,346,347,348,349,350,&lt;br /&gt;351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366&lt;br /&gt;,367,368,369,370,371,372,373,374]&lt;br /&gt;*Main B&gt; -- What was the window it matched?&lt;br /&gt;*Main B&gt; fmap (map resSeq . fst) largest&lt;br /&gt;Right [304,305,306,307,308,309,310]&lt;br /&gt;&lt;/pre&gt;I then load up the protein in PyMOL to inspect the matched ranges and, sure enough, it works correctly: &lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="http://4.bp.blogspot.com/-smm0QWGe8Hc/UCWeM0nJLRI/AAAAAAAAAB8/iqF475mRq9Q/s1600/context.png" imageanchor="1" style="margin-left:1em; margin-right:1em"&gt;&lt;img border="0" height="240" width="320" src="http://4.bp.blogspot.com/-smm0QWGe8Hc/UCWeM0nJLRI/AAAAAAAAAB8/iqF475mRq9Q/s320/context.png" /&gt;&lt;/a&gt;&lt;/div&gt;In the image I highlighted the matched window in yellow and the matched context in purple.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;So I hope this shows some of the tricks I use to improve code clarity.  I left out a lot of type signatures for brevity because this was a one-off script and I only wanted to draw attention to certain functions, but if I were really serious about fully documenting the code I would include all type signatures.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Appendix: Full code&lt;/h4&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;{-# LANGUAGE OverloadedStrings #-}&lt;br /&gt;&lt;br /&gt;import Control.Applicative&lt;br /&gt;import Control.Arrow (second)&lt;br /&gt;import Control.Monad&lt;br /&gt;import Data.Attoparsec.Char8 as P hiding (skipWhile)&lt;br /&gt;import Data.Attoparsec (skipWhile)&lt;br /&gt;import Data.Function (on)&lt;br /&gt;import Data.List&lt;br /&gt;import Data.Maybe&lt;br /&gt;import Data.Monoid&lt;br /&gt;import Data.Ord&lt;br /&gt;import Numeric.LinearAlgebra -- from the "hmatrix" package&lt;br /&gt;&lt;br /&gt;type Point = Vector Double&lt;br /&gt;&lt;br /&gt;data Atom = Atom {&lt;br /&gt;    chainID :: Char,&lt;br /&gt;    resSeq  :: Int,&lt;br /&gt;    coord   :: Point }&lt;br /&gt;    deriving (Show)&lt;br /&gt;&lt;br /&gt;skip n = void $ P.take n&lt;br /&gt;decimal' = skipSpace &gt;&gt; decimal&lt;br /&gt;double'  = skipSpace &gt;&gt; P.double&lt;br /&gt;&lt;br /&gt;pAtom :: Parser Atom&lt;br /&gt;pAtom = do&lt;br /&gt;    string "ATOM  "        -- Must be an "ATOM  " record&lt;br /&gt;    skip 6&lt;br /&gt;    string " CA "          -- Must be an alpha carbon&lt;br /&gt;    satisfy (inClass " A") -- First confirmation (' ' or 'A')&lt;br /&gt;    skip 4&lt;br /&gt;    _chainID &lt;- anyChar&lt;br /&gt;    _resSeq &lt;- decimal'&lt;br /&gt;    skip 1&lt;br /&gt;    x &lt;- double'&lt;br /&gt;    y &lt;- double'&lt;br /&gt;    z &lt;- double'&lt;br /&gt;    skip 26&lt;br /&gt;    endOfLine&lt;br /&gt;    return $ Atom {&lt;br /&gt;        chainID = _chainID,&lt;br /&gt;        resSeq  = _resSeq,&lt;br /&gt;        coord   = fromList [x, y, z] }&lt;br /&gt;&lt;br /&gt;pLine = skipWhile (not . isEndOfLine) *&gt; endOfLine&lt;br /&gt;&lt;br /&gt;pPDB :: Parser [Atom]&lt;br /&gt;pPDB = catMaybes &lt;$&gt; (    many $ (Just &lt;$&gt; pAtom)&lt;br /&gt;                      &lt;|&gt; (Nothing &lt;$ pLine))&lt;br /&gt;&lt;br /&gt;dist :: Point -&gt; Point -&gt; Double&lt;br /&gt;dist v1 v2 = norm2 (v1 - v2)&lt;br /&gt;&lt;br /&gt;distA :: Atom -&gt; Atom -&gt; Double&lt;br /&gt;distA = dist `on` coord&lt;br /&gt;&lt;br /&gt;type Context = [Atom]&lt;br /&gt;type Cutoff  = Double&lt;br /&gt;&lt;br /&gt;for = flip fmap&lt;br /&gt;&lt;br /&gt;addContext :: Cutoff -&gt; [Atom] -&gt; [(Atom, Context)]&lt;br /&gt;addContext cutoff as = for as $ \a1 -&gt;&lt;br /&gt;    (a1, filter (\a2 -&gt; distA a1 a2 &lt; cutoff) as)&lt;br /&gt;&lt;br /&gt;windows :: Int -&gt; [a] -&gt; [[a]]&lt;br /&gt;windows n = filter (\xs -&gt; length xs == n)&lt;br /&gt;          . map (Prelude.take n)&lt;br /&gt;          . tails&lt;br /&gt;&lt;br /&gt;duplicate a1 a2 = chainID a1 == chainID a2&lt;br /&gt;               &amp;&amp; resSeq  a1 == resSeq  a2&lt;br /&gt;&lt;br /&gt;joinContexts :: [(Atom, Context)] -&gt; ([Atom], Context)&lt;br /&gt;joinContexts ps = (self, nonSelf)&lt;br /&gt;  where self = map fst ps&lt;br /&gt;        context = concat $ map snd ps&lt;br /&gt;        totalContext = nubBy duplicate context&lt;br /&gt;        nonSelf = deleteFirstsBy duplicate totalContext self&lt;br /&gt;&lt;br /&gt;sequential a1 a2 = chainID a1     == chainID a2&lt;br /&gt;               &amp;&amp; (resSeq  a1 + 1 == resSeq  a2)&lt;br /&gt;&lt;br /&gt;type Chain = [Atom]&lt;br /&gt;&lt;br /&gt;chains' :: ([Atom] -&gt; [Atom]) -&gt; [Atom] -&gt; [Chain]&lt;br /&gt;chains' c []  = [c [] ]&lt;br /&gt;chains' c [a] = [c [a]]&lt;br /&gt;chains' c (a1:bs@(a2:as))&lt;br /&gt;    | sequential a1 a2 =         chains' c' bs&lt;br /&gt;    | otherwise        = (c' []):chains' id bs&lt;br /&gt;  where c' = c . (a1:)&lt;br /&gt;&lt;br /&gt;-- The actual function I use&lt;br /&gt;chains :: [Atom] -&gt; [Chain]&lt;br /&gt;chains = chains' id&lt;br /&gt;       . sortBy (comparing chainID `thenBy` comparing resSeq)&lt;br /&gt;  where thenBy = mappend&lt;br /&gt;&lt;br /&gt;type Window = [Atom]&lt;br /&gt;&lt;br /&gt;distribute :: (Window, [Chain]) -&gt; [(Window, Chain)]&lt;br /&gt;distribute (x, ys) = map ((,) x) ys&lt;br /&gt;&lt;br /&gt;type WindowSize = Int&lt;br /&gt;&lt;br /&gt;pairs :: WindowSize -&gt; Cutoff -&gt; [Atom] -&gt; [(Window, Chain)]&lt;br /&gt;pairs windowSize cutoff =&lt;br /&gt;    concat&lt;br /&gt;  . map (distribute . second chains . joinContexts)&lt;br /&gt;  . windows windowSize&lt;br /&gt;  . addContext cutoff&lt;br /&gt;&lt;/pre&gt;</description><link>http://www.haskellforall.com/2012/08/code-example-1.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><media:thumbnail xmlns:media='http://search.yahoo.com/mrss/' url='http://4.bp.blogspot.com/-smm0QWGe8Hc/UCWeM0nJLRI/AAAAAAAAAB8/iqF475mRq9Q/s72-c/context.png' height='72' width='72'/><thr:total>0</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-1271468473371720067</guid><pubDate>Tue, 31 Jul 2012 14:20:00 +0000</pubDate><atom:updated>2012-07-31T07:20:31.482-07:00</atom:updated><title>Free monad transformers</title><description>I'm spinning off the &lt;tt&gt;Control.Monad.Trans.Free&lt;/tt&gt; module from &lt;tt&gt;pipes&lt;/tt&gt; into its &lt;a href="http://hackage.haskell.org/package/transformers-free"&gt;own package&lt;/a&gt;: &lt;tt&gt;transformers-free&lt;/tt&gt;.  Some people requested this because they wanted to experiment with the &lt;tt&gt;FreeT&lt;/tt&gt; type in their own code without making &lt;tt&gt;pipes&lt;/tt&gt; a full-blown dependency.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Free monad transformers&lt;/h4&gt;&lt;br /&gt;Recently I've evangelized the use of free monads for building abstract syntax trees that let you abstract away the interpreter.  This lets you seamlessly build custom domain-specific languages in Haskell.&lt;br /&gt;&lt;br /&gt;However, sometimes we can't specify the syntax tree all at once.  Often we want to interleave the syntax tree with some other monad to generate streaming or interactive computations.  &lt;tt&gt;FreeT&lt;/tt&gt; solves this problem by allowing us to mix building steps of the abstract syntax tree with calling actions in some base monad: &lt;pre&gt;&lt;br /&gt;data FreeF f a x = Pure a | Free (f x)&lt;br /&gt;&lt;br /&gt;newtype FreeT f m a = FreeT {&lt;br /&gt;    runFreeT :: m (FreeF f a (FreeT f m a)) }&lt;br /&gt;&lt;/pre&gt;For example, let's say we want to write our own Python-style generator: &lt;pre&gt;&lt;br /&gt;type Generator b m r = FreeT ((,) b) m r&lt;br /&gt;&lt;/pre&gt;In this case, our syntax tree is an ordinary list where we run the base monad to generate the next element.  We can even duplicate Python syntax: &lt;pre&gt;&lt;br /&gt;yield :: b -&gt; Generator b m ()&lt;br /&gt;yield b = liftF (b, ())&lt;br /&gt;&lt;/pre&gt;We can set the base monad to &lt;tt&gt;IO&lt;/tt&gt; if we want to prompt the user to enter each subsequent element of the list: &lt;pre&gt;&lt;br /&gt;prompt :: Generator String IO r&lt;br /&gt;prompt = forever $ do&lt;br /&gt;    lift $ putStrLn "Enter a string:"&lt;br /&gt;    str &lt;- lift getLine&lt;br /&gt;    yield str&lt;br /&gt;&lt;/pre&gt;We can then demand the next element from our generator using &lt;tt&gt;runFreeT&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;main = do&lt;br /&gt;    x &lt;- runFreeT prompt&lt;br /&gt;    case x of&lt;br /&gt;        Pure       _  -&gt; return ()&lt;br /&gt;        Free (str, _) -&gt; putStrLn $ "User entered: " ++ str&lt;br /&gt;&lt;/pre&gt;This does not prompt the user for an infinite number of values.  Instead, we only prompt the user to enter as many values as we demand from the generator, which was just one value in the above example.  However, if we wanted to bleed our user dry, we could gratuitously demand the entire generator: &lt;pre&gt;&lt;br /&gt;main = putStrLnAllTheThings prompt&lt;br /&gt;&lt;br /&gt;putStrLnAllTheThings gen = do&lt;br /&gt;    x &lt;- runFreeT gen&lt;br /&gt;    case x of&lt;br /&gt;        Pure         _   -&gt; return ()&lt;br /&gt;        Free (str, gen') -&gt; do&lt;br /&gt;            putStrLn str&lt;br /&gt;            putStrLnAllTheThings gen'&lt;br /&gt;&lt;/pre&gt;However, even that still streams the values and never retains them in memory.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Denotation&lt;/h4&gt;&lt;br /&gt;Sometimes we want to give our free monad a complete denotation, but our base functor does not cut it.  The classic example is simulating the &lt;tt&gt;State&lt;/tt&gt; monad using a free monad.  We could try adding the following two terms to our base functor to act like a &lt;tt&gt;State&lt;/tt&gt; monad: &lt;pre&gt;&lt;br /&gt;data BaseF s x&lt;br /&gt;  = Get (s -&gt; x)&lt;br /&gt;  | Put s x&lt;br /&gt;  | Something x&lt;br /&gt;  ...&lt;br /&gt;&lt;/pre&gt;... and we even can write the following &lt;tt&gt;State&lt;/tt&gt;-like primitives: &lt;pre&gt;&lt;br /&gt;get' :: Free (BaseF s) s&lt;br /&gt;get' = liftF $ Get id&lt;br /&gt;&lt;br /&gt;put' :: s -&gt; Free (BaseF s) ()&lt;br /&gt;put' s = liftF $ Put s ()&lt;br /&gt;&lt;/pre&gt;... but these simulated primitives do not necessarily obey the &lt;tt&gt;State&lt;/tt&gt; monad equations such as: &lt;pre&gt;&lt;br /&gt;put x &gt;&gt; put y = put y&lt;br /&gt;get &gt;&gt;= put = return ()&lt;br /&gt;&lt;/pre&gt;However, we can instead outsource part of the denotation to the actual &lt;tt&gt;State&lt;/tt&gt; monad.  All we do is delete the &lt;tt&gt;Get&lt;/tt&gt; and &lt;tt&gt;Put&lt;/tt&gt; constructors from our base functor: &lt;pre&gt;&lt;br /&gt;data BaseF x&lt;br /&gt;  = Something x&lt;br /&gt;  ...&lt;br /&gt;&lt;/pre&gt;... and instead just use &lt;tt&gt;State&lt;/tt&gt; (or &lt;tt&gt;StateT m&lt;/tt&gt;) as the base monad: &lt;pre&gt;&lt;br /&gt;doSomething :: FreeT BaseF (State s) ()&lt;br /&gt;doSomething = do&lt;br /&gt;    x &lt;- lift get&lt;br /&gt;    lift $ put x&lt;br /&gt;    something&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;FreeT&lt;/tt&gt; monad transformer is correct by construction, so we can use the monad transformer laws to equationally reason about our program to eliminate the dead code at the end of our function: &lt;pre&gt;&lt;br /&gt;-- lift m &gt;&gt;= lift . f = lift (m &gt;&gt;= f)&lt;br /&gt;doSomething = do&lt;br /&gt;    lift $ do&lt;br /&gt;        x &lt;- get&lt;br /&gt;        put x&lt;br /&gt;    something&lt;br /&gt;&lt;br /&gt;-- get &gt;&gt;= put = return ()&lt;br /&gt;doSomething = do&lt;br /&gt;    lift $ return ()&lt;br /&gt;    something&lt;br /&gt;&lt;br /&gt;-- lift (return x) = return x&lt;br /&gt;doSomething = do&lt;br /&gt;    return ()&lt;br /&gt;    something&lt;br /&gt;&lt;br /&gt;-- return () &gt;&gt; m = m&lt;br /&gt;doSomething = something&lt;br /&gt;&lt;/pre&gt;&lt;tt&gt;FreeT&lt;/tt&gt; offers us a nice way to selectively outsource our denotation to other monads whenever we need stronger equational guarantees.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;free&lt;/tt&gt; compatibility&lt;/h4&gt;&lt;br /&gt;I do not intend to use &lt;tt&gt;transformers-free&lt;/tt&gt; to replace the &lt;tt&gt;free&lt;/tt&gt; package for free monads that are not monad transformers.  Even in my own code I still use &lt;tt&gt;free&lt;/tt&gt; for ordinary free monads.  I only provide the ordinary &lt;tt&gt;Free&lt;/tt&gt; type to keep the &lt;tt&gt;transformers&lt;/tt&gt; tradition of formulating the ordinary monad in terms of the corresponding monad transformer.&lt;br /&gt;&lt;br /&gt;When designing the &lt;tt&gt;transformers-free&lt;/tt&gt; library, I tried to adhere to the &lt;tt&gt;free&lt;/tt&gt; package as closely as possible for naming conventions.  I really only disagree with one naming convention Edward used, which is naming one of the constructors &lt;tt&gt;Free&lt;/tt&gt;, for two reasons: &lt;ul&gt;&lt;li&gt; It shares the same name as the type, which is confusing since it's not the only constructor. &lt;li&gt; It does not share the same name as its smart constructor, &lt;tt&gt;wrap&lt;/tt&gt;, which is confusing because &lt;tt&gt;Pure&lt;/tt&gt; does share the same name as its smart constructor, &lt;tt&gt;pure&lt;/tt&gt;. &lt;/ul&gt;So he probably should have named the constructor &lt;tt&gt;Wrap&lt;/tt&gt;, but I decided to stick with his name and not buck convention.&lt;br /&gt;&lt;br /&gt;I also structured the &lt;tt&gt;FreeT&lt;/tt&gt; type so that the derived &lt;tt&gt;Free&lt;/tt&gt; type would resemble &lt;tt&gt;Free&lt;/tt&gt; from the &lt;tt&gt;free&lt;/tt&gt; package as closely as possible.  The only difference is that in &lt;tt&gt;transformers-free&lt;/tt&gt; you have to use the &lt;tt&gt;runFree&lt;/tt&gt; observation function first before you can pattern match on the constructors, but otherwise it's identical: &lt;pre&gt;&lt;br /&gt;-- using the "free" package&lt;br /&gt;f :: Free f r -&gt; ...&lt;br /&gt;f x = case x of&lt;br /&gt;    Pure r -&gt; ...&lt;br /&gt;    Free w -&gt; ...&lt;br /&gt;&lt;br /&gt;-- using the "transformers-free" package&lt;br /&gt;f :: Free f r -&gt; ...&lt;br /&gt;f x = case runFree x of&lt;br /&gt;    Pure r -&gt; ...&lt;br /&gt;    Free w -&gt; ...&lt;br /&gt;&lt;/pre&gt;I also found that this was the most natural way to write the &lt;tt&gt;FreeT&lt;/tt&gt; type and the easiest to use, based on my experience using it within the &lt;tt&gt;pipes&lt;/tt&gt; library.  Of course, your own mileage might vary!&lt;br /&gt;&lt;br /&gt;I haven't copied all the functions that the &lt;tt&gt;free&lt;/tt&gt; package provides.  I mainly omitted the recursion schemes because there are a few other recursion schemes that I was also considering: &lt;pre&gt;&lt;br /&gt;foldFree1 :: (a -&gt; r) -&gt; (f r -&gt; r) -&gt; Free f a -&gt; r&lt;br /&gt;-- or&lt;br /&gt;foldFree2 :: (FreeF f a r -&gt; r) -&gt; Free f a -&gt; r&lt;br /&gt;&lt;/pre&gt;... and their &lt;tt&gt;FreeT&lt;/tt&gt; equivalents, which use &lt;tt&gt;m r&lt;/tt&gt; as the carrier of the algebra instead: &lt;pre&gt;&lt;br /&gt;foldFreeT1 :: (a -&gt; m r) -&gt; (f (m r) -&gt; m r) -&gt; FreeT f m a -&gt; r&lt;br /&gt;-- or&lt;br /&gt;foldFreeT2 :: (FreeF f a (m r) -&gt; m r) -&gt; FreeT f m a -&gt; r&lt;br /&gt;&lt;/pre&gt;In the end, I chose not to include anything yet and leave it up to discussion, since it is easier to add API functions than remove them.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Performance&lt;/h4&gt;&lt;br /&gt;I also wrote up a codensity version implemented using the following type: &lt;pre&gt;&lt;br /&gt;newtype FreeT {&lt;br /&gt;    foldFreeT :: (a -&gt; m r) -&gt; (f (m r) -&gt; m r) -&gt; m r }&lt;br /&gt;&lt;/pre&gt;This gives large speed differences for code that never uses the base monad.  I'm on vacation, so I don't have access to my work computer to reproduce the benchmarks, but I vaguely remember that they ranged from a best case improvement of roughly 50% faster for operations on the tail of the list to a worst case penalty of roughly 30% slower for operations on the head of the list.  However, for real world use cases where you intermingle &lt;tt&gt;IO&lt;/tt&gt; operations like simple print statements at each step then the performance differences drop to less than 5%.&lt;br /&gt;&lt;br /&gt;The main reasons I haven't released the codensity version yet are: &lt;ul&gt;&lt;li&gt; If I release multiple implementations, I want to type-class them with appropriate laws. &lt;li&gt; Type-class signatures cannot be easily updated, so I want to solidify the API first. &lt;/ul&gt;Note: Some reddit readers may remember me remarking on the naive implementation giving linear time complexity for left-associative code, but this was a false alarm: the code was actually right-associative.  Since &lt;tt&gt;do&lt;/tt&gt; notation is right-associative, the time complexity difference between left-associative code doesn't arise frequently in practice, but one should always still keep it in mind, especially when writing code like: &lt;pre&gt;&lt;br /&gt;do x &lt;- longFreeMonad&lt;br /&gt;   somethingElse&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;transformers&lt;/tt&gt; compatibility&lt;/h4&gt;&lt;br /&gt;I'm proposing this library as a candidate for inclusion in the &lt;tt&gt;transformers&lt;/tt&gt; package, so the documentation is structured very similarly.&lt;br /&gt;&lt;br /&gt;I also provide a &lt;tt&gt;MonadIO&lt;/tt&gt; instance for the type, something I was very reluctant to do since I consider &lt;tt&gt;MonadTrans&lt;/tt&gt; to be sufficient for that purpose.  However, I relented since: &lt;ul&gt;&lt;li&gt; I've gotten a lot of feedback in favor of a &lt;tt&gt;MonadIO&lt;/tt&gt; instance for this type &lt;li&gt; If this ever does get accepted into &lt;tt&gt;transformers&lt;/tt&gt;, it will get a &lt;tt&gt;MonadIO&lt;/tt&gt; instance anyway. &lt;/ul&gt;&lt;br /&gt;&lt;h4&gt;Iteratees&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;FreeT&lt;/tt&gt; type (or its isomorphic codensity version) arises very frequently in iteratee libraries.  For example, the &lt;tt&gt;Iteratee&lt;/tt&gt; type from the &lt;tt&gt;enumerator&lt;/tt&gt; package is isomorphic to: &lt;pre&gt;&lt;br /&gt;data IterateeF a next&lt;br /&gt;  = Continue (a -&gt; next)&lt;br /&gt;  | Error SomeException&lt;br /&gt;  &lt;br /&gt;Iteratee a m r ~ FreeT (IterateeF (Stream a)) (r, Stream a)&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;Iteratee&lt;/tt&gt; type from the &lt;tt&gt;iteratee&lt;/tt&gt; package is isomorphic to: &lt;pre&gt;&lt;br /&gt;data IterateeF a next&lt;br /&gt;  = Await (a -&gt; next) (Maybe SomeException)&lt;br /&gt;&lt;br /&gt;Iteratee a m r ~ FreeT (IterateeF (Stream a)) (r, Stream a)&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;Pipe&lt;/tt&gt; type from &lt;tt&gt;pipes&lt;/tt&gt; is: &lt;pre&gt;&lt;br /&gt;data PipeF a b next&lt;br /&gt;  = Await (a -&gt; next)&lt;br /&gt;  | Yield (b, next)&lt;br /&gt;&lt;br /&gt;type Pipe a b m r = FreeT (PipeF a b) m r&lt;br /&gt;&lt;/pre&gt;And the &lt;tt&gt;Pipe&lt;/tt&gt; type from &lt;tt&gt;conduit&lt;/tt&gt; is (sort of) isomorphic to: &lt;pre&gt;&lt;br /&gt;data ConduitF l i o u m next&lt;br /&gt;  = HaveOutput (m ()) o next&lt;br /&gt;  | NeedInput (i -&gt; next) (u -&gt; next)&lt;br /&gt;  | LeftOver l next&lt;br /&gt;&lt;br /&gt;Pipe l i o u m r ~ FreeT (ConduitF l i o u m) m r&lt;br /&gt;&lt;/pre&gt;I say "sort of" because &lt;tt&gt;conduit&lt;/tt&gt; followed the &lt;tt&gt;pipes-1.0&lt;/tt&gt; approach that made the base monad optional, which only gives a correct monad transformer when viewed through the lens of &lt;tt&gt;runPipe&lt;/tt&gt;.  However, in principle, &lt;tt&gt;conduit&lt;/tt&gt; with congruence laws implements something isomorphic to &lt;tt&gt;FreeT&lt;/tt&gt; since &lt;tt&gt;conduit&lt;/tt&gt; requires its users only use &lt;tt&gt;runPipe&lt;/tt&gt; to inspect conduits.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;pipes&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;pipes-2.2&lt;/tt&gt; &lt;a href="http://hackage.haskell.org/package/pipes"&gt;package&lt;/a&gt; now uses &lt;tt&gt;transformers-free&lt;/tt&gt; to provide &lt;tt&gt;Control.Monad.Trans.Free&lt;/tt&gt; meaning that &lt;tt&gt;Pipe&lt;/tt&gt; now has a &lt;tt&gt;MonadIO&lt;/tt&gt; instance, something which many people have requested before.&lt;br /&gt;&lt;br /&gt;Also, if you install &lt;tt&gt;transformers-free&lt;/tt&gt; on its own and have an existing &lt;tt&gt;pipes&lt;/tt&gt; installation, make sure that you upgrade &lt;tt&gt;pipes&lt;/tt&gt; to version 2.2 to avoid conflicting exports for &lt;tt&gt;Control.Monad.Trans.Free&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;However, I have no plans yet to shift &lt;tt&gt;Control.IMonad.Trans.Free&lt;/tt&gt; to an external package since I doubt other people will use it any time in the near future.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusion&lt;/h4&gt;&lt;br /&gt;The &lt;tt&gt;transformers-free&lt;/tt&gt; package provides the unifying theoretical abstraction for streaming or interactive programs: the free monad transformer.  Once you learn the abstraction, you will start to see it everywhere, even in non-iteratee libraries.</description><link>http://www.haskellforall.com/2012/07/free-monad-transformers.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>2</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-6093749414184193382</guid><pubDate>Thu, 19 Jul 2012 18:52:00 +0000</pubDate><atom:updated>2012-07-19T11:52:28.784-07:00</atom:updated><title>First-class modules without defaults</title><description>Recently &lt;a href="http://www.reddit.com/r/haskell/comments/wp229/recordwildcards_for_localised_module_imports_what/"&gt;Chris Doner proposed&lt;/a&gt; a first-class module approach which uses the &lt;tt&gt;Default&lt;/tt&gt; type-class and then I &lt;a href="http://www.reddit.com/r/haskell/comments/wpx97/a_simpler_approach_to_firstclass_dictionaries/"&gt;revised his approach&lt;/a&gt; to not use type-classes at all, encoding all the information in dictionaries.  I'm using this post to expand upon my variation of Chris's approach and show how one would translate his approach to my approach and explain what I believe are the advantages of this improvement.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Dictionaries&lt;/h4&gt;&lt;br /&gt;This approach builds off the classic encoding of a &lt;a href="http://www.haskellforall.com/2012/05/scrap-your-type-classes.html"&gt;type-class as a dictionary&lt;/a&gt;.  The trick is simple, first you convert a module to an equivalent type-class representing that module's interface, then you convert that type-class to a dictionary.&lt;br /&gt;&lt;br /&gt;As an example, I'm going to start from Dan Burton's Modular Prelude and rework his &lt;tt&gt;ByteStringModule&lt;/tt&gt; type to use my improvement and then show how they differ.&lt;br /&gt;&lt;br /&gt;Dan's &lt;tt&gt;ByteStringModule&lt;/tt&gt; looks like this: &lt;pre&gt;&lt;br /&gt;data ByteStringModule = S&lt;br /&gt;  { map :: (Word8 -&gt; Word8) -&gt; ByteString -&gt; ByteString&lt;br /&gt;  , concatMap :: (Word8 -&gt; ByteString) -&gt; ByteString -&gt; ByteString&lt;br /&gt;  , filter :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; ByteString&lt;br /&gt;  , length :: ByteString -&gt; Int&lt;br /&gt;  , singleton :: Word8 -&gt; ByteString&lt;br /&gt;  , null :: ByteString -&gt; Bool&lt;br /&gt;  , pack :: [Word8] -&gt; ByteString&lt;br /&gt;  , unpack :: ByteString -&gt; [Word8]&lt;br /&gt;  , empty :: ByteString&lt;br /&gt;  , readFile :: FilePath -&gt; IO ByteString&lt;br /&gt;  , writeFile :: FilePath -&gt; ByteString -&gt; IO ()&lt;br /&gt;  , break :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; (ByteString, ByteString)&lt;br /&gt;  , span :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; (ByteString, ByteString)&lt;br /&gt;  , dropWhile :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; ByteString&lt;br /&gt;  , takeWhile :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; ByteString&lt;br /&gt;  , any :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; Bool&lt;br /&gt;  , all :: (Word8 -&gt; Bool) -&gt; ByteString -&gt; Bool&lt;br /&gt;  , splitAt :: Int -&gt; ByteString -&gt; (ByteString, ByteString)&lt;br /&gt;  }&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;_Data_ByteString_ :: ByteStringModule&lt;br /&gt;_Data_ByteString_ = S&lt;br /&gt;  { null = ...&lt;br /&gt;    ... }&lt;br /&gt;&lt;br /&gt;instance Default ByteStringModule where&lt;br /&gt;  def = _Data_ByteString_&lt;br /&gt;&lt;/pre&gt;To use my approach, you instead parametrize the dictionary on the type of the "string-like" thing: &lt;pre&gt;&lt;br /&gt;data StringModule s = String&lt;br /&gt;  { map :: (Word8 -&gt; Word8) -&gt; s -&gt; s&lt;br /&gt;  , concatMap :: (Word8 -&gt; s) -&gt; s -&gt; s&lt;br /&gt;  , filter :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;  , length :: s -&gt; Int&lt;br /&gt;  , singleton :: Word8 -&gt; s&lt;br /&gt;  , null :: s -&gt; Bool&lt;br /&gt;  , pack :: [Word8] -&gt; s&lt;br /&gt;  , unpack :: s -&gt; [Word8]&lt;br /&gt;  , empty :: s&lt;br /&gt;  , readFile :: FilePath -&gt; IO s&lt;br /&gt;  , writeFile :: FilePath -&gt; s -&gt; IO ()&lt;br /&gt;  , break :: (Word8 -&gt; Bool) -&gt; s -&gt; (s, s)&lt;br /&gt;  , span :: (Word8 -&gt; Bool) -&gt; s -&gt; (s, s)&lt;br /&gt;  , dropWhile :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;  , takeWhile :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;  , any :: (Word8 -&gt; Bool) -&gt; s -&gt; Bool&lt;br /&gt;  , all :: (Word8 -&gt; Bool) -&gt; s -&gt; Bool&lt;br /&gt;  , splitAt :: Int -&gt; s -&gt; (s, s)&lt;br /&gt;  }&lt;br /&gt;&lt;/pre&gt;Using this approach you can encode &lt;tt&gt;String&lt;/tt&gt;, &lt;tt&gt;ByteString&lt;/tt&gt; and &lt;tt&gt;Text&lt;/tt&gt;, all using the same dictionary type: &lt;pre&gt;&lt;br /&gt;import qualified Data.ByteString as S&lt;br /&gt;import qualified Data.ByteString.Lazy as L&lt;br /&gt;import qualified Data.Text as T&lt;br /&gt;import qualified Prelude as P&lt;br /&gt;&lt;br /&gt;lazyByteString :: StringModule L.ByteString&lt;br /&gt;lazyByteString = String {&lt;br /&gt;    null = L.null,&lt;br /&gt;    ... }&lt;br /&gt;&lt;br /&gt;strictByteString :: StringModule S.ByteString&lt;br /&gt;strictByteString = String {&lt;br /&gt;    null = S.null,&lt;br /&gt;    ... }&lt;br /&gt;&lt;br /&gt;text :: StringModule T.Text&lt;br /&gt;text = String {&lt;br /&gt;    null = T.null,&lt;br /&gt;    ... }&lt;br /&gt;&lt;br /&gt;string :: StringModule P.String&lt;br /&gt;string = String {&lt;br /&gt;    null = P.null,&lt;br /&gt;    ... }&lt;br /&gt;&lt;/pre&gt;Here I've parametrized the dictionary on the "string-like" type, so we can reuse the same dictionary type for all of them.  This represents the dictionary equivalent of the following type-class: &lt;pre&gt;&lt;br /&gt;class StringModule s where&lt;br /&gt;    map :: (Word8 -&gt; Word8) -&gt; s -&gt; s&lt;br /&gt;    concatMap :: (Word8 -&gt; s) -&gt; s -&gt; s&lt;br /&gt;    filter :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;    length :: s -&gt; Int&lt;br /&gt;    singleton :: Word8 -&gt; s&lt;br /&gt;    null :: s -&gt; Bool&lt;br /&gt;    pack :: [Word8] -&gt; s&lt;br /&gt;    unpack :: s -&gt; [Word8]&lt;br /&gt;    empty :: s&lt;br /&gt;    readFile :: FilePath -&gt; IO s&lt;br /&gt;    writeFile :: FilePath -&gt; s -&gt; IO ()&lt;br /&gt;    break :: (Word8 -&gt; Bool) -&gt; s -&gt; (s, s)&lt;br /&gt;    span :: (Word8 -&gt; Bool) -&gt; s -&gt; (s, s)&lt;br /&gt;    dropWhile :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;    takeWhile :: (Word8 -&gt; Bool) -&gt; s -&gt; s&lt;br /&gt;    any :: (Word8 -&gt; Bool) -&gt; s -&gt; Bool&lt;br /&gt;    all :: (Word8 -&gt; Bool) -&gt; s -&gt; Bool&lt;br /&gt;    splitAt :: Int -&gt; s -&gt; (s, s)    &lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Comparison&lt;/h4&gt;&lt;br /&gt;This improvement has several advantages over Chris's original approach: &lt;ul&gt;&lt;li&gt; You don't have to define a new data structure for each "instance" of the module. &lt;li&gt; The shared dictionary type guarantees that all "instance"s expose the same signature &lt;li&gt; You can program generically over the &lt;tt&gt;StringModule&lt;/tt&gt; "class" &lt;li&gt; No type-classes are required, so you can define multiple competing "instances" of the same module without conflicts. &lt;li&gt; You can qualify first-class modules instead of completely unpacking them. &lt;/ul&gt;&lt;br /&gt;&lt;h4&gt;Syntax&lt;/h4&gt;&lt;br /&gt;Now I'll show how you syntactically translate all the features of Chris's modules to my improved version.  Let's assume we have some module &lt;tt&gt;Data.String&lt;/tt&gt;, that exports the above four &lt;tt&gt;StringModule&lt;/tt&gt; instances (i.e. &lt;tt&gt;lazyByteString&lt;/tt&gt;, &lt;tt&gt;strictByteString&lt;/tt&gt;, &lt;tt&gt;text&lt;/tt&gt;, and &lt;tt&gt;string&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Using Chris's approach, you distinguish which module you wish to unpack into the current scope by choosing which constructor you unpack into: &lt;pre&gt;&lt;br /&gt;zot :: (L.ByteString, S.ByteString)&lt;br /&gt;zot = (a,b) where&lt;br /&gt;  a = pack [1,2,3] where L{..} = def&lt;br /&gt;  b = pack [1,2,3] where B{..} = def&lt;br /&gt;&lt;/pre&gt;Using the improved version, you distinguish which module you wish to unpack by explicitly selecting which dictionary you unpack: &lt;pre&gt;&lt;br /&gt;zot = (a,b) where&lt;br /&gt;  a = pack [1,2,3] where String{..} = lazyByteString&lt;br /&gt;  b = pack [1,2,3] where String{..} = strictByteString&lt;br /&gt;&lt;/pre&gt;Hmmm, those are long names.  Wouldn't it be nice if we could somehow alias them? &lt;pre&gt;&lt;br /&gt;l = lazyByteString&lt;br /&gt;s = strictByteString&lt;br /&gt;&lt;br /&gt;zot = (a,b) where&lt;br /&gt;  a = pack [1,2,3] where String{..} = l&lt;br /&gt;  b = pack [1,2,3] where String{..} = s&lt;br /&gt;&lt;/pre&gt;Oh yeah!  Dictionaries are &lt;b&gt;first-class&lt;/b&gt; because they are ordinary Haskell values, so renaming them is easy.  We can even locally alias modules, something which the ordinary module system cannot do: &lt;pre&gt;&lt;br /&gt;zot = (a,b) where&lt;br /&gt;  l = lazyByteString&lt;br /&gt;  s = strictByteString&lt;br /&gt;  a = pack [1,2,3] where String{..} = l&lt;br /&gt;  b = pack [1,2,3] where String{..} = s&lt;br /&gt;&lt;/pre&gt;Also, using my improvement we can program generically over the string dictionary type: &lt;pre&gt;&lt;br /&gt;zot :: StringModule s -&gt; (s, s)&lt;br /&gt;zot s = (a,b) where&lt;br /&gt;  String{..} = s&lt;br /&gt;  a = pack [1,2,3]&lt;br /&gt;  b = pack [1,2,3]&lt;br /&gt;&lt;/pre&gt;This is just the dictionary version of a class constraint, where you pass the instance as an ordinary parameter.  This is not possible using Chris's approach, which is one reason I am advocating this change.&lt;br /&gt;&lt;br /&gt;Another advantage of this improvement is that you don't even need to unpack the module at all.  You get qualification for free: &lt;pre&gt;&lt;br /&gt;l = lazyByteString&lt;br /&gt;s = strictByteString&lt;br /&gt;&lt;br /&gt;zot = (a,b) where&lt;br /&gt;  a = pack l [1,2,3]&lt;br /&gt;  b = pack s [1,2,3]&lt;br /&gt;&lt;/pre&gt;In fact, if you alias first-class modules to single-letter names (as you might do with ordinary modules), then the syntactic overhead is identical to using ordinary modules: 2 extra characters, except as a suffix instead of a prefix.&lt;br /&gt;&lt;br /&gt;Using Chris's approach, you would have to use the ordinary module system to qualify which &lt;tt&gt;pack&lt;/tt&gt; you meant: &lt;pre&gt;&lt;br /&gt;zot s = (a, b) where&lt;br /&gt;  a = L.pack def [1,2,3]&lt;br /&gt;  b = S.pack def [1,2,3]&lt;br /&gt;&lt;/pre&gt;So using his approach there is actually more syntactic overhead for qualifying imports, plus you must rely on the ordinary module system to namespace qualified imports.&lt;br /&gt;&lt;br /&gt;Also, using his approach there is no good way to nest a module within a module and still qualify a nested import, since you can't program generically over the outer module.  So there would be no good way to do something like this: &lt;pre&gt;&lt;br /&gt;data OuterModule a = Out { outVal :: a }&lt;br /&gt;data InnerModule a = In  {  inVal :: a }&lt;br /&gt;&lt;br /&gt;dict :: OuterModule (InnerModule String)&lt;br /&gt;dict = Out (In "Hello, world!")&lt;br /&gt;&lt;br /&gt;contrived :: String&lt;br /&gt;contrived = inVal (outVal dict) -- nested qualified import&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Common features&lt;/h4&gt;&lt;br /&gt;No matter which approach you like, there are several cool features that both approaches share.  For example, you can unpack unqualified names into the top-level global namespace.  For Chris's approach you would insert the following top-level declaration: &lt;pre&gt;&lt;br /&gt;L {..} = def&lt;br /&gt;&lt;/pre&gt;... and for my variation you would use: &lt;pre&gt;&lt;br /&gt;String {..} = lazyByteString&lt;br /&gt;&lt;/pre&gt;Also, I will argue (to the death!) that both approaches are superior to type-class-based approaches.  While I believe type-classes are okay for theoretically-grounded constructs (like &lt;tt&gt;Monad&lt;/tt&gt; or &lt;tt&gt;Category&lt;/tt&gt;), I believe that the dictionary approach is superior for banal interfaces like &lt;tt&gt;ListLike&lt;/tt&gt;/&lt;tt&gt;ListModule&lt;/tt&gt; or &lt;tt&gt;StringLike&lt;/tt&gt;/&lt;tt&gt;StringModule&lt;/tt&gt; since it is completely first-class.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;This post is NOT intended to rip on Chris, but simply to improve on his original proposal.  He had the two brilliant ideas of both using "type-classes" as modules and using the &lt;tt&gt;RecordWildCards&lt;/tt&gt; extension to unpack names unqualified.  I think the only mistake he made was unnecessarily filtering everything through the `Default` type-class and I only want to say that I think the pure dictionary approach is a strict improvement on his otherwise already brilliant idea.</description><link>http://www.haskellforall.com/2012/07/first-class-modules-without-defaults.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>12</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-572071035785262951</guid><pubDate>Thu, 19 Jul 2012 05:31:00 +0000</pubDate><atom:updated>2012-07-18T22:31:38.404-07:00</atom:updated><title>Purify code using free monads</title><description>Experienced Haskell programmers commonly advise newcomers to keep as much of their program as pure as possible.  Purity confers many practical advantages: &lt;ul&gt;&lt;li&gt; You can formally prove things about your code &lt;li&gt; Barring that, you can reason easily about your code &lt;li&gt; If all else fails, you can QuickCheck your code &lt;/ul&gt;To demonstrate this, I'll use the following simple &lt;tt&gt;echo&lt;/tt&gt; program: &lt;pre&gt;&lt;br /&gt;import System.Exit&lt;br /&gt;&lt;br /&gt;main = do x &lt;- getLine&lt;br /&gt;          putStrLn x&lt;br /&gt;          exitSuccess&lt;br /&gt;          putStrLn "Finished"&lt;br /&gt;&lt;/pre&gt;The above program only makes one mistake: It mixes business logic with side-effects.  Now, there's nothing wrong with that and I program like that all the time for simple programs that I can fit in my head.  However, I hope to interest you in all the cool things you can do by factoring out the side-effects from the program logic.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Free monads&lt;/h4&gt;&lt;br /&gt;First, we must purify our program, and we can &lt;b&gt;always&lt;/b&gt; factor out impure parts from any code by using &lt;a href="http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html"&gt;free monads&lt;/a&gt;.  Free monads let you decompose any impure program into a pure representation of its behavior and a minimal impure interpreter: &lt;pre&gt;&lt;br /&gt;import Control.Monad.Free&lt;br /&gt;import System.Exit hiding (ExitSuccess)&lt;br /&gt;&lt;br /&gt;data TeletypeF x&lt;br /&gt;  = PutStrLn String x&lt;br /&gt;  | GetLine (String -&gt; x)&lt;br /&gt;  | ExitSuccess&lt;br /&gt;&lt;br /&gt;instance Functor TeletypeF where&lt;br /&gt;    fmap f (PutStrLn str x) = PutStrLn str (f x)&lt;br /&gt;    fmap f (GetLine      k) = GetLine (f . k)&lt;br /&gt;    fmap f  ExitSuccess     = ExitSuccess&lt;br /&gt;&lt;br /&gt;type Teletype = Free TeletypeF&lt;br /&gt;&lt;br /&gt;putStrLn' :: String -&gt; Teletype ()&lt;br /&gt;putStrLn' str = liftF $ PutStrLn str ()&lt;br /&gt;&lt;br /&gt;getLine' :: Teletype String&lt;br /&gt;getLine' = liftF $ GetLine id&lt;br /&gt;&lt;br /&gt;exitSuccess' :: Teletype r&lt;br /&gt;exitSuccess' = liftF ExitSuccess&lt;br /&gt;&lt;br /&gt;run :: Teletype r -&gt; IO r&lt;br /&gt;run (Pure r) = return r&lt;br /&gt;run (Free (PutStrLn str t)) = putStrLn str &gt;&gt;  run t&lt;br /&gt;run (Free (GetLine  f    )) = getLine      &gt;&gt;= run . f&lt;br /&gt;run (Free  ExitSuccess    ) = exitSuccess&lt;br /&gt;&lt;br /&gt;echo :: Teletype ()&lt;br /&gt;echo = do str &lt;- getLine'&lt;br /&gt;          putStrLn' str&lt;br /&gt;          exitSuccess'&lt;br /&gt;          putStrLn' "Finished"&lt;br /&gt;&lt;br /&gt;main = run echo&lt;br /&gt;&lt;/pre&gt;The above rewrite concentrates &lt;b&gt;all&lt;/b&gt; of the impure code within the &lt;tt&gt;run&lt;/tt&gt; function.  I like to call this process "purifying the code" because we distill out all of the program's logic into pure code leaving behind only the bare minimum impure residue in our &lt;tt&gt;run&lt;/tt&gt; interpreter.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Proofs&lt;/h4&gt;&lt;br /&gt;Now, it seems like we didn't gain much from purifying our code and we paid a price in code size.  However, now we can prove things about our code using equational reasoning.&lt;br /&gt;&lt;br /&gt;For example, everybody reading this probably noticed the obvious bug in the original &lt;tt&gt;echo&lt;/tt&gt; program: &lt;pre&gt;&lt;br /&gt;import System.Exit&lt;br /&gt;&lt;br /&gt;main = do x &lt;- getLine&lt;br /&gt;          putStrLn x&lt;br /&gt;          exitSuccess&lt;br /&gt;          putStrLn "Finished" &lt;-- oops!&lt;br /&gt;&lt;/pre&gt;The last command never executes ... or does it?  How would we prove that?&lt;br /&gt;&lt;br /&gt;Actually, we can't prove that because it's &lt;b&gt;not true&lt;/b&gt;.  The author of the &lt;tt&gt;System.Exit&lt;/tt&gt; module could simply change the definition of &lt;tt&gt;exitSuccess&lt;/tt&gt; to: &lt;pre&gt;&lt;br /&gt;exitSuccess :: IO ()&lt;br /&gt;exitSuccess = return ()&lt;br /&gt;&lt;/pre&gt;The above program would still type-check, but now it would also successfully print &lt;tt&gt;Finished&lt;/tt&gt; to the console.&lt;br /&gt;&lt;br /&gt;However, for our purified version, we &lt;b&gt;can&lt;/b&gt; prove that any command after &lt;tt&gt;exitSuccess'&lt;/tt&gt; never executes: &lt;pre&gt;&lt;br /&gt;exitSuccess' &gt;&gt; m = exitSuccess'&lt;br /&gt;&lt;/pre&gt;We do so using "equational reasoning", which is the most important benefit of purity.  "Equational reasoning" means that we can take any expression and just substitute in the function definitions of the components.  Each step of the following proof uses a comment to indicate the specific function definition used to reach the next step: &lt;pre&gt;&lt;br /&gt;exitSuccess' &gt;&gt; m&lt;br /&gt;&lt;br /&gt;-- exitSuccess' = liftF ExitSuccess&lt;br /&gt;= liftF ExitSuccess &gt;&gt; m&lt;br /&gt;&lt;br /&gt;-- m &gt;&gt; m' = m &gt;&gt;= \_ -&gt; m'&lt;br /&gt;= liftF ExitSuccess &gt;&gt;= \_ -&gt; m&lt;br /&gt;&lt;br /&gt;-- liftF f = Free (fmap Pure f)&lt;br /&gt;= Free (fmap Pure ExitSuccess) &gt;&gt;= \_ -&gt; m&lt;br /&gt;&lt;br /&gt;-- fmap f ExitSuccess = ExitSuccess&lt;br /&gt;= Free ExitSuccess &gt;&gt;= \_ -&gt; m&lt;br /&gt;&lt;br /&gt;-- Free m &gt;&gt;= f = Free (fmap (&gt;&gt;= f) m)&lt;br /&gt;= Free (fmap (&gt;&gt;= \_ -&gt; m) ExitSuccess)&lt;br /&gt;&lt;br /&gt;-- fmap f ExitSuccess = ExitSuccess&lt;br /&gt;= Free ExitSuccess&lt;br /&gt;&lt;br /&gt;-- fmap f ExitSuccess = ExitSuccess&lt;br /&gt;= Free (fmap Pure ExitSuccess)&lt;br /&gt;&lt;br /&gt;-- liftF f = Free (fmap Pure f)&lt;br /&gt;= liftF ExitSuccess&lt;br /&gt;&lt;br /&gt;-- exitSuccess' = liftF ExitSuccess&lt;br /&gt;= exitSuccess'&lt;br /&gt;&lt;/pre&gt;Notice how in the last steps we reversed the equality and worked backwards from the function definition to the defined expression.  This is perfectly legitimate because thanks to purity the equals sign in Haskell doesn't mean assignment: it actually means equality!  This means we can translate both ways across an equals sign when equationally reasoning about code.  That's pretty amazing!&lt;br /&gt;&lt;br /&gt;Equally important, the above proof is true no matter how the free monad is interpreted.  We could swap out the &lt;tt&gt;run&lt;/tt&gt; function for any other interpreter, including a pure interpreter, and the equation still holds: &lt;pre&gt;&lt;br /&gt;exitSuccess' &gt;&gt; m = exitSuccess'&lt;br /&gt;&lt;/pre&gt;This means that we could safely use this as a GHC rewrite rule for an optimization pass over our program: &lt;pre&gt;&lt;br /&gt;{-# RULES&lt;br /&gt;  "exit" forall m. exitSuccess' &gt;&gt; m = exitSuccess'&lt;br /&gt;    #-}&lt;br /&gt;&lt;/pre&gt;...and we can guarantee that the rule is always safe to apply and will never be broken.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Reasoning&lt;/h4&gt;&lt;br /&gt;We'd like to prove that our program always outputs the same string it received as input.  Unfortunately, we can't prove this because it's &lt;b&gt;not true&lt;/b&gt;.  The maintainer of the &lt;tt&gt;putStrLn&lt;/tt&gt; function could always have a change of heart and redefine it to: &lt;pre&gt;&lt;br /&gt;putStrLn str = return () -- worst maintainer, ever&lt;br /&gt;&lt;/pre&gt;In fact, we can't even prove this is true for our free monad version, either.  &lt;tt&gt;run&lt;/tt&gt; uses the same &lt;tt&gt;putStrLn&lt;/tt&gt;, so it would suffer from the same bug.  However, we can still prove things about the free monad itself by instead studying it through a pure interpreter: &lt;pre&gt;&lt;br /&gt;runPure :: Teletype r -&gt; [String] -&gt; [String]&lt;br /&gt;runPure (Pure r)                  xs  = []&lt;br /&gt;runPure (Free (PutStrLn y  t))    xs  = y:runPure t xs&lt;br /&gt;runPure (Free (GetLine     k))    []  = []&lt;br /&gt;runPure (Free (GetLine     k)) (x:xs) = runPure (k x) xs&lt;br /&gt;runPure (Free  ExitSuccess   )    xs  = []&lt;br /&gt;&lt;/pre&gt;Now, we can prove that: &lt;pre&gt;&lt;br /&gt;runPure echo = take 1&lt;br /&gt;&lt;/pre&gt;... based off of the &lt;a href="http://www.haskell.org/onlinereport/standard-prelude.html"&gt;Haskell98 Prelude&lt;/a&gt;'s &lt;tt&gt;take&lt;/tt&gt;.  I leave this one as an exercise for the reader, because this post is already pretty long.&lt;br /&gt;&lt;br /&gt;Notice that by examining &lt;tt&gt;echo&lt;/tt&gt; through a pure lens, we caught a small corner case we didn't originally anticipate: The user might not enter any input!  In that scenario our interpreter must return an empty list, just like &lt;tt&gt;take&lt;/tt&gt;.  Equational reasoning forces us to be rigorous in a way that simply saying "our program always outputs the same string it received" can never be.  The more you work through these kinds of equations, the more you improve your ability to reason about your own code and catch mistakes in your own assumptions.&lt;br /&gt;&lt;br /&gt;Equally important, equational transformations let you view your program in a whole new light.  We saw our program was a glorified &lt;tt&gt;take 1&lt;/tt&gt; when filtered through &lt;tt&gt;runPure&lt;/tt&gt;, meaning we could leverage our intuition about &lt;tt&gt;take&lt;/tt&gt; for understanding our program and catching that corner case.&lt;br /&gt;&lt;br /&gt;Once you factor your code through the &lt;tt&gt;Free&lt;/tt&gt; monad and prove its soundness it acts like a trusted kernel and then you need only maintain the interpreter from that point forward.  So while we couldn't quite prove the entire program was correct, we were able to prove that everything except the interpreter is correct.  Equally important, we reduced the interpreter to the absolute minimal attack surface possible so that we can fit it in our head and maintain it by hand.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Testing&lt;/h4&gt;&lt;br /&gt;We can't prove anything about code in the &lt;tt&gt;IO&lt;/tt&gt; monad.  How would we even do that?  We could say something like: "If you compile this and run the program and type some string into the prompt, you will get the same string back", but that's not really an equation, so there's nothing rigorous about it.  However, we could write it as a test for our program.&lt;br /&gt;&lt;br /&gt;Unfortunately, tests for impure code don't really scale to large and complicated programs and in test-dependent programming languages writing these tests consumes a significant fraction of the programmer's time.&lt;br /&gt;&lt;br /&gt;Fortunately, though, we can easily exercise pure code with the &lt;tt&gt;QuickCheck&lt;/tt&gt; library, which pathologically scours pure assertions for a violation in a completely automated fashion.&lt;br /&gt;&lt;br /&gt;For example, let's assume that you were too lazy to prove that &lt;tt&gt;runPure echo = take 1&lt;/tt&gt;.  We can instead ask &lt;tt&gt;QuickCheck&lt;/tt&gt; to test that proposition for us: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; import Test.QuickCheck&lt;br /&gt;&gt;&gt;&gt; quickCheck (\xs -&gt; runPure echo xs == take 1 xs)&lt;br /&gt;+++ OK, passed 100 tests.&lt;br /&gt;&lt;/pre&gt;How cool is that!  You can test your code much more aggressively if you keep it as pure as possible.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;Equational reasoning only works for pure code, so the pure component of your code base serves as a trusted kernel for which you can: &lt;ul&gt;&lt;li&gt; prove soundness, &lt;li&gt; reason about behavior, and &lt;li&gt; aggressively test. &lt;/ul&gt;This is why we always strive to maximize the pure portions of our code bases and minimize the impure parts.&lt;br /&gt;&lt;br /&gt;Fortunately, the &lt;tt&gt;Free&lt;/tt&gt; monad guarantees that you can always easily achieve the absolute maximal level of purity possible and the absolute minimal amount of impure code.  This is why every experienced Haskell programmer should be fluent in free monads.&lt;br /&gt;</description><link>http://www.haskellforall.com/2012/07/purify-code-using-free-monads.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>4</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5755130484879134648</guid><pubDate>Thu, 12 Jul 2012 04:59:00 +0000</pubDate><atom:updated>2012-07-11T21:59:30.987-07:00</atom:updated><title>Breaking from a loop</title><description>This post describes how to break from a code block by using &lt;tt&gt;EitherT&lt;/tt&gt;/&lt;tt&gt;MaybeT&lt;/tt&gt; instead of &lt;tt&gt;ContT&lt;/tt&gt;.  This technique isn't new, and has already been described at least once before &lt;a href="http://www.haskell.org/haskellwiki/Monad_Transformers_Tutorial"&gt;here&lt;/a&gt;.  However, there is still some weird culture of teaching &lt;tt&gt;ContT&lt;/tt&gt; for exiting from loops, which is incredibly over-kill and bad practice because it makes beginners think it's complicated when it's not.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Trick&lt;/h4&gt;&lt;br /&gt;Exiting from a code block is ridiculously simple: &lt;pre&gt;&lt;br /&gt;import Control.Error -- from the 'errors' package&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;&lt;br /&gt;exit = left -- or rename 'exit' to 'break' if you prefer&lt;br /&gt;&lt;br /&gt;main = runEitherT $ forever $ do&lt;br /&gt;    str &lt;- lift getLine&lt;br /&gt;    when (str == "exit") $ exit ()&lt;br /&gt;&lt;/pre&gt;I find this significantly easier to understand than the equivalent &lt;tt&gt;ContT&lt;/tt&gt; version.  Normally when you use &lt;tt&gt;Either&lt;/tt&gt;/&lt;tt&gt;EitherT&lt;/tt&gt;, you terminate on the first &lt;tt&gt;Left&lt;/tt&gt; you encounter.  All that &lt;tt&gt;exit&lt;/tt&gt; does is return its argument wrapped in a &lt;tt&gt;Left&lt;/tt&gt;, halting the surrounding &lt;tt&gt;EitherT&lt;/tt&gt; block.&lt;br /&gt;&lt;br /&gt;You can even use the value returned from the block, which will be a &lt;tt&gt;Left&lt;/tt&gt; if the block exited with a &lt;tt&gt;exit&lt;/tt&gt; statement, or a &lt;tt&gt;Right&lt;/tt&gt; if the block terminated normally: &lt;pre&gt;&lt;br /&gt;main = do&lt;br /&gt;    e &lt;- runEitherT $ forever $ do&lt;br /&gt;        str &lt;- lift getLine&lt;br /&gt;        when (str == "exit") $ exit ()&lt;br /&gt;    case e of&lt;br /&gt;        Left  a -&gt; ... -- Loop terminated with an 'exit'&lt;br /&gt;        Right b -&gt; ... -- Loop terminated normally&lt;br /&gt;&lt;/pre&gt;This approach is incredibly simple and lets you distinguish how the loop terminates.  If you don't care about distinguishing the two code paths and they return the same result type, then just use: &lt;pre&gt;&lt;br /&gt;main = do&lt;br /&gt;    r &lt;- fmap (either id id) $ runEitherT $ ...&lt;br /&gt;    ...&lt;br /&gt;&lt;/pre&gt;... which also works if the loop is non-terminating.&lt;br /&gt;&lt;br /&gt;If you want to &lt;tt&gt;exit&lt;/tt&gt; without returning any value, just use &lt;tt&gt;MaybeT&lt;/tt&gt; instead: &lt;pre&gt;&lt;br /&gt;exit = mzero&lt;br /&gt;&lt;br /&gt;main = runMaybeT $ forever $ do&lt;br /&gt;    str &lt;- getLine&lt;br /&gt;    when (str == "exit") exit&lt;br /&gt;&lt;/pre&gt;Or you could stick with &lt;tt&gt;EitherT&lt;/tt&gt; and just use &lt;tt&gt;exit ()&lt;/tt&gt;, as the first example did, since &lt;tt&gt;Either () r&lt;/tt&gt; is isomorphic to &lt;tt&gt;Maybe r&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;EitherT vs. ErrorT&lt;/h4&gt;&lt;br /&gt;You might wonder why people historically teach &lt;tt&gt;ContT&lt;/tt&gt; instead of &lt;tt&gt;EitherT&lt;/tt&gt; for exiting from loops.  I can only guess that they did this because of the terrible &lt;tt&gt;EitherT&lt;/tt&gt; implementation in the &lt;tt&gt;transformers&lt;/tt&gt; package that goes by the name &lt;tt&gt;ErrorT&lt;/tt&gt;.  The &lt;tt&gt;ErrorT&lt;/tt&gt; implementation makes two major mistakes: &lt;ul&gt;&lt;li&gt; It constrains the &lt;tt&gt;Left&lt;/tt&gt; value with the &lt;tt&gt;Error&lt;/tt&gt; class. &lt;li&gt; The name mistakenly misleads users to believe that the &lt;tt&gt;Left&lt;/tt&gt; value is only useful for returning errors. &lt;/ul&gt;The first mistake prevents you from exiting with any old value unless you first make it an instance of the &lt;tt&gt;Error&lt;/tt&gt; class.  The second mistake insidiously misleads new Haskell programmers to miss the opportunity to exit from &lt;tt&gt;EitherT&lt;/tt&gt; blocks using ordinary non-exceptional values and then they get led astray by people peddling &lt;tt&gt;ContT&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The above examples worked because they didn't use &lt;tt&gt;ErrorT&lt;/tt&gt; at all and instead used the superior implementation in the &lt;tt&gt;either&lt;/tt&gt; package which doesn't constrain the behavior of the &lt;tt&gt;Left&lt;/tt&gt; value, either practically or semantically.  This is why you should always give data types neutral names to encourage people to use them in ways you didn't anticipate.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Nested blocks&lt;/h4&gt;&lt;br /&gt;You might think you need &lt;tt&gt;ContT&lt;/tt&gt; if you want to do anything more complicated such as multiple levels of nesting and exiting.  However, if you thought so you'd be wrong!  Nesting multiple &lt;tt&gt;EitherT&lt;/tt&gt; blocks works perfectly fine: &lt;pre&gt;&lt;br /&gt;-- I'm too lazy to add type signatures for this&lt;br /&gt;{-# LANGUAGE NoMonomorphismRestriction #-}&lt;br /&gt;&lt;br /&gt;import Control.Error&lt;br /&gt;import Control.Monad&lt;br /&gt;import Control.Monad.Trans&lt;br /&gt;&lt;br /&gt;exit = left&lt;br /&gt;&lt;br /&gt;main =&lt;br /&gt;    runEitherT $ forM_ [1..3] $ \i -&gt;&lt;br /&gt;        runEitherT $ forM_ [4..6] $ \j -&gt; do&lt;br /&gt;            when (j == 6) $ liftInner $ exit ()&lt;br /&gt;            liftIO $ print (i, j)&lt;br /&gt;  where liftInner = id&lt;br /&gt;        liftOuter = lift&lt;br /&gt;        liftIO    = lift . lift&lt;br /&gt;&lt;/pre&gt;Let's check it out: &lt;pre&gt;&lt;br /&gt;$ ./break&lt;br /&gt;(1,4)&lt;br /&gt;(1,5)&lt;br /&gt;(2,4)&lt;br /&gt;(2,5)&lt;br /&gt;(3,4)&lt;br /&gt;(3,5)&lt;br /&gt;&lt;/pre&gt;I can choose to break out of &lt;b&gt;two&lt;/b&gt; nested levels by replacing &lt;tt&gt;liftInner&lt;/tt&gt; with &lt;tt&gt;liftOuter&lt;/tt&gt;, which just &lt;tt&gt;lift&lt;/tt&gt;s the &lt;tt&gt;exit&lt;/tt&gt; call to the surrounding &lt;tt&gt;EitherT&lt;/tt&gt; block: &lt;pre&gt;&lt;br /&gt;            ...&lt;br /&gt;            when (j == 6) $ liftOuter $ exit ()&lt;br /&gt;            ...&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;$ ./break&lt;br /&gt;(1, 4)&lt;br /&gt;(1, 5)&lt;br /&gt;&lt;/pre&gt;Nice!  Mainstream languages require extended syntax to let you break out of multiple nested loops.  Haskell does it using ordinary functions.  I really can't convey how amazing that is without being entirely unprofessional.</description><link>http://www.haskellforall.com/2012/07/breaking-from-loop.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>3</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-5611564277991379745</guid><pubDate>Sun, 08 Jul 2012 13:14:00 +0000</pubDate><atom:updated>2012-12-07T09:30:59.142-08:00</atom:updated><title>errors-1.0: Simplified error handling</title><description>&lt;h4&gt;Update&lt;/h4&gt;&lt;br /&gt;I just released a quick patch changing a dependency from the &lt;tt&gt;EitherT&lt;/tt&gt; package to the &lt;tt&gt;Either&lt;/tt&gt; package.  What this means is that if you already installed version 1.0 and upgrade to 1.1, you will have two packages exporting conflicting modules for &lt;tt&gt;Control.Monad.Trans.Either&lt;/tt&gt;.  The fix is very simple.  Just type: &lt;pre&gt;&lt;br /&gt;ghc-pkg hide EitherT&lt;br /&gt;&lt;/pre&gt;Which will hide the &lt;tt&gt;EitherT&lt;/tt&gt; package so it does not conflict.&lt;br /&gt;&lt;br /&gt;I tried to make this fix as rapidly as possible to mitigate the damage.  I apologize, but somebody notified me that &lt;tt&gt;either&lt;/tt&gt; is a higher quality dependency for the &lt;tt&gt;EitherT&lt;/tt&gt; type.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Introduction&lt;/h4&gt;&lt;br /&gt;This post marks the release of &lt;tt&gt;errors-1.0&lt;/tt&gt;, a package designed to fill all the gaps in type-safe error handling.  I target this package specifically towards Haskell programmers that prefer to use &lt;tt&gt;Maybe&lt;/tt&gt; and &lt;tt&gt;Either&lt;/tt&gt; for type-safe exception handling, yet get frustrated by thousands of paper-cuts every time some convenient function is missing.&lt;br /&gt;&lt;br /&gt;Now, all those pain points are gone, and instead of an import list that looks something like this: &lt;pre&gt;&lt;br /&gt;import Control.Monad.Trans.Either&lt;br /&gt;import Data.Maybe&lt;br /&gt;import Safe&lt;br /&gt;...&lt;br /&gt;&lt;/pre&gt;You now can just import: &lt;pre&gt;&lt;br /&gt;import Control.Error&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Utility Functions&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;Control.Error&lt;/tt&gt; re-exports &lt;tt&gt;Control.Error.Util&lt;/tt&gt;, which provides some very useful utility functions: &lt;pre&gt;&lt;br /&gt;hush       :: Either a b -&gt; Maybe b&lt;br /&gt;note       :: a -&gt; Maybe b -&gt; Either a b&lt;br /&gt;hushT      :: Monad m =&gt; EitherT a m b -&gt; MaybeT m b&lt;br /&gt;noteT      :: Monad m =&gt; a -&gt; MaybeT m b -&gt; EitherT a m b&lt;br /&gt;&lt;br /&gt;liftMaybe  :: Monad m =&gt; Maybe b    -&gt; MaybeT m b&lt;br /&gt;liftEither :: Monad m =&gt; Either a b -&gt; EitherT a m b&lt;br /&gt;&lt;/pre&gt;I'm pretty sure every experienced Haskell programmer has desired either the &lt;tt&gt;hush&lt;/tt&gt; or &lt;tt&gt;note&lt;/tt&gt; functions at some point and ended up either in-lining it into their code or defining it in some sort of &lt;tt&gt;Util&lt;/tt&gt; module of their project.&lt;br /&gt;&lt;br /&gt;It's quite frustrating, actually.  We frequently encounter code that uses a mixture of &lt;tt&gt;Maybe&lt;/tt&gt; or &lt;tt&gt;Either&lt;/tt&gt; and want to combine them both within the same monad, but when we search using &lt;a href="http://www.haskell.org/hoogle/"&gt;Hoogle&lt;/a&gt; or &lt;a href="http://holumbus.fh-wedel.de/hayoo/hayoo.html"&gt;Hayoo&lt;/a&gt; for a function like &lt;tt&gt;hush&lt;/tt&gt;, we get just one result: &lt;pre&gt;&lt;br /&gt;Precis.Utils.ControlOperators.suppress :: Either e a -&gt; Maybe a&lt;br /&gt;&lt;/pre&gt;This exemplifies one such utility function that the &lt;tt&gt;precis&lt;/tt&gt; package wrote to scratch its own itch.  Who would want to make the &lt;tt&gt;precis&lt;/tt&gt; package a dependency for such a trivial function, especially when the &lt;tt&gt;precis&lt;/tt&gt; package has nothing to do with error-handling?&lt;br /&gt;&lt;br /&gt;I also couldn't even find an equivalent to the &lt;tt&gt;note&lt;/tt&gt; function, although perhaps that's just because my Hoogle-fu isn't strong enough.  However, I find it surprising that such a useful conversion function does not reside in some standard location on Hackage.  Well, now it officially resides in the &lt;tt&gt;errors&lt;/tt&gt; package.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Teaching&lt;/h4&gt;&lt;br /&gt;Also, most Haskell aficionados know that &lt;tt&gt;liftMaybe&lt;/tt&gt; and &lt;tt&gt;liftEither&lt;/tt&gt; are easy to write: &lt;pre&gt;&lt;br /&gt;liftMaybe  = MaybeT  . return&lt;br /&gt;liftEither = EitherT . return&lt;br /&gt;&lt;/pre&gt;However, many beginners to Haskell don't know how to lift a &lt;tt&gt;Maybe&lt;/tt&gt; to a &lt;tt&gt;MaybeT&lt;/tt&gt; and would benefit from the above function.  Imagine a beginner Hoogling for: &lt;pre&gt;&lt;br /&gt;(Monad m) =&gt; Maybe a -&gt; MaybeT m a&lt;br /&gt;&lt;/pre&gt;... and instead of getting a bunch of almost-correct matches, they get an exact match &lt;b&gt;and&lt;/b&gt; they can click the link to the &lt;tt&gt;liftMaybe&lt;/tt&gt; function, consult the source code and have an "AHA!" moment where they learn a bit more about how monad transformers work.  I'll wager there are many Haskell beginners right now that give up on using &lt;tt&gt;Maybe&lt;/tt&gt;s within &lt;tt&gt;MaybeT&lt;/tt&gt; because they don't even know it's possible to do so.  Well, now they do.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Social Confirmation&lt;/h4&gt;&lt;br /&gt;I designed the &lt;tt&gt;errors&lt;/tt&gt; library to encourage type-safe error-handling style in Haskell, showing beginners that they can use the type system to handle errors &lt;b&gt;painlessly&lt;/b&gt;, without using out-of-band language features like &lt;tt&gt;Control.Exception&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;While I have nothing against &lt;tt&gt;Control.Exception&lt;/tt&gt;, I'm worried that the proliferation of libraries revolving around it along with the absence of high-quality and instructive &lt;tt&gt;Either&lt;/tt&gt;/&lt;tt&gt;EitherT&lt;/tt&gt; libraries might lead beginners to believe that Haskell does not have a type-safe, simple, and easy way to handle errors.  They might even lose interest in the language because they mistakenly feel it does not live up to their expectations of elegance and simplicity.  After all, how can functional programming be so great if it can't do something as simple as error handling elegantly?&lt;br /&gt;&lt;br /&gt;A &lt;a href="http://www.reddit.com/r/haskell/comments/w5ynx/what_do_you_guys_think_of_my_approach_at/"&gt;recent post on reddit&lt;/a&gt; emphasizes that we shouldn't take for granted that beginners even know how to integrate high quality &lt;tt&gt;Maybe&lt;/tt&gt;/&lt;tt&gt;Either&lt;/tt&gt; code in complicated applications.  All the expert knowledge of how to seamlessly inter-convert the various error-handling styles types gets locked away in people's pet utility libraries.  This package solves that problem by providing easily accessible source code that beginner's can use and learn from.&lt;br /&gt;&lt;br /&gt;More importantly, I designed the library to encourage beginners to use the type-safe error-handling style by providing a sort of social confirmation that is lacking on Hackage.  The lack of a type-safe error handling ecosystem acts like a social cue to beginners that perhaps they are going down the wrong path and should reconsider.  After all, if &lt;tt&gt;Either&lt;/tt&gt; is supposedly the right way to handle errors, why does it seem like nobody cares about it enough to create a proper package covering common use cases?  Well, now they know at least one person cares.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Scripting&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;Control.Error&lt;/tt&gt; also exports &lt;tt&gt;Control.Error.Script&lt;/tt&gt;, which covers the common use case of simple scripting: &lt;pre&gt;&lt;br /&gt;type Script a = EitherT String IO a&lt;br /&gt;&lt;/pre&gt;The entire module provides a way to convert between &lt;tt&gt;Control.Exception&lt;/tt&gt; and &lt;tt&gt;EitherT&lt;/tt&gt;, so that people who prefer to not use &lt;tt&gt;Control.Exception&lt;/tt&gt; now have a standard way to interface it with &lt;tt&gt;EitherT&lt;/tt&gt;-style code.  The most important function in the module is: &lt;pre&gt;&lt;br /&gt;{- NOTE: This has been renamed to "scriptIO" and "tryIO" now resides in&lt;br /&gt;         Control.Error.Util and only catches IO exceptions -}&lt;br /&gt;tryIO :: IO a -&gt; Script a&lt;br /&gt;&lt;/pre&gt;... which is like &lt;tt&gt;lift&lt;/tt&gt; except that it also catches exceptions and translates them into &lt;tt&gt;Left&lt;/tt&gt;s.  It also provides convenience functions to bind &lt;tt&gt;Maybe&lt;/tt&gt;s and &lt;tt&gt;Either&lt;/tt&gt;s within the monad: &lt;pre&gt;&lt;br /&gt;tryMaybe :: String -&gt; Maybe a -&gt; Script a&lt;br /&gt;tryEither :: Either String r -&gt; Script r&lt;br /&gt;&lt;/pre&gt;These seem a little bit cumbersome to use at first, since you'd have to take all your favorite partial functions and convert them to &lt;tt&gt;Maybe&lt;/tt&gt; or &lt;tt&gt;Either&lt;/tt&gt; first and then pass them to &lt;tt&gt;tryMaybe&lt;/tt&gt;/&lt;tt&gt;tryEither&lt;/tt&gt; ... or do you?&lt;br /&gt;&lt;br /&gt;Fortunately for you, this library has "batteries included", and &lt;tt&gt;Control.Error&lt;/tt&gt; also exports the &lt;tt&gt;Control.Error.Safe&lt;/tt&gt; module which wraps all your favorite partial functions both in the &lt;tt&gt;Either&lt;/tt&gt; and &lt;tt&gt;EitherT&lt;/tt&gt; monad.&lt;br /&gt;&lt;br /&gt;The &lt;tt&gt;Either&lt;/tt&gt; variants close a gaping hole in the &lt;tt&gt;safe&lt;/tt&gt; library, where the only way you could attach a descriptive error message was using exceptions (again, this is the kind of social cue I'm talking about).  Also, the &lt;tt&gt;EitherT&lt;/tt&gt; variants are incredibly useful within the &lt;tt&gt;Script&lt;/tt&gt; monad, where you can now seamlessly bind all your favorite error-handling functions of all types in the same monad: &lt;pre&gt;&lt;br /&gt;import Control.Error&lt;br /&gt;import System.Environment&lt;br /&gt;&lt;br /&gt;main = runScript $ do&lt;br /&gt;    as &lt;- tryIO getArgs&lt;br /&gt;    (file, n) &lt;- case as of&lt;br /&gt;        [file, n'] -&gt; do&lt;br /&gt;            n &lt;- tryRead "Could not parse LINENUM" n'&lt;br /&gt;            return (file, n)&lt;br /&gt;        _ -&gt; throwT "Usage: MYPROGRAM FILE LINENUM"&lt;br /&gt;    str &lt;- tryIO $ readFile file&lt;br /&gt;    line &lt;- tryAt "Line not found" (lines str) n&lt;br /&gt;    tryIO $ putStrLn line&lt;br /&gt;&lt;/pre&gt;Notice the pattern?  Everything that can be bound in the &lt;tt&gt;Script&lt;/tt&gt; monad begins with the prefix &lt;tt&gt;try&lt;/tt&gt;.  A future release of the library will also provide versions with the default error messages (i.e. "Prelude.read: no parse"), but I just haven't decided what to name those versions, yet.&lt;br /&gt;&lt;br /&gt;Also, notice that you don't have to import &lt;tt&gt;Control.Monad.Trans&lt;/tt&gt; since for the special case of the &lt;tt&gt;Script&lt;/tt&gt; monad the &lt;tt&gt;tryIO&lt;/tt&gt; function serves the role of &lt;tt&gt;lift&lt;/tt&gt;.  The compiler error for the lack of &lt;tt&gt;Control.Monad.Trans&lt;/tt&gt; is a nice reminder that you used &lt;tt&gt;lift&lt;/tt&gt; instead of &lt;tt&gt;tryIO&lt;/tt&gt; by mistake.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Why not ErrorT?&lt;/h4&gt;&lt;br /&gt;I'm a huge fan of the &lt;tt&gt;transformers&lt;/tt&gt; package, with one major exception: &lt;tt&gt;ErrorT&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;The first reason is that &lt;tt&gt;ErrorT&lt;/tt&gt; comes with the additional baggage of the &lt;tt&gt;Error&lt;/tt&gt; class, which really has no place in a proper &lt;tt&gt;EitherT&lt;/tt&gt; implementation.  I don't know how many times I've tried using that type, got hit by the &lt;tt&gt;Error&lt;/tt&gt; class constraint, and threw up my hands in disgust and went back to &lt;tt&gt;EitherT&lt;/tt&gt; (provided by the appropriately-named &lt;tt&gt;EitherT&lt;/tt&gt; package and re-exported by &lt;tt&gt;Control.Error&lt;/tt&gt;).&lt;br /&gt;&lt;br /&gt;However, there is a deeper reason that I'm basing my library on &lt;tt&gt;EitherT&lt;/tt&gt; and not &lt;tt&gt;ErrorT&lt;/tt&gt;, which is the implementation of &lt;tt&gt;catchError&lt;/tt&gt; and &lt;tt&gt;throwError&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;For the longest time, I never appreciated that &lt;tt&gt;throw&lt;/tt&gt; and &lt;tt&gt;catch&lt;/tt&gt; in any &lt;tt&gt;Either&lt;/tt&gt;-like block are actually &lt;tt&gt;return&lt;/tt&gt; and &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt; in the dual &lt;tt&gt;Either&lt;/tt&gt; monad (the one with the type variables swapped).  I missed this because the types of &lt;tt&gt;catchError&lt;/tt&gt; and &lt;tt&gt;throwError&lt;/tt&gt; I would see in every library were never made fully polymorphic: &lt;pre&gt;&lt;br /&gt;-- The non-monad-transformer versions, for simplicity&lt;br /&gt;throwError :: e -&gt; Either e r&lt;br /&gt;catchError :: Either e r -&gt; (e -&gt; Either e r) -&gt; Either e r&lt;br /&gt;&lt;/pre&gt;If I generalized the two above function signatures to be fully polymorphic, you'd have something that looks remarkably like the signatures for &lt;tt&gt;return&lt;/tt&gt; and &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;throwE/return :: a -&gt; Either a r&lt;br /&gt;catchE/(&gt;&gt;=)  :: Either a r -&gt; (a -&gt; Either b r) -&gt; Either b r&lt;br /&gt;&lt;/pre&gt;In fact, if you just used a newtype to swap the type variables, you'd have something that works exactly like a monad: &lt;pre&gt;&lt;br /&gt;newtype EitherR r e = EitherR { runEitherR :: Either e r }&lt;br /&gt;&lt;br /&gt;return :: a -&gt; EitherR r a&lt;br /&gt;return :: a -&gt;         m a&lt;br /&gt;return = throwE -- except with newtypes&lt;br /&gt;&lt;br /&gt;(&gt;&gt;=)  :: EitherR r a -&gt; (a -&gt; EitherR r b) -&gt; EitherR r b&lt;br /&gt;(&gt;&gt;=)  ::         m a -&gt; (a -&gt;         m b) -&gt;         m b&lt;br /&gt;(&gt;&gt;=) = catchE -- except with newtypes&lt;br /&gt;&lt;/pre&gt;So now we have the ability to not only throw and catch exceptional values, but to even change the &lt;b&gt;type&lt;/b&gt; of the exceptional value.  I like to call this the "success" monad (after &lt;tt&gt;ehird&lt;/tt&gt;'s term for it, since he was the one who pointed out this awesome symmetry to me).  In this monad, each statement is an exception handler and the monad terminates when you "throw" a successful result: &lt;pre&gt;&lt;br /&gt;runEitherRT $ do&lt;br /&gt;    e2 &lt;- ioExceptionHandler e1&lt;br /&gt;    bool &lt;- arithmeticExceptionhandler e2&lt;br /&gt;    when bool $ lift $ putStrLn "DEBUG: Something happened"&lt;br /&gt;    succeed () -- the dual of "throw"&lt;br /&gt;    -- Statements beyond here will not be evaluated&lt;br /&gt;    notEvaluated&lt;br /&gt;&lt;/pre&gt;If any handler succeeds (by returning a &lt;tt&gt;Right&lt;/tt&gt; result), the entire monad terminates with the successful result.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Laws for throwE and catchE&lt;/h4&gt;&lt;br /&gt;In fact, since &lt;tt&gt;throwE&lt;/tt&gt; and &lt;tt&gt;catchE&lt;/tt&gt; are just &lt;tt&gt;return&lt;/tt&gt; and &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt; in disguise, we can use the monad laws to state the behavior that &lt;tt&gt;throwE&lt;/tt&gt; and &lt;tt&gt;catchE&lt;/tt&gt; are expected to satisfy: &lt;pre&gt;&lt;br /&gt;-- return x &gt;&gt;= f = f x&lt;br /&gt;throwE x `catchE` f = f x&lt;br /&gt;&lt;br /&gt;-- m &gt;&gt;= return = m&lt;br /&gt;m `catchE` throwE = m&lt;br /&gt;&lt;br /&gt;-- (m &gt;&gt;= f) &gt;&gt;= g = m &gt;&gt;= (\x -&gt; f x &gt;&gt;= g)&lt;br /&gt;(m `catchE` f) `catchE` g = m `catchE` (\e -&gt; f e `catchE` g)&lt;br /&gt;&lt;/pre&gt;If you spend a moment to think about all of those laws they all make intuitive sense.  They each say, respectively: &lt;ul&gt;&lt;li&gt; If you throw a value, the catch block processes it &lt;li&gt; If your catch block just rethrows the error, it's the same as not catching in the first place &lt;li&gt; Catch blocks are associative &lt;/ul&gt;These laws exactly match our intuition for how &lt;tt&gt;throwE&lt;/tt&gt; and &lt;tt&gt;catchE&lt;/tt&gt; should behave!&lt;br /&gt;&lt;br /&gt;If all of this excites you, then you'll love &lt;tt&gt;Data.EitherR&lt;/tt&gt;, which is one of the modules exported by &lt;tt&gt;Control.Error&lt;/tt&gt;.  It provides all the machinery necessary for working in the &lt;tt&gt;EitherR&lt;/tt&gt; monad and also provides the convenience functions for the generalized &lt;tt&gt;throw&lt;/tt&gt; and &lt;tt&gt;catch&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;throwE :: e -&gt; Either e r&lt;br /&gt;catchE :: Either a r -&gt; (a -&gt; Either b r) -&gt; Either b r&lt;br /&gt;&lt;/pre&gt;These are just newtype wrappers around the &lt;tt&gt;return&lt;/tt&gt; and &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt; in the success monad.  If all you want is &lt;tt&gt;throwE&lt;/tt&gt; and &lt;tt&gt;catchE&lt;/tt&gt;, then you never need to actually use &lt;tt&gt;EitherR&lt;/tt&gt; directly and the above functions are sufficient.&lt;br /&gt;&lt;br /&gt;Also, technically you could just use &lt;tt&gt;Either&lt;/tt&gt; itself to implement the "success" monad by just reversing the convention for the type variables and use &lt;tt&gt;throwE&lt;/tt&gt; and &lt;tt&gt;catchE&lt;/tt&gt; to implement the error monad.  However, the main reason you might not want to do that is to not confuse other people who are familiar with the traditional convention for &lt;tt&gt;Either&lt;/tt&gt;.  People will understand your code better if you stick to &lt;tt&gt;Either&lt;/tt&gt; for code that terminates on errors and &lt;tt&gt;EitherR&lt;/tt&gt; for code that terminates on successes.&lt;br /&gt;&lt;br /&gt;Additionally, if you want to actually switch between both monads in your code and use ordinary &lt;tt&gt;do&lt;/tt&gt; notation for each one, then the &lt;tt&gt;EitherR&lt;/tt&gt; and &lt;tt&gt;EitherRT&lt;/tt&gt; newtypes will be absolutely essential to convert between both monads.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Simplicity&lt;/h4&gt;&lt;br /&gt;There's one last thing that's nice about &lt;tt&gt;Control.Error&lt;/tt&gt;: it re-exports &lt;tt&gt;Data.Either&lt;/tt&gt; and &lt;tt&gt;Data.Maybe&lt;/tt&gt;.  It's just one nice little feature that helps trim down your import list.&lt;br /&gt;&lt;br /&gt;I always enjoy coming up with compelling and interesting Haskell code examples in as few lines as possible, and keeping the import list clean is just one of those "nice" things when showing people from other languages how clean and simple Haskell can be.  My rule of thumb is that if you really want to impress other people with Haskell, then show them how much power you can fit clearly and expressively into a single 80x24 terminal window, including all imports and extensions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;Hopefully this library will help shrink up a lot of people's utility modules and encourage the &lt;tt&gt;Either&lt;/tt&gt;/&lt;tt&gt;EitherT&lt;/tt&gt; style of error-handling.  Let me know if there is a feature that you think is missing from this library, because the goal of this library is to make error handling as simple and painless as possible.</description><link>http://www.haskellforall.com/2012/07/errors-10-simplified-error-handling.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>7</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-3049625109806104245</guid><pubDate>Mon, 02 Jul 2012 01:43:00 +0000</pubDate><atom:updated>2012-07-01T18:43:37.781-07:00</atom:updated><title>pipes-2.1 and index-core-1.0 - Indexed types</title><description>This &lt;a href="http://hackage.haskell.org/package/pipes"&gt;new release&lt;/a&gt; marks a major upgrade to the &lt;tt&gt;pipes&lt;/tt&gt; &lt;tt&gt;Frame&lt;/tt&gt; implementation that unifies the entire implementation within a single type using indexed types.  The most important benefits of this are: &lt;ul&gt;&lt;li&gt; &lt;tt&gt;Frame&lt;/tt&gt;s are now unified into a single type &lt;li&gt; The newtype is gone &lt;li&gt; &lt;tt&gt;do&lt;/tt&gt; notation can be rebound to work with monads on indexed types. &lt;/ul&gt;Now, &lt;tt&gt;Frame&lt;/tt&gt; code is virtually indistinguishable from &lt;tt&gt;Pipe&lt;/tt&gt; code.  For example, the &lt;tt&gt;take'&lt;/tt&gt; &lt;tt&gt;Frame&lt;/tt&gt; looks like this: &lt;pre&gt;&lt;br /&gt;take' n = do&lt;br /&gt;    replicateMR_ $ do&lt;br /&gt;        a &lt;- await&lt;br /&gt;        yield a&lt;br /&gt;    close&lt;br /&gt;    liftU $ putStrLn "You shall not pass"&lt;br /&gt;&lt;/pre&gt;However, before I continue, I want to make good on a promise to notify readers of my blog that I made some mistakes in my &lt;a href="http://www.haskellforall.com/2012/05/conduit-bugs.html"&gt;previous post&lt;/a&gt; on bugs in &lt;tt&gt;conduit&lt;/tt&gt;.  I corrected some of the mistakes in the original post and in &lt;a href="http://www.yesodweb.com/blog/2012/05/response-conduit-bugs"&gt;Michael's response post&lt;/a&gt; he explained several of his design decisions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Indexed types&lt;/h4&gt;&lt;br /&gt;To upgrade &lt;tt&gt;pipes&lt;/tt&gt; to use indexed types, I wrote a base library that provides the foundation for indexed types: &lt;tt&gt;index-core-1.0&lt;/tt&gt;, which you can find &lt;a href="http://hackage.haskell.org/package/index-core"&gt;here&lt;/a&gt;.  This library is strongly based on the functional pearl "Kleisli arrows of outrageous fortune" by Conor McBride.&lt;br /&gt;&lt;br /&gt;The other significant alternative for indexed monads was the &lt;tt&gt;indexed&lt;/tt&gt; package, but I chose not to use it for several reasons.&lt;br /&gt;&lt;br /&gt;First, Conor's approach is strictly more powerful, allowing computations that can end in multiple states while still preserving type safety.  Although &lt;tt&gt;pipes&lt;/tt&gt; does not make use of this facility, I preferred using a stronger framework for indexed types as a dependency to encourage others to use his approach.&lt;br /&gt;&lt;br /&gt;Second, Conor's approach makes it MUCH easier to translate ordinary types into indexed types mechanically.  The best example of this is the "indexed free monad transformer" (what a mouthful) used to implement &lt;tt&gt;Frame&lt;/tt&gt;, which is the indexed equivalent to the free monad transformer used for &lt;tt&gt;Pipe&lt;/tt&gt;s.  However, not only are the types mechanically translatable, but so is the code, which is almost indistinguishable from unindexed code.&lt;br /&gt;&lt;br /&gt;However, I make one important deviation from Conor's approach, which is terminology.  Unfortunately, Conor's paper uses the term "indexed monads" to refer to the conventional approach represented in the &lt;tt&gt;indexed&lt;/tt&gt; package, and uses the term "monads on indexed types" to describe his approach, and it actually took me my third read-through of his paper before I even caught that distinction at all.  As a result, I decided to use more distinctive terminology to distinguish them so I prefer to use the term "indexed monad" to refer to Conor's approach and "restricted monad" to refer to the more restrictive approach found in &lt;tt&gt;indexed&lt;/tt&gt;.  All the documentation in &lt;tt&gt;index-core&lt;/tt&gt; follows this naming convention.&lt;br /&gt;&lt;br /&gt;Besides providing indexed and restricted monads, &lt;tt&gt;index-core&lt;/tt&gt; also provides the tools to switch between ordinary monads and restricted monads.  For example, you can always upgrade an ordinary monad to a restricted monad using the &lt;tt&gt;u&lt;/tt&gt; (for 'u'pgrade) function, and downgrade it again using &lt;tt&gt;unU&lt;/tt&gt;.  This is useful when you enable &lt;tt&gt;do&lt;/tt&gt; notation for indexed monads, but you still want to also use &lt;tt&gt;do&lt;/tt&gt; notation for ordinary monads: &lt;pre&gt;&lt;br /&gt;-- Upgrading IO to work in an indexed do block&lt;br /&gt;unU $ do&lt;br /&gt;    str &lt;- u getLine&lt;br /&gt;    u $ putStrLn str&lt;br /&gt;&lt;/pre&gt;Alternatively, you can choose to not enable indexed &lt;tt&gt;do&lt;/tt&gt; notation and instead downgrade index-preserving restricted monads to ordinary monads using the &lt;tt&gt;D&lt;/tt&gt; (for 'D'owngrade) function and upgrade it again using &lt;tt&gt;unD&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;-- Downgrading Frame to work in an ordinary do block&lt;br /&gt;unD $ do&lt;br /&gt;    a &lt;- D await&lt;br /&gt;    D $ yield a&lt;br /&gt;&lt;/pre&gt;However, if you took the latter approach, you would need to use the indexed monad bind directly anytime you use an operation that changes the index (such as the &lt;tt&gt;close&lt;/tt&gt; operation).  It's up to you which approach you prefer.&lt;br /&gt;&lt;br /&gt;Also, &lt;tt&gt;index-core&lt;/tt&gt; exports restricted monad versions of the functions found in &lt;tt&gt;Control.Monad&lt;/tt&gt;, except with 'R'-suffixed names (for 'R'estricted), like &lt;tt&gt;foreverR&lt;/tt&gt; and &lt;tt&gt;replicateMR&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Note that &lt;tt&gt;index-core&lt;/tt&gt; does not yet export a restricted &lt;tt&gt;Applicative&lt;/tt&gt; class.  It can be done, but I just haven't gotten a chance to do it, so all the examples in this post and in the &lt;tt&gt;pipes&lt;/tt&gt; tutorial don't yet use the &lt;tt&gt;Applicative&lt;/tt&gt; style.&lt;br /&gt;&lt;br /&gt;&lt;br/ &gt;&lt;h4&gt;Sugar&lt;/h4&gt;&lt;br /&gt;&lt;tt&gt;Frame&lt;/tt&gt;s are now on par with &lt;tt&gt;Pipe&lt;/tt&gt;s in terms of elegance and syntactic sugar.  All of the complaints raised for &lt;tt&gt;pipes-2.0&lt;/tt&gt; are fixed by this upgrade.  There is no two-stage monad any longer, meaning that you can do elegant things like: &lt;pre&gt;&lt;br /&gt;strict = toList &gt;&gt;= fromList&lt;br /&gt;&lt;/pre&gt;... and the implementation of &lt;tt&gt;toList&lt;/tt&gt; is now very succinct, exactly the way you'd expect to write it: &lt;pre&gt;&lt;br /&gt;toList = do&lt;br /&gt;    a' &lt;- awaitF&lt;br /&gt;    case a' of&lt;br /&gt;        Nothing -&gt; return []&lt;br /&gt;        Just a  -&gt; do&lt;br /&gt;            as &lt;- toList&lt;br /&gt;            return (a:as)&lt;br /&gt;&lt;/pre&gt;Note that I've switched the roles of &lt;tt&gt;awaitF&lt;/tt&gt; and &lt;tt&gt;await&lt;/tt&gt;.  This is so that &lt;tt&gt;Frame&lt;/tt&gt; &lt;tt&gt;await&lt;/tt&gt; is now a drop-in replacement for &lt;tt&gt;Pipe&lt;/tt&gt; &lt;tt&gt;await&lt;/tt&gt; and also to bring &lt;tt&gt;pipes&lt;/tt&gt;s in line with &lt;tt&gt;pipes-core&lt;/tt&gt;, notationally, which uses &lt;tt&gt;await&lt;/tt&gt; to denote the default request which does not return a &lt;tt&gt;Maybe&lt;/tt&gt;.  &lt;tt&gt;awaitF&lt;/tt&gt; becomes the &lt;tt&gt;Frame&lt;/tt&gt; equivalent to &lt;tt&gt;tryAwait&lt;/tt&gt; from &lt;tt&gt;pipes-core&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Miscellany&lt;/h4&gt;&lt;br /&gt;The hierarchy has been reorganized a bit.  I've moved &lt;tt&gt;Frame&lt;/tt&gt;s to &lt;tt&gt;Control.Frame&lt;/tt&gt; because they are no longer built on top of the &lt;tt&gt;Pipe&lt;/tt&gt; type.  Also, now I've moved the tutorials to &lt;tt&gt;Control.Pipe.Tutorial&lt;/tt&gt; and &lt;tt&gt;Control.Frame.Tutorial&lt;/tt&gt; and made a lot of updates to the &lt;tt&gt;Frame&lt;/tt&gt; tutorial, especially the strictness part, which now does a really good job of demonstrating how you can be selectively strict in the input.&lt;br /&gt;&lt;br /&gt;Now that &lt;tt&gt;conduit&lt;/tt&gt; is also expanding its documentation, I thought it would be a good time to choose a better module hierarchy to set as an example for other libraries.  I think that a simple "&lt;tt&gt;.Tutorial&lt;/tt&gt;" extension for a module's corresponding tutorial is perhaps the most flexible and straightforward way to navigate to the tutorial for a particularly module.  The advantage of splitting the tutorial module from the actual API module is so that you can feel free to write a long tutorial without worrying about getting in the way of navigating the API.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Streaming Haskell Group&lt;/h4&gt;&lt;br /&gt;Besides cleaning up the &lt;tt&gt;Frame&lt;/tt&gt; implementation, there's another reason I'm switching to indexed types.  Recently, Michael founded the &lt;a href="https://groups.google.com/forum/?fromgroups#!forum/streaming-haskell"&gt;streaming-haskell&lt;/a&gt; group and after a some of discussion with the other members of the Streaming Haskell group, I'm beginning to believe that the final type that we will end up agreeing on will require some form of indexed types, so this release is my effort to lay the groundwork for an indexed type ecosystem so that people will be less afraid to experiment with indexed types.  With this release I hope to give people: &lt;ul&gt;&lt;li&gt; The tools to work with indexed types &lt;li&gt; An instructive library to consult as a reference &lt;li&gt; A motivating example for the practical benefits of indexed types &lt;/ul&gt;In a future post I will discuss in greater length why indexed types are the future of more advanced iteratee implementations, perhaps even for ones that rely on implementation hiding.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Future Directions&lt;/h4&gt;&lt;br /&gt;As many people know, I make a big deal about avoiding implementation hiding when enforcing class laws.  I believe strongly in keeping the entire library correct by construction so that it is easy for other people to extend without worrying about breaking any laws.  At the same time, I strive to simplify the interface the user must understand to use the library and I think this version is a big step in that direction.&lt;br /&gt;&lt;br /&gt;I'm a big advocate for free monads and one of the big benefits of free monads is the power to choose your observation function.  Historically, &lt;tt&gt;runPipe&lt;/tt&gt; (or &lt;tt&gt;runFrame&lt;/tt&gt;) has been the canonical observation function, but I believe people's creativity has been filtered through the lens of what they could accomplish through &lt;tt&gt;runPipe&lt;/tt&gt; and they don't think of all the things they could do by writing their own observation functions.  By sticking to strong guarantees I try to promote experimentation in the observation function and in the future I will write a post with some motivating examples to get people to think outside the &lt;tt&gt;runPipe&lt;/tt&gt; box.&lt;br /&gt;&lt;br /&gt;Now that I'm happier with the state of the &lt;tt&gt;Frame&lt;/tt&gt; API you will soon see a library of utility functions included in upcoming minor releases so that you don't have to write your own (although, it's very easy to do so now!).  Also, parsing is a major goal in the near future and a complete parsing implementation is my target for version &lt;tt&gt;3.0&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;As far as exceptions go, you can still have the same exception-handling power that &lt;tt&gt;conduit&lt;/tt&gt; does by just layering &lt;tt&gt;Frame&lt;/tt&gt; on top of &lt;tt&gt;ResourceT&lt;/tt&gt;, but I choose not to do so yet because I have other ideas for how to implement it.  Because advanced &lt;tt&gt;Frame&lt;/tt&gt; users can in theory implement exception handling using the API I currently present, it's lower on my priority list than parsing, which is non-trivial.  However, if you disagree with my priorities, feel free to let me know.  I always strive to follow feedback from users.</description><link>http://www.haskellforall.com/2012/07/pipes-21-and-index-core-10-indexed.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>0</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-2886506495105582920</guid><pubDate>Sat, 16 Jun 2012 20:02:00 +0000</pubDate><atom:updated>2012-06-20T11:32:33.130-07:00</atom:updated><title>GADTs</title><description>&lt;h4&gt;Prelude&lt;/h4&gt;&lt;br /&gt;Some time ago I asked a question on &lt;a href="http://www.reddit.com/r/haskell/comments/md7e8/gadts_question/"&gt;/r/haskell&lt;/a&gt; about what unique purpose GADTs served that other language features could not provide.  Edward Kmett (as usual) gave the best answer: &lt;blockquote&gt;To be pedantic, there should be no examples that cannot be encoded without GADTs. You can always transform a GADT into a finally [sic] tagless representation through a class if you have Rank N types.&lt;/blockquote&gt;The &lt;a href="http://www.cs.rutgers.edu/%7Eccshan/tagless/jfp.pdf"&gt;"Finally Tagless"&lt;/a&gt; paper came up several times in that discussion, so I decided to read it and it was a very well-written and exciting paper.  However, both Edward's answer and one key sentence from the paper damaged my understanding of GADTs for 7 months: &lt;blockquote&gt;In Haskell, typecase can be implemented using either GADTs or type-class functional dependencies &lt;/blockquote&gt;This combined with Edward's answer led me to believe that type-classes and functional dependencies were necessary to implement GADTs in the absence of language support for GADTs, but I recently discovered this is wrong!  The only extension you need is &lt;tt&gt;Rank2Types&lt;/tt&gt;, and no type-classes or functional dependencies are required at all.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;GADTs&lt;/h4&gt;&lt;br /&gt;For those unfamiliar with GADTs ("Generalized Algebraic Data Types"), they allow you to restrict the type variables of a constructor's result.  For example, when you define a type like: &lt;pre&gt;&lt;br /&gt;data Maybe a = Just a | Nothing&lt;br /&gt;&lt;/pre&gt;... one of the things it does is define two constructors with the following type signatures: &lt;pre&gt;&lt;br /&gt;Just    :: a -&gt; Maybe a&lt;br /&gt;Nothing :: Maybe a&lt;br /&gt;&lt;/pre&gt;Using the &lt;tt&gt;GADTs&lt;/tt&gt; extensions, you can declare data types like &lt;tt&gt;Maybe a&lt;/tt&gt; by instead supplying the type signature of the constructors: &lt;pre&gt;&lt;br /&gt;data Maybe a where&lt;br /&gt;    Just    :: a -&gt; Maybe a&lt;br /&gt;    Nothing :: Maybe a&lt;br /&gt;&lt;/pre&gt;However, this extension unlocks an additional feature, namely the ability to type-restrict the type variables of the constructor's final result.  The most common example is a list with type-level length annotations. &lt;pre&gt;&lt;br /&gt;data Z   -- i.e. "Z"ero&lt;br /&gt;data S n -- i.e. "S"ucc&lt;br /&gt;&lt;br /&gt;-- A List of length 'n' holding values of type 'a'&lt;br /&gt;data List a n where&lt;br /&gt;    Nil  :: List a Z&lt;br /&gt;    Cons :: a -&gt; List a m -&gt; List a (S m)&lt;br /&gt;&lt;/pre&gt;The advantage of type-level annotations is that we can now use that annotation to enforce stronger invariants.  For example, we can write a safe &lt;tt&gt;head&lt;/tt&gt; function that only accepts lists with at least one element: &lt;pre&gt;&lt;br /&gt;head :: List a (S n) -&gt; a&lt;br /&gt;head (Cons a _) = a&lt;br /&gt;&lt;/pre&gt;The type-level length annotation guarantees that you can't pass an empty list (i.e. &lt;tt&gt;Nil&lt;/tt&gt;) to &lt;tt&gt;head&lt;/tt&gt;, so it is now a safe and total function.&lt;br /&gt;&lt;br /&gt;However, you cannot directly translate the above &lt;tt&gt;List&lt;/tt&gt; constructors into ordinary data types because with ordinary data types the final result of each constructor must be polymorphic in all type variables.  The above definitions for &lt;tt&gt;Nil&lt;/tt&gt; and &lt;tt&gt;Cons&lt;/tt&gt; require restricting the length type variable returned by the constructor.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Yoneda Lemma&lt;/h4&gt;&lt;br /&gt;Fortunately, the Yoneda lemma from category theory provides the necessary trick to convert a GADT to an ordinary data type.  The Yoneda lemma translated into Haskell is actually more understandable than the equivalent category theory explanation (at least, to me).  It simply says that if &lt;tt&gt;f&lt;/tt&gt; is a functor, then the following two types are isomorphic: &lt;pre&gt;&lt;br /&gt;(forall b. (a -&gt; b) -&gt; f b) ~ f a&lt;br /&gt;&lt;/pre&gt;... which means that we can define two functions &lt;tt&gt;fw&lt;/tt&gt; and &lt;tt&gt;bw&lt;/tt&gt; that can convert back and forth between those two types: &lt;pre&gt;&lt;br /&gt;fw :: (Functor f) =&gt; (forall b . (a -&gt; b) -&gt; f b) -&gt; f a&lt;br /&gt;fw f = f id&lt;br /&gt;&lt;br /&gt;bw :: (Functor f) =&gt; f a -&gt; (forall b . (a -&gt; b) -&gt; f b)&lt;br /&gt;bw x f = fmap f x&lt;br /&gt;&lt;/pre&gt;Actually, these functions must meet one more requirement to be an isomorphism.  They must satisfy the following laws: &lt;pre&gt;&lt;br /&gt;fw . bw = id&lt;br /&gt;bw . fw = id&lt;br /&gt;&lt;/pre&gt;One of those is easy to prove, the other one is difficult (and is the meat of the Yoneda lemma in Haskell).  Also, you can translate the Yoneda lemma into Haskell in other ways, because it's very general, but the above version suffices for this post.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;The Trick&lt;/h4&gt;&lt;br /&gt;Now we will use the Yoneda isomorphism to transform the GADT constructors (with restricted results) into isomorphic ordinary constructors (with polymorphic results).  Let's begin with the above &lt;tt&gt;List&lt;/tt&gt; data type.&lt;br /&gt;&lt;br /&gt;The &lt;tt&gt;Nil&lt;/tt&gt; constructor has the signature: &lt;pre&gt;&lt;br /&gt;Nil :: List a Z&lt;br /&gt;&lt;/pre&gt;... but the Yoneda lemma says that if &lt;tt&gt;List a&lt;/tt&gt; is a functor, then the following constructor is isomorphic: &lt;pre&gt;&lt;br /&gt;Nil :: (Z -&gt; n) -&gt; List a n&lt;br /&gt;&lt;/pre&gt;Similarly, the signature for the &lt;tt&gt;Cons&lt;/tt&gt; constructor: &lt;pre&gt;&lt;br /&gt;Cons :: a -&gt; List a m -&gt; List a (S m)&lt;br /&gt;&lt;/pre&gt;... can be transformed into: &lt;pre&gt;&lt;br /&gt;Cons :: a -&gt; List a m -&gt; (S m -&gt; n) -&gt; List a n&lt;br /&gt;&lt;/pre&gt;Now we have a data type where the constructors have polymorphic type variables in their output: &lt;pre&gt;&lt;br /&gt;data List a n where&lt;br /&gt;    Nil  :: (Z -&gt; n) -&gt; List a n&lt;br /&gt;    Cons :: a -&gt; List a m -&gt; (S m -&gt; n) -&gt; List a n&lt;br /&gt;&lt;/pre&gt;... meaning that we can now transform it into an ordinary data type: &lt;pre&gt;&lt;br /&gt;data List a n =&lt;br /&gt;    Nil (Z -&gt; n)&lt;br /&gt;  | forall m. Cons a (List a m) (S m -&gt; n)&lt;br /&gt;&lt;/pre&gt;The above type signature only requires the &lt;tt&gt;Rank2Types&lt;/tt&gt; extension to write.&lt;br /&gt;&lt;br /&gt;Notice how the above type converts the "phantom type" into a concrete value-level dependency.  By restricting the permissible functions for &lt;tt&gt;(Z -&gt; n)&lt;/tt&gt; and &lt;tt&gt;(S m -&gt; n)&lt;/tt&gt; we can constrain the GADTs equivalent "phantom type".  Interestingly, those two constraints (correct me if I'm wrong) seem to define an F-algebra.&lt;br /&gt;&lt;br /&gt;Remember that the Yoneda isomorphism only holds if &lt;tt&gt;List a&lt;/tt&gt; is a functor, so the final step is to define the appropriate functor: &lt;pre&gt;&lt;br /&gt;instance Functor (List a) where&lt;br /&gt;    fmap f (Nil k) = Nil (f . k)&lt;br /&gt;    fmap f (Cons a as k) = Cons a as (f . k)&lt;br /&gt;&lt;/pre&gt;Or you can use the &lt;tt&gt;DeriveFunctor&lt;/tt&gt; extension and just write: &lt;pre&gt;&lt;br /&gt;data List a n = ... deriving (Functor)&lt;br /&gt;&lt;/pre&gt;... and it will derive the correct &lt;tt&gt;Functor&lt;/tt&gt; instance automatically for you.&lt;br /&gt;&lt;br /&gt;Take care to note that this &lt;tt&gt;Functor&lt;/tt&gt; instance is not the same as the ordinary &lt;tt&gt;Functor&lt;/tt&gt; instance for lists.  This one maps functions over the length type parameter &lt;tt&gt;n&lt;/tt&gt;, as opposed to the value type parameter &lt;tt&gt;a&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conversion&lt;/h4&gt;&lt;br /&gt;The equations proving the Yoneda isomorphism say that we should be able to convert our data type back into the equivalent GADT just by using the &lt;tt&gt;fw&lt;/tt&gt; function.  Let's check it out: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; :t fw Nil&lt;br /&gt;fw Nil :: List a Z&lt;br /&gt;&gt;&gt;&gt; :t fw (Cons 'A' (fw Nil))&lt;br /&gt;fw (Cons 'A' (fw Nil)) :: List Char (S Z)&lt;br /&gt;&lt;/pre&gt;We now have lists with type-level length annotations, but without GADTs.  All we would have to do to recapitulate the GADT constructors would be to define the smart constructors: &lt;pre&gt;&lt;br /&gt;nil = fw Nil&lt;br /&gt;cons a as = fw (Cons a as)&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; :t nil&lt;br /&gt;nil :: List a Z&lt;br /&gt;&gt;&gt;&gt; :t cons 'A' nil&lt;br /&gt;cons 'A' nil :: List Char (S Z)&lt;br /&gt;&lt;/pre&gt;There is no magic to what &lt;tt&gt;fw&lt;/tt&gt; is doing.  Remember all it does is supply an &lt;tt&gt;id&lt;/tt&gt;, so we could have rewritten the above as: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; :t Nil id&lt;br /&gt;Nil id :: List a Z&lt;br /&gt;&gt;&gt;&gt; :t Cons 'A' (Nil id) id&lt;br /&gt;Cons 'A' (Nil id) id :: List Char (S Z)&lt;br /&gt;&lt;/pre&gt;To understand why this works, notice that the type signature of &lt;tt&gt;Nil&lt;/tt&gt; is: &lt;pre&gt;&lt;br /&gt;Nil :: (Z -&gt; n) -&gt; List a n&lt;br /&gt;&lt;/pre&gt;So when we pass it an &lt;tt&gt;id&lt;/tt&gt;, the compiler infers that the first field of &lt;tt&gt;Nil&lt;/tt&gt; must have type &lt;tt&gt;(Z -&gt; Z)&lt;/tt&gt;, therefore &lt;tt&gt;n&lt;/tt&gt; must be &lt;tt&gt;Z&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;Nil :: (Z -&gt; Z) -&gt; List a Z&lt;br /&gt;&lt;/pre&gt;If our new &lt;tt&gt;List&lt;/tt&gt; data type is truly isomorphic to the original, then we should be able to write a type-safe &lt;tt&gt;head&lt;/tt&gt; function, just like with the GADT.  Let's first write out the type signature for &lt;tt&gt;head&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;head :: List a (S n) -&gt; a&lt;br /&gt;&lt;/pre&gt;The argument has type &lt;tt&gt;List a (S n)&lt;/tt&gt;, which expands to one of two possible constructors: &lt;pre&gt;&lt;br /&gt;List a (S n) =&lt;br /&gt;    Nil (Z -&gt; S n)&lt;br /&gt;  | forall m. Cons a (List a m) -&gt; (S m -&gt; S n)&lt;br /&gt;&lt;/pre&gt;The Cons constructor is always permissible, since we can always pass it an &lt;tt&gt;id&lt;/tt&gt; for its final field, to satisfy the type (which would constrain &lt;tt&gt;m&lt;/tt&gt; to &lt;tt&gt;n&lt;/tt&gt;).  However, the existence of the &lt;tt&gt;Nil&lt;/tt&gt; constructor depends on the existence of a function of type &lt;tt&gt;(Z -&gt; S n)&lt;/tt&gt;.&lt;br /&gt;&lt;br /&gt;Fortunately, no such function exists, so we can guarantee that such a &lt;tt&gt;Nil&lt;/tt&gt; constructor can never be built.  &lt;tt&gt;S n&lt;/tt&gt; has no constructors, so the only way we can build it is to start from a pre-existing value of type &lt;tt&gt;S n&lt;/tt&gt;, and this is what the &lt;tt&gt;id&lt;/tt&gt; function does.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Initiality&lt;/h4&gt;&lt;br /&gt;However, more generally Haskell possesses a major flaw that empty types truly aren't empty and are in fact inhabited by the "bottom" value (i.e. &lt;tt&gt;undefined&lt;/tt&gt;/&lt;tt&gt;_|_&lt;/tt&gt;).  This means that I could define the following function: &lt;pre&gt;&lt;br /&gt;showZ :: Z -&gt; String&lt;br /&gt;showZ _ = "Hello, world"&lt;br /&gt;&lt;/pre&gt;... and it would type-check even though &lt;tt&gt;Z&lt;/tt&gt; has no constructors that you could pass to &lt;tt&gt;showZ&lt;/tt&gt;.  Unfortunately, it type-checks because the following is valid Haskell: &lt;pre&gt;&lt;br /&gt;fakeZ :: Z&lt;br /&gt;fakeZ = fakeZ -- the definition of bottom&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; showZ fakeZ&lt;br /&gt;"Hello, world!"&lt;br /&gt;&lt;/pre&gt;This leads to weird situations where you could do things like build lists with lengths of type &lt;tt&gt;String&lt;/tt&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; :t Nil showZ&lt;br /&gt;Nil showZ :: List a String&lt;br /&gt;&lt;/pre&gt;So the absence of a truly initial object in Haskell (i.e. a truly empty type) means that the above GADT transformation is not as safe as true GADTs.  If it were, then we could implement all our type-level tricks at the value level, using constructor fields like our &lt;tt&gt;(Z -&gt; n)&lt;/tt&gt; to recapitulate type-level proof requirements at the value-level.&lt;br /&gt;&lt;br /&gt;This means the best we can do is define our &lt;tt&gt;head&lt;/tt&gt; function to be: &lt;pre&gt;&lt;br /&gt;head :: List a (S n) -&gt; a&lt;br /&gt;head (Cons a _ _) = a&lt;br /&gt;&lt;/pre&gt;... and pray that the user does not define functions of types with empty constructors.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;&lt;tt&gt;operational&lt;/tt&gt; vs. &lt;tt&gt;free&lt;/tt&gt;&lt;/h4&gt;&lt;br /&gt;Another example of this equivalence between these two representations of GADTs came up recently on reddit in &lt;a href="http://www.reddit.com/r/haskell/comments/utxq2/why_free_monads_matter/c4yo95b"&gt;the comments&lt;/a&gt; to another post of mine discussing &lt;a href="http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html"&gt;free monads&lt;/a&gt;.  There was a discussion between the relationship between free monads and the &lt;tt&gt;operational&lt;/tt&gt; package.  However, the above transformation shows that the free monad is as powerful as the &lt;tt&gt;operational&lt;/tt&gt; approach.&lt;br /&gt;&lt;br /&gt;To demonstrate this, using the &lt;tt&gt;free&lt;/tt&gt; package you would define the following base functor for a teletype: &lt;pre&gt;&lt;br /&gt;data TeletypeF x =&lt;br /&gt;    PutChar Char x&lt;br /&gt;  | GetChar (Char -&gt; x)&lt;br /&gt;  deriving (Functor)&lt;br /&gt;&lt;/pre&gt;.. and then free monad for a teletype program would then be: &lt;pre&gt;&lt;br /&gt;type Teletype = Free TeletypeF&lt;br /&gt;&lt;/pre&gt;Using the &lt;tt&gt;operational&lt;/tt&gt; package, you would instead write: &lt;pre&gt;&lt;br /&gt;data TeletypeF x where&lt;br /&gt;    PutChar :: Char -&gt; TeletypeF ()&lt;br /&gt;    GetChar :: TeletypeF Char&lt;br /&gt;&lt;/pre&gt;.. and the corresponding program would be: &lt;pre&gt;&lt;br /&gt;type Teletype = Program TeletypeF&lt;br /&gt;&lt;/pre&gt;However, the Yoneda transformation shows that the two data types are in fact equivalent.  Transforming the operational GADT using the Yoneda lemma gives: &lt;pre&gt;&lt;br /&gt;data TeletypeF x =&lt;br /&gt;    PutChar :: Char -&gt; (() -&gt; x) -&gt; TeletypeF x&lt;br /&gt;    GetChar :: (Char -&gt; x) -&gt; TeletypeF x&lt;br /&gt;    deriving (Functor)&lt;br /&gt;&lt;/pre&gt;... which is exactly isomorphic to the signature for the corresponding Free monad.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Conclusions&lt;/h4&gt;&lt;br /&gt;GADTs are nothing more than the Yoneda lemma in disguise.&lt;br /&gt;&lt;br /&gt;This implies that the absence of truly initial objects in Haskell is the only obstacle to moving all dependently-typed programming "down" to the value level.  Haskell's type-level programming extensions can be seen as nothing more than a work-around for the lack of value-level initial objects, and they solve this issue by moving parts of the program to the type level where there are true initial objects.  Thus, it perhaps is more appropriate to think of type-level programming as not being a step "above" value level programming in some sort of heirarchy (i.e. values  types  kinds  hyper-kinds) but rather simply existing on the same plane with different rules.  This would imply Haskell programming is simply a hybrid approach of programming using two arenas (the value-level arena where initial objects don't exist and the type-level arena where they do exist).  Instead of value-level and type-level programming being two different "levels" (which implies an ordering or hierarchy), maybe they are simply two unordered arenas of programming.&lt;br /&gt;&lt;br /&gt;</description><link>http://www.haskellforall.com/2012/06/gadts.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>7</thr:total></item><item><guid isPermaLink='false'>tag:blogger.com,1999:blog-1777990983847811806.post-9164355965022050153</guid><pubDate>Sat, 09 Jun 2012 21:30:00 +0000</pubDate><atom:updated>2012-06-10T07:42:28.305-07:00</atom:updated><title>Why free monads matter</title><description>&lt;h4&gt;Interpreters&lt;/h4&gt;&lt;br /&gt;Good programmers decompose data from the interpreter that processes that data.  Compilers exemplify this approach, where they will typically represent the source code as an abstract syntax tree, and then pass that tree to one of many possible interpreters.  We benefit from decoupling the interpreter and the syntax tree, because then we can interpret the syntax tree in multiple ways.  For example, we could: &lt;ul&gt;&lt;li&gt; compile it to an executable, &lt;li&gt; run it directly (i.e. the traditional sense of "interpret"), &lt;li&gt; pretty print it, &lt;li&gt; compress and archive it, &lt;li&gt; or do nothing at all with it! &lt;/ul&gt;Each of those options corresponds to a different interpreter.&lt;br /&gt;&lt;br /&gt;Let's try to come up with some sort of abstraction that represents the essence of a syntax tree.  Abstractions always begin from specific examples, so let's invent our own toy programming language and try to represent it as a data type.&lt;br /&gt;&lt;br /&gt;Our toy language will only have three commands: &lt;pre&gt;&lt;br /&gt;output b -- prints a "b" to the console&lt;br /&gt;bell     -- rings the computer's bell&lt;br /&gt;done     -- end of execution&lt;br /&gt;&lt;/pre&gt;So we represent it as a syntax tree where subsequent commands are leaves of prior commands: &lt;pre&gt;&lt;br /&gt;data Toy b next =&lt;br /&gt;    Output b next&lt;br /&gt;  | Bell next&lt;br /&gt;  | Done&lt;br /&gt;&lt;/pre&gt;Notice how the &lt;tt&gt;Done&lt;/tt&gt; command has no leaf since it must be the last command.&lt;br /&gt;&lt;br /&gt;Then I could write a sample program that I might want to pass to an interpreter: &lt;pre&gt;&lt;br /&gt;-- output 'A'&lt;br /&gt;-- done&lt;br /&gt;Output 'A' Done :: Toy Char (Toy a next)&lt;br /&gt;&lt;/pre&gt;... but unfortunately this doesn't work because every time I want to add a command, it changes the type: &lt;pre&gt;&lt;br /&gt;-- bell&lt;br /&gt;-- output 'A'&lt;br /&gt;-- done&lt;br /&gt;Bell (Output 'A' Done) :: Toy a (Toy Char (Toy b next)))&lt;br /&gt;&lt;/pre&gt;Fortunately, we can cheat and use the following data type to wrap as many &lt;tt&gt;Toy&lt;/tt&gt;s as we want into the same data type: &lt;pre&gt;&lt;br /&gt;data Cheat f = Cheat (f (Cheat f))&lt;br /&gt;&lt;/pre&gt;With &lt;tt&gt;Cheat&lt;/tt&gt; we've defined a stream of functors that will only end when it gets to the &lt;tt&gt;Done&lt;/tt&gt; constructor.  Fortunately, &lt;tt&gt;Cheat&lt;/tt&gt; already exists in Haskell and goes by another name: &lt;pre&gt;&lt;br /&gt;data Fix f = Fix (f (Fix f))&lt;br /&gt;&lt;/pre&gt;It's named &lt;tt&gt;Fix&lt;/tt&gt; because it is "the fixed point of a functor".&lt;br /&gt;&lt;br /&gt;With &lt;tt&gt;Fix&lt;/tt&gt; in hand, now we can fix our example programs: &lt;pre&gt;&lt;br /&gt;Fix (Output 'A' (Fix Done))              :: Fix (Toy Char)&lt;br /&gt;&lt;br /&gt;Fix (Bell (Fix (Output 'A' (Fix Done)))) :: Fix (Toy Char)&lt;br /&gt;&lt;/pre&gt;Now they have the same type.  Perfect!  Or is it?&lt;br /&gt;&lt;br /&gt;There's still a problem.  This approach only works if you can use the &lt;tt&gt;Done&lt;/tt&gt; constructor to terminate every chain of functors.  Unfortunately, programmers don't often have the luxury of writing the entire program from start to finish.  We often just want to write subroutines that can be called from within other programs and our &lt;tt&gt;Fix&lt;/tt&gt; trick doesn't let us write a subroutine without terminating the entire program.&lt;br /&gt;&lt;br /&gt;Ok, so let's hack together a quick and dirty fix to work around this problem.  Our subroutine finished but we are not ready to call &lt;tt&gt;Done&lt;/tt&gt;, so instead we throw an exception and let whoever calls our subroutine catch it and resume from where we left off: &lt;pre&gt;&lt;br /&gt;data FixE f e = Fix (f (FixE f e)) | Throw e&lt;br /&gt;&lt;/pre&gt;Then we write a &lt;tt&gt;catch&lt;/tt&gt; function: &lt;pre&gt;&lt;br /&gt;catch ::&lt;br /&gt;    (Functor f) =&gt; FixE f e1 -&gt; (e1 -&gt; FixE f e2) -&gt; FixE f e2&lt;br /&gt;catch (Fix x) f = Fix (fmap (flip catch f) x)&lt;br /&gt;catch (Throw e) f = f e&lt;br /&gt;&lt;/pre&gt;We can only use this if &lt;tt&gt;Toy b&lt;/tt&gt; is a functor, so we muddle around until we find something that type-checks (and satisfies the &lt;a href="http://hackage.haskell.org/packages/archive/base/4.3.1.0/doc/html/Control-Monad.html#t:Functor"&gt;Functor laws&lt;/a&gt;): &lt;pre&gt;&lt;br /&gt;instance Functor (Toy b) where&lt;br /&gt;    fmap f (Output x next) = Output x (f next)&lt;br /&gt;    fmap f (Bell     next) = Bell     (f next)&lt;br /&gt;    fmap f  Done           = Done&lt;br /&gt;&lt;/pre&gt;Now we can write code that can be caught and resumed: &lt;pre&gt;&lt;br /&gt;data IncompleteException = IncompleteException&lt;br /&gt;&lt;br /&gt;-- output 'A'&lt;br /&gt;-- throw IncompleteException&lt;br /&gt;subroutine = Fix (Output 'A' (Throw IncompleteException))&lt;br /&gt;    :: FixE (Toy Char) IncompleteException&lt;br /&gt;&lt;br /&gt;-- try {subroutine}&lt;br /&gt;-- catch (IncompleteException) {&lt;br /&gt;--     bell&lt;br /&gt;--     done&lt;br /&gt;-- }&lt;br /&gt;program = subroutine `catch` (\_ -&gt; Fix (Bell (Fix Done))&lt;br /&gt;    :: FixE (Toy Char) e&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;h4&gt;Free Monads - Part 1&lt;/h4&gt;&lt;br /&gt;So we proudly package up this "improved" &lt;tt&gt;Fix&lt;/tt&gt; and release it on Hackage under the package name &lt;tt&gt;fix-improved&lt;/tt&gt;, and then find out that the users are misusing the library.  They start using the exception to pass around ordinary values instead of exceptional values.  How dare they!  Exceptions are only for &lt;b&gt;exceptional&lt;/b&gt; situations and not for ordinary flow control.  What a bunch of morons!&lt;br /&gt;&lt;br /&gt;... except we are the morons, because our &lt;tt&gt;FixE&lt;/tt&gt; already exists, too, and it's called the &lt;a href="http://hackage.haskell.org/packages/archive/free/2.0.3/doc/html/Control-Monad-Free.html#t:Free"&gt;Free monad&lt;/a&gt;: &lt;pre&gt;&lt;br /&gt;data Free f r = Free (f (Free f r)) | Pure r&lt;br /&gt;&lt;/pre&gt;As the name suggests, it is automatically a monad (if &lt;tt&gt;f&lt;/tt&gt; is a functor): &lt;pre&gt;&lt;br /&gt;instance (Functor f) =&gt; Monad (Free f) where&lt;br /&gt;    return = Pure&lt;br /&gt;    (Free x) &gt;&gt;= f = Free (fmap (&gt;&gt;= f) x)&lt;br /&gt;    (Pure r) &gt;&gt;= f = f r&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;return&lt;/tt&gt; was our &lt;tt&gt;Throw&lt;/tt&gt;, and &lt;tt&gt;(&gt;&gt;=)&lt;/tt&gt; was our &lt;tt&gt;catch&lt;/tt&gt;.  Our users were actually using the &lt;tt&gt;e&lt;/tt&gt; values as return values because that is the correct way to use them within a monad.&lt;br /&gt;&lt;br /&gt;The great part about Haskell is that for any monad we get &lt;tt&gt;do&lt;/tt&gt; notation for free.  However, &lt;tt&gt;Free (Toy b)&lt;/tt&gt; is the monad, not &lt;tt&gt;Toy b&lt;/tt&gt;, which means that if we want to sequence our primitive commands using &lt;tt&gt;do&lt;/tt&gt; notation, we have convert our commands of type &lt;tt&gt;Toy b&lt;/tt&gt; into &lt;tt&gt;Free (Toy b)&lt;/tt&gt;.  Our attempt to do so produces something that looks like this: &lt;pre&gt;&lt;br /&gt;output :: a -&gt; Free (Toy a) ()&lt;br /&gt;output x = Free (Output x (Pure ()))&lt;br /&gt;&lt;br /&gt;bell :: Free (Toy a) ()&lt;br /&gt;bell = Free (Bell (Pure ()))&lt;br /&gt;&lt;br /&gt;done :: Free (Toy a) r&lt;br /&gt;done = Free Done&lt;br /&gt;&lt;/pre&gt;I'll be damned if that's not a common pattern we can abstract: &lt;pre&gt;&lt;br /&gt;liftF :: (Functor f) =&gt; f r -&gt; Free f r&lt;br /&gt;liftF command = Free (fmap Pure command)&lt;br /&gt;&lt;br /&gt;output x = liftF (Output x ())&lt;br /&gt;bell     = liftF (Bell     ())&lt;br /&gt;done     = liftF  Done&lt;br /&gt;&lt;/pre&gt;Now, we can sequence these primitive commands using &lt;tt&gt;do&lt;/tt&gt; notation, and everything just works!  Let's translate our previous example, getting rid of the superfluous exceptions: &lt;pre&gt;&lt;br /&gt;subroutine :: Free (Toy Char) ()&lt;br /&gt;subroutine = output 'A'&lt;br /&gt;&lt;br /&gt;program :: Free (Toy Char) r&lt;br /&gt;program = do&lt;br /&gt;    subroutine&lt;br /&gt;    bell&lt;br /&gt;    done&lt;br /&gt;&lt;/pre&gt;This is where things get magical.  We now have &lt;tt&gt;do&lt;/tt&gt; notation for something that hasn't even been interpreted yet: it's pure data.  Newcomers to Haskell often associate monads with side effects or actions, but the above code does nothing more than build a data type.  We can prove that it is still just an ordinary data type by defining a function to convert it to a string: &lt;pre&gt;&lt;br /&gt;showProgram :: (Show a, Show r) =&gt; Free (Toy a) r -&gt; String&lt;br /&gt;showProgram (Free (Output a x)) =&lt;br /&gt;    "output " ++ show a ++ "\n" ++ showProgram x&lt;br /&gt;showProgram (Free (Bell x)) =&lt;br /&gt;    "bell\n" ++ showProgram x&lt;br /&gt;showProgram (Free Done) =&lt;br /&gt;    "done\n"&lt;br /&gt;showProgram (Pure r) =&lt;br /&gt;    "return " ++ show r ++ "\n"&lt;br /&gt;&lt;/pre&gt;.. and printing it: &lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; putStr (showProgram program)&lt;br /&gt;output 'A'&lt;br /&gt;bell&lt;br /&gt;done&lt;br /&gt;&lt;/pre&gt;It looks like we just inadvertently defined our first interpreter: the pretty printer!  We can use our pretty printer to quickly check that our monad obeys some of the &lt;a href="http://hackage.haskell.org/packages/archive/base/4.3.1.0/doc/html/Control-Monad.html#t:Monad"&gt;monad laws&lt;/a&gt;: &lt;pre&gt;&lt;br /&gt;pretty :: (Show a, Show r) =&gt; Free (Toy a) r -&gt; IO ()&lt;br /&gt;pretty = putStr . showProgram&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; pretty (output 'A')&lt;br /&gt;output 'A'&lt;br /&gt;return ()&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; pretty (return 'A' &gt;&gt;= output)&lt;br /&gt;output 'A'&lt;br /&gt;return ()&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; pretty (output 'A' &gt;&gt;= return)&lt;br /&gt;output 'A'&lt;br /&gt;return ()&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; pretty ((output 'A' &gt;&gt; done) &gt;&gt; output 'C')&lt;br /&gt;output 'A'&lt;br /&gt;done&lt;br /&gt;&lt;br /&gt;&gt;&gt;&gt; pretty (output 'A' &gt;&gt; (done &gt;&gt; output 'C'))&lt;br /&gt;output 'A'&lt;br /&gt;done&lt;br /&gt;&lt;/pre&gt;Notice how &lt;tt&gt;Done&lt;/tt&gt; swallows all commands after it, unlike &lt;tt&gt;Pure&lt;/tt&gt;.  I only included &lt;tt&gt;Done&lt;/tt&gt; in the &lt;tt&gt;Toy&lt;/tt&gt; functor for illustrative purposes.  In many cases you don't need a &lt;tt&gt;Done&lt;/tt&gt;-like constructor in your functor since you probably want &lt;tt&gt;Pure&lt;/tt&gt;'s resumable behavior, however in other cases you may actually want &lt;tt&gt;Done&lt;/tt&gt;'s "abort" semantics.&lt;br /&gt;&lt;br /&gt;We could also write an actual interpreter in the conventional sense of the word: &lt;pre&gt;&lt;br /&gt;ringBell :: IO () -- some obnoxious library would provide this&lt;br /&gt;&lt;br /&gt;interpret :: (Show b) =&gt; Free (Toy b) r -&gt; IO ()&lt;br /&gt;interpret (Free (Output b x)) = print b  &gt;&gt; interpret x&lt;br /&gt;interpret (Free (Bell     x)) = ringBell &gt;&gt; interpret x&lt;br /&gt;interpret (Free  Done       ) = return ()&lt;br /&gt;interpret (Pure r) = throwIO (userError "Improper termination")&lt;br /&gt;&lt;/pre&gt;The free monad is completely agnostic as to how it is used.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Concurrency&lt;/h4&gt;&lt;br /&gt;Let's say we have two monadic "threads" we want to interleave.  For &lt;tt&gt;IO&lt;/tt&gt;, we could just use &lt;tt&gt;forkIO&lt;/tt&gt; to run them in parallel, but what if we wanted to thread two &lt;tt&gt;State&lt;/tt&gt; monads or even two &lt;tt&gt;Cont&lt;/tt&gt; monads.  How would that even work?&lt;br /&gt;&lt;br /&gt;Well, we could try representing a thread as a list of individual monad actions. &lt;pre&gt;&lt;br /&gt;type Thread m = [m ()]&lt;br /&gt;&lt;/pre&gt;... but this doesn't guarantee that our interpreter will call them in the order we list them, nor does it allow us to pass return values between successive monad actions.  We can enforce their ordering, though, by nesting each subsequent action within the previous one, and if there are no more actions left, we use a separate constructor to indicate we are done: &lt;pre&gt;&lt;br /&gt;data Thread m r = Atomic (m (Thread m r)) | Return r&lt;br /&gt;&lt;/pre&gt;This nesting forces the first action to be evaluated before the next one can be revealed and the &lt;tt&gt;Atomic&lt;/tt&gt; constructor wraps one indivisible step.  We can then turn any single monad invocation into an atomic &lt;tt&gt;Thread&lt;/tt&gt; step: &lt;pre&gt;&lt;br /&gt;atomic :: (Monad m) =&gt; m a -&gt; Thread m a&lt;br /&gt;atomic m = Atomic $ liftM Return m&lt;br /&gt;&lt;/pre&gt;Now we need a way to make &lt;tt&gt;Thread&lt;/tt&gt; a monad, but we will just "pretend" that we sequence two threads while still keeping their atomic steps separate so that we can later interleave them with other threads. &lt;pre&gt;&lt;br /&gt;instance (Monad m) =&gt; Monad (Thread m) where&lt;br /&gt;    return = Return&lt;br /&gt;    (Atomic m) &gt;&gt;= f = Atomic (liftM (&gt;&gt;= f) m)&lt;br /&gt;    (Return r) &gt;&gt;= f = f r&lt;br /&gt;&lt;/pre&gt;Using this, we can write threads broken into atomic steps: &lt;pre&gt;&lt;br /&gt;thread1 :: Thread IO ()&lt;br /&gt;thread1 = do&lt;br /&gt;    atomic $ print 1&lt;br /&gt;    atomic $ print 2&lt;br /&gt;&lt;br /&gt;thread2 :: Thread IO ()&lt;br /&gt;thread2 = do&lt;br /&gt;    str &lt;- atomic $ getLine&lt;br /&gt;    atomic $ putStrLn str&lt;br /&gt;&lt;/pre&gt;All we are missing is a way to interleave two threads, while still maintaining the atomicity of the individual steps.  Let's just do a naive alternation: &lt;pre&gt;&lt;br /&gt;interleave ::&lt;br /&gt;    (Monad m) =&gt; Thread m r -&gt; Thread m r -&gt; Thread m r&lt;br /&gt;interleave (Atomic m1) (Atomic m2) = do&lt;br /&gt;    next1 &lt;- atomic m1&lt;br /&gt;    next2 &lt;- atomic m2&lt;br /&gt;    interleave next1 next2&lt;br /&gt;interleave t1 (Return _) = t1&lt;br /&gt;interleave (Return _) t2 = t2&lt;br /&gt;&lt;/pre&gt;Now we need a way to run threads after we are done interleaving them: &lt;pre&gt;&lt;br /&gt;runThread :: (Monad m) =&gt; Thread m r -&gt; m r&lt;br /&gt;runThread (Atomic m) = m &gt;&gt;= runThread&lt;br /&gt;runThread (Return r) = return r&lt;br /&gt;&lt;/pre&gt;&lt;pre&gt;&lt;br /&gt;&gt;&gt;&gt; runThread (interleave thread1 thread2)&lt;br /&gt;1&lt;br /&gt;[[Input: "Hello, world!"]]&lt;br /&gt;2&lt;br /&gt;Hello, world!&lt;br /&gt;&lt;/pre&gt;Magic!  We just wrote a primitive threading system in Haskell!  Now try using it with the pure &lt;tt&gt;State&lt;/tt&gt; monad.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Free Monads - Part 2&lt;/h4&gt;&lt;br /&gt;If you've been paying attention, &lt;tt&gt;Thread&lt;/tt&gt; is just &lt;tt&gt;Free&lt;/tt&gt; in disguise and &lt;tt&gt;atomic&lt;/tt&gt; is &lt;tt&gt;liftF&lt;/tt&gt;.  The above example shows how a free monad greatly resembles a list.  In fact, just compare the definition of &lt;tt&gt;Free&lt;/tt&gt; to the definition of a &lt;tt&gt;List&lt;/tt&gt;: &lt;pre&gt;&lt;br /&gt;data Free f r = Free (f (Free f r)) | Pure r&lt;br /&gt;data List a   = Cons  a (List a  )  | Nil&lt;br /&gt;&lt;/pre&gt;In other words, we can think of a free monad as just being a list of functors.  The &lt;tt&gt;Free&lt;/tt&gt; constructor behaves like a &lt;tt&gt;Cons&lt;/tt&gt;, prepending a functor to the list, and the &lt;tt&gt;Pure&lt;/tt&gt; constructor behaves like &lt;tt&gt;Nil&lt;/tt&gt;, representing an empty list (i.e. no functors).&lt;br /&gt;&lt;br /&gt;So if a &lt;tt&gt;List&lt;/tt&gt; is a list of values, and a free monad is just a list of functors, what happens if the free monad's functor is itself a value: &lt;pre&gt;&lt;br /&gt;type List' a = Free ((,) a) ()&lt;br /&gt;&lt;br /&gt;List' a&lt;br /&gt;= Free ((,) a) ()&lt;br /&gt;= Free (a, List' a)) | Pure ()&lt;br /&gt;= Free a (List' a) | Pure ()&lt;br /&gt;&lt;/pre&gt;It becomes an ordinary list!&lt;br /&gt;&lt;br /&gt;A list is just a special case of a free monad.  However, the &lt;tt&gt;Monad&lt;/tt&gt; instance for &lt;tt&gt;[]&lt;/tt&gt; is not the same thing as the &lt;tt&gt;Monad&lt;/tt&gt; instance for &lt;tt&gt;List' a&lt;/tt&gt; (i.e. &lt;tt&gt;Free ((,) a)&lt;/tt&gt;).  In the &lt;tt&gt;List' a&lt;/tt&gt; monad, &lt;tt&gt;join&lt;/tt&gt; behaves like &lt;tt&gt;(++)&lt;/tt&gt; and &lt;tt&gt;return&lt;/tt&gt; behaves like &lt;tt&gt;[]&lt;/tt&gt;, so you can think of the &lt;tt&gt;List' a&lt;/tt&gt; monad as just being a fancy way to concatenate values using &lt;tt&gt;do&lt;/tt&gt; notation.&lt;br /&gt;&lt;br /&gt;When you think of free monads as lists, a lot of things become much more obvious.  For example, &lt;tt&gt;liftF&lt;/tt&gt; is just like the singleton list, creating a free monad with exactly one functor in it: &lt;pre&gt;&lt;br /&gt;singleton x = Cons x Nil -- i.e. x:[], or [x]&lt;br /&gt;&lt;br /&gt;liftF x = Free (fmap Pure x)&lt;br /&gt;&lt;/pre&gt;Similarly, our &lt;tt&gt;interleave&lt;/tt&gt; function is just a list merge: &lt;pre&gt;&lt;br /&gt;merge (x1:xs1) (x2:xs2) = x1:x2:merge xs1 xs2&lt;br /&gt;merge xs1 [] = xs1&lt;br /&gt;merge [] xs2 = xs2&lt;br /&gt;&lt;br /&gt;-- this is actually more similar to:&lt;br /&gt;-- [x1] ++ [x2] ++ interleave xs1 xs2&lt;br /&gt;interleave (Atomic m1) (Atomic m2) = do&lt;br /&gt;    next1 &lt;- liftF m1&lt;br /&gt;    next2 &lt;- liftF m2&lt;br /&gt;    interleave next1 next2&lt;br /&gt;interleave a1 (Return _) = a1&lt;br /&gt;interleave (Return _) a2 = a2&lt;br /&gt;&lt;/pre&gt;So really, when you think of it that way, concurrency is nothing more than merging a bunch of lists of actions.  In a later post, I will review a great paper that demonstrates how you can actually build elegant and robust threading systems and schedulers using this free monad approach.&lt;br /&gt;&lt;br /&gt;It's not a coincidence that free monads resemble lists.  If you learn category theory, you'll discover that they are both free objects, where lists are free monoids, and free monads are ... well, free monads.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Interpreters - Revisited&lt;/h4&gt;&lt;br /&gt;In the first section I presented the concept of using free monads for interpreters, but the concept of an interpreter is more powerful and useful than it sounds and it's not just limited to compilers and pretty printers.&lt;br /&gt;&lt;br /&gt;For example, let's say you wanted to one-up Notch's game idea for &lt;tt&gt;0x10c&lt;/tt&gt; and make a player-programmable game ... except in Haskell!  You want to accept programs from players that they can run in the game, but you don't want to give them full-blown access to the &lt;tt&gt;IO&lt;/tt&gt; monad, so what do you do?&lt;br /&gt;&lt;br /&gt;The naive approach might be to copy the Haskell language's original design, where output is presented as list of requests made to the outside world and input is presented as a list of responses received from the outside world: &lt;pre&gt;&lt;br /&gt;main :: [Response] -&gt; [Request]&lt;br /&gt;&lt;/pre&gt;The &lt;tt&gt;Request&lt;/tt&gt; type would enumerate the sort of actions you could take and the &lt;tt&gt;Response&lt;/tt&gt; type would delimit the results you would get back.  Then for our game, the set of inputs might be: &lt;pre&gt;&lt;br /&gt;data Request =&lt;br /&gt;    Look Direction&lt;br /&gt;  | ReadLine&lt;br /&gt;  | Fire Direction&lt;br /&gt;  | WriteLine String&lt;br /&gt;&lt;/pre&gt;... and the responses might be: &lt;pre&gt;&lt;br /&gt;data Response =&lt;br /&gt;    Image Picture     -- Response for Look&lt;br /&gt;  | ChatLine String   -- Response for Read&lt;br /&gt;  | Succeeded Bool    -- Response for Write&lt;br /&gt;&lt;/pre&gt;Well, that certainly won't work.  There is no clear coupling between requests and responses (&lt;tt&gt;Fire&lt;/tt&gt; doesn't even have a response), and it's not clear what should happen if you try to read responses before you even generate requests.&lt;br /&gt;&lt;br /&gt;So let's try to impose some kind of order on these inputs and outputs by merging them into a single data type: &lt;pre&gt;&lt;br /&gt;data Interaction next =&lt;br /&gt;    Look Direction (Image -&gt; next)&lt;br /&gt;  | Fire Direction next&lt;br /&gt;  | ReadLine (String -&gt; next)&lt;br /&gt;  | WriteLine String (Bool -&gt; next)&lt;br /&gt;&lt;/pre&gt;Each constructor can have some fields the player fills in (i.e. the player's requests), and they can also provide functions which the interpreter will supply input to.  You can think of this &lt;tt&gt;Interaction&lt;/tt&gt; type as the contract between the programmer and the interpreter for a single step.&lt;br /&gt;&lt;br /&gt;Conveniently, &lt;tt&gt;Interaction&lt;/tt&gt; forms a functor: &lt;pre&gt;&lt;br /&gt;instance Functor Interaction where&lt;br /&gt;    fmap f (Look dir g) = Look dir (f . g)&lt;br /&gt;    fmap f (Fire dir x) = Fire dir (f x)&lt;br /&gt;    fmap f (ReadLine g) = ReadLine (f . g)&lt;br /&gt;    fmap f (WriteLine s g) = WriteLine s (f . g)&lt;br /&gt;&lt;/pre&gt;Actually, you don't even have to write that.  GHC provides the &lt;tt&gt;DeriveFunctor&lt;/tt&gt; extension, which would you let you just write: &lt;pre&gt;&lt;br /&gt;data Interaction ... deriving (Functor)&lt;br /&gt;&lt;/pre&gt;... and it will get it correct.&lt;br /&gt;&lt;br /&gt;As always, we can create a list of actions by using the &lt;tt&gt;Free&lt;/tt&gt; monad: &lt;pre&gt;&lt;br /&gt;type Program = Free Interaction&lt;br /&gt;&lt;/pre&gt;With &lt;tt&gt;Program&lt;/tt&gt; in hand, the player can now write a simple program: &lt;pre&gt;&lt;br /&gt;easyToAnger = Free $ ReadLine $ \s -&gt; case s of&lt;br /&gt;    "No" -&gt; Free $ Fire Forward&lt;br /&gt;          $ Free $ WriteLine "Take that!" (\_ -&gt; easyToAnger)&lt;br /&gt;    _    -&gt; easyToAnger&lt;br /&gt;&lt;/pre&gt;The interpreter can then interpret the program for him, perhaps converting it into some sort of &lt;tt&gt;Game&lt;/tt&gt; monad: &lt;pre&gt;&lt;br /&gt;interpret :: Program r -&gt; Game r&lt;br /&gt;interpret prog = case prog of&lt;br /&gt;    Free (Look dir g) -&gt; do&lt;br /&gt;        img &lt;- collectImage dir&lt;br /&gt;        interpret (g img)&lt;br /&gt;    Free (Fire dir next) -&gt; do&lt;br /&gt;        sendBullet dir&lt;br /&gt;        interpret next&lt;br /&gt;    Free (ReadLine g) -&gt; do&lt;br /&gt;        str &lt;- getChatLine&lt;br /&gt;        interpret (g str)&lt;br /&gt;    Free (WriteLine s g) -&gt;&lt;br /&gt;        putChatLine s&lt;br /&gt;        interpret (g True)&lt;br /&gt;    Pure r -&gt; return r&lt;br /&gt;&lt;/pre&gt;Every free monad is guaranteed to be a monad, so we can always give the player syntactic sugar for writing their programs using Haskell &lt;tt&gt;do&lt;/tt&gt; notation: &lt;pre&gt;&lt;br /&gt;look :: Direction -&gt; Program Image&lt;br /&gt;look dir = liftF (Look dir id)&lt;br /&gt;&lt;br /&gt;fire :: Direction -&gt; Program ()&lt;br /&gt;fire dir = liftF (Fire dir ())&lt;br /&gt;&lt;br /&gt;readLine :: Program String&lt;br /&gt;readLine = liftF (ReadLine id)&lt;br /&gt;&lt;br /&gt;writeLine :: String -&gt; Program Bool&lt;br /&gt;writeLine s = liftF (WriteLine s id)&lt;br /&gt;&lt;/pre&gt;Now, the player can more easily write their program as: &lt;pre&gt;&lt;br /&gt;easyToAnger :: Program a&lt;br /&gt;easyToAnger = forever $ do&lt;br /&gt;    str &lt;- readLine&lt;br /&gt;    when (str == "No") $ do&lt;br /&gt;        fire Forward&lt;br /&gt;        -- Ignore the Bool returned by writeLine&lt;br /&gt;        _ &lt;- writeLine "Take that!"&lt;br /&gt;        return ()&lt;br /&gt;&lt;/pre&gt;In short, we've given the player a sand-boxed interaction language that delimits their actions, yet complete with all the syntactic monad sugar and luxuries of programming in Haskell.  On top of this, we've given ourselves the complete freedom to interpret the player's program any way we please.  For example, if I were to release a patch tomorrow that changed the game world (and Haskell had some form of code hot-swapping), I could keep running the players' programs without interruption by just switching out the interpreter.  Or, if I were sadistic, I could use the most aggressive player's program to control a real-world destructive robot of doom (a.k.a. the &lt;tt&gt;IO&lt;/tt&gt; monad) and watch it wreak havoc.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h4&gt;Free Monads - Part 3&lt;/h4&gt;&lt;br /&gt;The free monad is the interpreter's best friend.  Free monads "free the interpreter" as much as possible while still maintaining the bare minimum necessary to form a monad.&lt;br /&gt;&lt;br /&gt;Free monads arise every time an interpreter wants to give the program writer a monad, and nothing more.  If you are the interpreter and I am the program writer, you can push against me and keep your options as free as possible by insisting that I write a program using a free monad that you provide me.  The free monad is guaranteed to be the formulation that gives you the most flexibility how to interpret it, since it is purely syntactic.&lt;br /&gt;&lt;br /&gt;This notion of "freeing the interpreter" up as much as possible sounds a lot like an optimization problem, which you might phrase as follows: &lt;blockquote&gt;What is the most flexible monad to interpret, given the constraint that it still must be a monad? &lt;/blockquote&gt;In fact, maximizing some notion of "freeness" given a constraint is the intuition that leads to the category theory definition of a &lt;a href="http://en.wikipedia.org/wiki/Free_object"&gt;free object&lt;/a&gt;, where the concept of "freeness" is made rigorous.  A free monad just happens to be the "free-est" object that still forms a monad.</description><link>http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html</link><author>noreply@blogger.com (Gabriel Gonzalez)</author><thr:total>11</thr:total></item></channel></rss>